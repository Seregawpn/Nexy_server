> [!WARNING] ARCHIVE NOTICE
> Этот документ архивный и не является source of truth.
> Актуальные каноны:
> - `server/Docs/SERVER_DEPLOYMENT_GUIDE.md` (деплой кода на удаленный сервер)
> - `server/Docs/RELEASE_AND_UPDATE_GUIDE.md` (публикация DMG/PKG и update-канал)
> - `server/Docs/DEPLOY_INCIDENT_RUNBOOK.md` (инциденты, зависимости, конфиги, rollback)

# План реализации: совместный текст + MCP-команда от ассистента

> **ВАЖНО**: Этот документ содержит исторический план реализации.  
> **Канон:** `Docs/MCP_INTEGRATION_SUMMARY.md` — итоговый summary с актуальным статусом реализации.

---

## Фаза 1. Контракт и парсинг

**Цель:** согласовать формат ответа ассистента и научиться безопасно его разбирать, не нарушая текущие потоковые механики.

### 1.1 Формат ответа ассистента
- Обязательные поля:
  - `session_id`: строка (UUID текущей сессии).
  - `text`: строка для озвучки (может быть пустой, но поле присутствует).
- Для action-сценариев:
  - `command`: строковая константа (например, `open_app`).
  - `args`: объект с аргументами. Минимальный набор:
    - `app_name`: строка (точное имя приложения в macOS).
  - Возможны дополнительные поля (`metadata`, `action_type`), но сервер должен корректно работать даже если их нет.
- Для текстовых ответов:
  - `command` отсутствует, либо равен `null`.

### 1.2 Документация/контракты
- `Docs/ARCHITECTURE_OVERVIEW.md`:
  - Добавить подраздел про ассистентские action-ответы.
  - Вставить примеры:
    - обычный ответ (только `text`);
    - action-ответ (JSON с `command` + текстом).
- `Docs/SERVER_DEVELOPMENT_RULES.md`:
  - В разделе про gRPC или FSM упомянуть, что решения об action принимает ассистент (LLM), сервер только транслирует.
- При необходимости оформить ADR с описанием новой ответственности ассистента.

### 1.3 Парсер/валидатор
- Реализовать helper, который принимает строку (или структуру) и возвращает:
  - `text_response`: строка;
  - `command_payload`: словарь `{event: "mcp.command_request", payload: {...}}` либо `None`;
  - дополнительные поля (`session_id`, `args`), если нужно для логирования.
- Требования к helper’у:
  - Толерантность к “кривым” данным: если пришёл обычный текст без JSON — вернуть `text_response`, `command_payload=None`.
  - Если JSON, но отсутствует `text` — логировать, и подставлять пустую строку (чтобы TTS не падал).
  - Проверка обязательных полей (`session_id`, `app_name`) и генерация ошибок/логов при их отсутствии.
  - Возможность расширения (не завязываться только на `open_app`).
- Расположение: `integrations/core/assistant_response_parser.py` (или аналогичный файл, доступный из workflow).

### 1.4 Тестирование (Фаза 1)
- Unit-тесты на helper:
  1. Action-ответ с валидными полями (ожидаем корректную структуру).
  2. Action-ответ без `text`.
  3. Обычный текстовый ответ (не JSON).
  4. JSON без `command`.
  5. Некорректный JSON (не парсится) → fallback на обычный текст.
- Проверка логирования: убедиться, что ошибки/варнинги пишутся в стандартные логи.

---

## Фаза 2. Workflow и генерация речи

**Цель:** научиться принимать комбинированные ответы, разделять их на «текст для TTS» и «payload для MCP», сохраняя потоковый режим.

### 2.1 Изменения в StreamingWorkflowIntegration
- После получения чанка из текстового модуля (или перед выдачей в клиент) прогонять его через helper (из Фазы 1).
- `text_response`:
  - обращаться как к обычному ответу (буферизация, разбиение на предложения, дедупликация).
  - если `text_response` пустой → не запускать аудио-генерацию (но MCP payload всё равно должен быть отправлен).
- `command_payload`:
  - сохранить в состоянии workflow (например, `self._pending_command_payload`), чтобы отдать клиенту один раз (в конце стрима или сразу после детекта).
  - гарантировать, что при нескольких чанках MCP payload не дублируется.

### 2.2 Взаимодействие с аудио модулем
- Предусмотреть случаи:
  - `text_response` присутствует → генерируем аудио как сейчас.
  - `text_response` пустой → пропускаем аудио-генерацию (чтобы не отправлять “тишину”).
  - Смешанный поток (сначала текст, потом action) — разрешить частичную генерацию текста до того, как приходит action JSON.

### 2.3 Логирование
- При обнаружении команды:
  - `scope=command`, `decision=start`, `ctx`: `session_id`, `command`, `args`.
  - При успешном завершении — `decision=complete`.
  - При ошибках парсинга — `decision=error`, причина.
- В обычном тексте логирование остаётся прежним (start/complete per sentence, и т.д.).

### 2.4 Тестирование (Фаза 2)
- Расширить тесты workflow (если есть) или добавить новые:
  1. Ответ без команды → текст и аудио идут как обычно.
  2. Ответ с командой + текстом → текст передаётся в TTS, MCP payload фиксируется.
  3. Ответ с командой, но без текста → MCP payload есть, текст/аудио отсутствуют.
  4. Несколько чанков, где action приходит не первым.
- Проверить, что действие (payload) не дублируется и что text/audio не ломаются.

---

## Фаза 3. gRPC слой, клиентский контракт и тесты

**Цель:** доставить текст и MCP payload до клиента, не ломая существующий gRPC интерфейс.

### 3.1 GrpcServiceIntegration и grpc_server
- В `GrpcServiceIntegration`:
  - адаптировать структуру `result`/`item`, чтобы в ней могли присутствовать и `text_response`, и `command_payload`.
  - убедиться, что `command_payload` передаётся дальше после завершения workflow (например, отдельный yield с флагом `success=True`).
- В `grpc_server.py`:
  - при получении `text_response` → отправить `StreamResponse(text_chunk=...)`.
  - при наличии `command_payload`:
    - вариант 1: отправлять ещё один `text_chunk`, но с префиксом (`__MCP__{...}`) — потребуется согласование с клиентом.
    - вариант 2: расширить protobuf (добавить поле `command_json`). Требует синхронизации и обновления клиента.
  - ***Выбор зависит от ограничений по backward-compatibility.*** Если менять proto нельзя, используем текстовый чанк с явным префиксом, о котором знает клиент.
  - Гарантировать, что `command_payload` рассылается один раз.

### 3.2 Клиентская часть (информативно)
- Сообщить команде клиента о новом формате:
  - какие чанки нужно отслеживать (по префиксу или новому полю).
  - куда публиковать JSON (EventBus `mcp.command_request`).
  - как обрабатывать текст без команды (ничего не меняется).

### 3.3 Обновления документации
- `Docs/ARCHITECTURE_OVERVIEW.md`: дополнить раздел gRPC → описать, как клиент отличает JSON чанк от текста.
- При необходимости — README или internal wiki с инструкцией для клиента.

### 3.4 Тестирование (Фаза 3)
- **Интеграционный тест** (можно моковый):
  1. Вызвать StreamingWorkflowIntegration с “action”-ответом → убедиться, что через gRPC отдаётся и текст, и JSON.
  2. Проверить формат chunk’ов (текст отдельно, JSON — отдельно).
- Если меняем proto: добавить тест на сериализацию/deserialization `StreamResponse`.
- При возможности — end-to-end тест (Python клиент, который принимает текст/JSON и проверяет, что всё распарсилось).

---

## Дополнительно (актуально для всех фаз)

- **Фича-флаг (опционально):**
  - `features.forward_assistant_actions` — включает передачу JSON на клиента. По умолчанию `false`, чтобы можно было безопасно выкатывать.
- **Логирование и мониторинг:**
  - добавить метрику `assistant_action_count{command}`.
  - при ошибках парсинга/валидации — писать в логи и метрики (чтобы отследить некорректные ответы ассистента).
- **Rollout:**
  - plan: dev → staging → prod.
  - убедиться, что клиент готов к новому формату перед включением флага.
- **Документирование:**
  - все изменения (включая флаги и клиенский контракт) прописать в PR description и соответствующих Docs.

---

Эти фазы позволяют поэтапно внедрить поддержку action-ответов без серверных детекторов и с минимальными рисками для текущего стримингового поведения.

---

## Резюме реализации

**См. канон:** `Docs/MCP_INTEGRATION_SUMMARY.md` — актуальный статус реализации и детали.

### ✅ Статус: Все фазы завершены (исторический)

**Фаза 1: ✅ ЗАВЕРШЕНА**
- ✅ Документированный контракт формата ответа ассистента
- ✅ Helper-класс `assistant_response_parser.py` с валидацией и парсингом
- ✅ Unit-тесты на все граничные случаи парсинга (12 тестов, все проходят)
- ✅ Обновлённая документация в `ARCHITECTURE_OVERVIEW.md` и `SERVER_DEVELOPMENT_RULES.md`
- ✅ Фича-флаг `features.forward_assistant_actions` и kill-switch добавлены в конфигурацию

**Фаза 2: ✅ ЗАВЕРШЕНА**
- ✅ Изменения в `StreamingWorkflowIntegration` для обработки комбинированных ответов
- ✅ Разделение `text_response` и `command_payload` в потоке
- ✅ Логирование с `scope=command` для отслеживания действий
- ✅ Пропуск аудио-генерации для пустого текста
- ✅ Unit/интеграционные тесты workflow созданы (6 тестов)

**Фаза 3: ✅ ЗАВЕРШЕНА**
- ✅ Адаптация `GrpcServiceIntegration` и `grpc_server.py` для передачи MCP payload
- ✅ Решение по формату передачи: префикс `__MCP__` (backward compatible, без изменения proto)
- ✅ Интеграционные тесты gRPC слоя созданы (4 теста, частично проходят)
- ✅ Документация для клиентской команды обновлена

### Критерии готовности к rollout

1. ✅ Все unit-тесты проходят (парсер: 12/12)
2. ⚠️ Интеграционные тесты требуют доработки моков (основная логика проверена)
3. ✅ Фича-флаг `features.forward_assistant_actions` добавлен в конфигурацию
4. ✅ Документация обновлена (`ARCHITECTURE_OVERVIEW.md`)
5. ⏳ Метрики `assistant_action_count{command}` (опционально, можно добавить позже)
6. ⏳ План rollout (dev → staging → prod) - требуется согласование

### Следующие шаги перед production

1. **Проверка клиента:**
   - Убедиться, что клиент готов отслеживать префикс `__MCP__` в `text_chunk`
   - Проверить публикацию события `mcp.command_request` в EventBus
   - Согласовать формат JSON payload с клиентской командой

2. **Тестирование на staging:**
   - Включить `FORWARD_ASSISTANT_ACTIONS=true` в staging окружении
   - Прогнать smoke-тесты с action-ответами
   - Проверить логирование с `scope=command`
   - Убедиться, что озвучка текста работает параллельно с MCP командами

3. **Доработка тестов (опционально):**
   - Улучшить моки в интеграционных тестах для полного покрытия
   - Добавить end-to-end тесты с реальным gRPC клиентом

4. **Мониторинг и метрики:**
   - Настроить метрику `assistant_action_count{command}` (если требуется)
   - Добавить алерты на ошибки парсинга/валидации

5. **Rollout план:**
   - Dev: включить фича-флаг, проверить базовую функциональность
   - Staging: полное тестирование с клиентом
   - Prod: канареечный rollout (1% → 25% → 100%) с мониторингом
