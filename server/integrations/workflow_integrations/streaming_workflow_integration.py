#!/usr/bin/env python3
"""
StreamingWorkflowIntegration - —É–ø—Ä–∞–≤–ª—è–µ—Ç –ø–æ—Ç–æ–∫–æ–º: —Ç–µ–∫—Å—Ç ‚Üí –∞—É–¥–∏–æ ‚Üí –∫–ª–∏–µ–Ω—Ç
"""

import logging
from typing import Dict, Any, AsyncGenerator, Optional, Union
from datetime import datetime

from config.unified_config import WorkflowConfig, get_config
from integrations.core.assistant_response_parser import AssistantResponseParser
from utils.logging_formatter import log_structured

logger = logging.getLogger(__name__)


class StreamingWorkflowIntegration:
    """
    –£–ø—Ä–∞–≤–ª—è–µ—Ç –ø–æ—Ç–æ–∫–æ–º –æ–±—Ä–∞–±–æ—Ç–∫–∏: –ø–æ–ª—É—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ ‚Üí –æ–±—Ä–∞–±–æ—Ç–∫–∞ ‚Üí –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∞—É–¥–∏–æ ‚Üí —Å—Ç—Ä–∏–º–∏–Ω–≥ –∫–ª–∏–µ–Ω—Ç—É
    """
    
    def __init__(
        self,
        text_processor=None,
        audio_processor=None,
        memory_workflow=None,
        text_filter_manager=None,
        workflow_config: Optional[Union[WorkflowConfig, Dict[str, Any]]] = None,
    ):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è StreamingWorkflowIntegration
        
        Args:
            text_processor: –ú–æ–¥—É–ª—å –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞ (UniversalModuleInterface)
            audio_processor: –ú–æ–¥—É–ª—å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∞—É–¥–∏–æ (UniversalModuleInterface)
            memory_workflow: Workflow –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –ø–∞–º—è—Ç—å—é
            text_filter_manager: –ú–æ–¥—É–ª—å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞ (UniversalModuleInterface)
        """
        # –£–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–æ–¥—É–ª–∏ (–Ω–∞–∑–≤–∞–Ω–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –æ—Å—Ç–∞–≤–ª–µ–Ω—ã –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)
        self.text_module = text_processor
        self.audio_module = audio_processor
        self.memory_workflow = memory_workflow
        self.text_filter_module = text_filter_manager
        self.is_initialized = False
        
        # –ï–¥–∏–Ω–∞—è –Ω–µ–±–ª–æ–∫–∏—Ä—É—é—â–∞—è –±—É—Ñ–µ—Ä–∏–∑–∞—Ü–∏—è –∏ –∫—Ä–∏—Ç–µ—Ä–∏–∏ —Ñ–ª–∞—à–∏–Ω–≥–∞ (–¥–ª—è —Ç–µ–∫—Å—Ç–∞ –∏ TTS –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ)
        self._stream_buffer: str = ""
        self._has_emitted: bool = False
        self._pending_segment: str = ""
        self._processed_sentences: set = set()  # –î–ª—è –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏
        
        # MCP command payload (–§–∞–∑–∞ 2)
        self._pending_command_payload: Optional[Dict[str, Any]] = None
        self._command_payload_sent: bool = False
        self._assistant_parser = AssistantResponseParser()
        # –ë—É—Ñ–µ—Ä –¥–ª—è –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è JSON –æ—Ç–≤–µ—Ç–æ–≤ –æ—Ç LLM
        self._json_buffer: str = ""
        self._json_parsed: bool = False
        # –¶–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –ø–æ—Ä–æ–≥–∏
        if workflow_config is None:
            workflow_config = get_config().get_workflow_thresholds()

        if isinstance(workflow_config, WorkflowConfig):
            cfg = workflow_config
        else:
            cfg = WorkflowConfig(**workflow_config)

        self.stream_min_chars: int = cfg.stream_min_chars
        self.stream_min_words: int = cfg.stream_min_words
        self.stream_first_sentence_min_words: int = cfg.stream_first_sentence_min_words
        self.stream_punct_flush_strict: bool = bool(cfg.stream_punct_flush_strict)
        self.force_flush_max_chars: int = cfg.force_flush_max_chars
        self.sentence_joiner: str = " "
        self.end_punctuations = ('.', '!', '?')
        
        logger.info("StreamingWorkflowIntegration —Å–æ–∑–¥–∞–Ω")
    
    async def initialize(self) -> bool:
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏
        
        Returns:
            True –µ—Å–ª–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —É—Å–ø–µ—à–Ω–∞, False –∏–Ω–∞—á–µ
        """
        try:
            logger.info("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è StreamingWorkflowIntegration...")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –º–æ–¥—É–ª–µ–π
            if not self.text_module:
                logger.warning("‚ö†Ô∏è TextProcessor –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω")
            
            if not self.audio_module:
                logger.warning("‚ö†Ô∏è AudioProcessor –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω")
            
            if not self.memory_workflow:
                logger.warning("‚ö†Ô∏è MemoryWorkflow –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω")
            
            if not self.text_filter_module:
                logger.warning("‚ö†Ô∏è TextFilterManager –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω")
            
            self.is_initialized = True
            logger.info("‚úÖ StreamingWorkflowIntegration –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω —É—Å–ø–µ—à–Ω–æ")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ StreamingWorkflowIntegration: {e}")
            return False
    
    async def process_request_streaming(self, request_data: Dict[str, Any]) -> AsyncGenerator[Dict[str, Any], None]:
        """–ü–æ—Ç–æ–∫–æ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–∞: –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∏ –∞—É–¥–∏–æ —Å—Ç—Ä–∏–º—è—Ç—Å—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ."""
        if not self.is_initialized:
            logger.error("‚ùå StreamingWorkflowIntegration –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
            yield {
                'success': False,
                'error': 'StreamingWorkflowIntegration not initialized',
                'text_response': '',
            }
            return

        session_id = request_data.get('session_id', 'unknown')
        try:
            logger.info(f"üîÑ –ù–∞—á–∞–ª–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–∞: {session_id}")
            logger.info(f"‚Üí Input text len={len(request_data.get('text','') or '')}, has_screenshot={bool(request_data.get('screenshot'))}")
            logger.info(f"‚Üí Input text content: '{request_data.get('text', '')[:100]}...'")

            logger.info("üîç –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê –ú–û–î–£–õ–ï–ô:")
            logger.info(f"   ‚Üí text_processor: {self.text_module is not None}")
            logger.info(f"   ‚Üí audio_processor: {self.audio_module is not None}")
            if self.text_module:
                logger.info(f"   ‚Üí text_processor.is_initialized: {getattr(self.text_module, 'is_initialized', 'NO_ATTR')}")
            if self.audio_module:
                logger.info(f"   ‚Üí audio_processor.is_initialized: {getattr(self.audio_module, 'is_initialized', 'NO_ATTR')}")

            hardware_id = request_data.get('hardware_id', 'unknown')
            memory_context = await self._get_memory_context_parallel(hardware_id)

            # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ –ø–µ—Ä–µ–¥ –Ω–æ–≤–æ–π —Å–µ—Å—Å–∏–µ–π,
            # –∏–Ω–∞—á–µ –æ—Å—Ç–∞—Ç–∫–∏ –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–µ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤—ã–∑—ã–≤–∞—é—Ç –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ —á–∞–Ω–∫–æ–≤
            self._stream_buffer = ""
            self._pending_segment = ""
            self._has_emitted = False
            self._processed_sentences.clear()
            # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ MCP –∫–æ–º–∞–Ω–¥—ã (–§–∞–∑–∞ 2)
            self._pending_command_payload = None
            self._command_payload_sent = False
            # –°–±—Ä–∞—Å—ã–≤–∞–µ–º –±—É—Ñ–µ—Ä –¥–ª—è –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è JSON –æ—Ç–≤–µ—Ç–æ–≤ –æ—Ç LLM
            self._json_buffer = ""
            self._json_parsed = False

            captured_segments: list[str] = []
            input_sentence_counter = 0
            emitted_segment_counter = 0
            total_audio_chunks = 0
            total_audio_bytes = 0
            sentence_audio_map: dict[int, int] = {}

            async for sentence in self._iter_processed_sentences(
                request_data.get('text', ''),
                request_data.get('screenshot'),
                memory_context
            ):
                input_sentence_counter += 1
                logger.info(f"üìù In sentence #{input_sentence_counter}: '{sentence[:120]}{'...' if len(sentence) > 120 else ''}' (len={len(sentence)})")

                # –ù–∞–∫–æ–ø–ª–µ–Ω–∏–µ JSON: –¥–æ–±–∞–≤–ª—è–µ–º —á–∞—Å—Ç—å –≤ –±—É—Ñ–µ—Ä
                self._json_buffer += sentence
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è –ª–∏ –±—É—Ñ–µ—Ä —Å JSON (–º–æ–∂–µ—Ç –±—ã—Ç—å `{` –∏–ª–∏ –ø—Ä–æ–±–µ–ª—ã –ø–µ—Ä–µ–¥ `{`)
                is_potential_json = self._json_buffer.strip().startswith('{')
                
                if is_potential_json:
                    # –ü—ã—Ç–∞–µ–º—Å—è —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω—ã–π JSON
                    parsed_json = None
                    try:
                        import json
                        parsed_json = json.loads(self._json_buffer.strip())
                        # JSON –≤–∞–ª–∏–¥–µ–Ω - –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ
                        logger.info(f"‚úÖ JSON –ø–æ–ª–Ω–æ—Å—Ç—å—é –Ω–∞–∫–æ–ø–ª–µ–Ω –∏ —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω: {len(self._json_buffer)} —Å–∏–º–≤–æ–ª–æ–≤")
                        self._json_parsed = True
                    except (json.JSONDecodeError, ValueError):
                        # JSON –µ—â—ë –Ω–µ –ø–æ–ª–Ω—ã–π - –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –Ω–∞–∫–∞–ø–ª–∏–≤–∞—Ç—å
                        logger.debug(f"üì¶ –ù–∞–∫–æ–ø–ª–µ–Ω–∏–µ JSON: {len(self._json_buffer)} —Å–∏–º–≤–æ–ª–æ–≤ (–µ—â—ë –Ω–µ –ø–æ–ª–Ω—ã–π)")
                        continue
                    
                    # JSON –ø–æ–ª–Ω–æ—Å—Ç—å—é –Ω–∞–∫–æ–ø–ª–µ–Ω - –ø–∞—Ä—Å–∏–º –µ–≥–æ
                    parsed = await self._parse_assistant_response(parsed_json, session_id)
                    if parsed.command_payload and not self._command_payload_sent:
                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º command_payload –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –æ–¥–∏–Ω —Ä–∞–∑
                        self._pending_command_payload = parsed.command_payload
                        # –õ–æ–≥–∏—Ä—É–µ–º –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –∫–æ–º–∞–Ω–¥—ã
                        self._log_command_detected(parsed, session_id)
                    
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ text_response –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
                    sentence = parsed.text_response
                    logger.info(f"üìù –ü–æ—Å–ª–µ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON: text_response='{sentence[:100] if sentence else '(–ø—É—Å—Ç–æ)'}...' (len={len(sentence) if sentence else 0})")
                    
                    # –û—á–∏—â–∞–µ–º JSON –±—É—Ñ–µ—Ä –ø–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥–∞
                    self._json_buffer = ""
                    self._json_parsed = False
                else:
                    # –≠—Ç–æ –Ω–µ JSON - –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∫ –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç (–ø–µ—Ä–µ–¥–∞—ë–º —á–∞—Å—Ç—è–º–∏)
                    logger.debug(f"üìù –û–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç (–Ω–µ JSON): {len(sentence)} —Å–∏–º–≤–æ–ª–æ–≤, –ø–µ—Ä–µ–¥–∞—ë–º —á–∞—Å—Ç—è–º–∏")
                    # –û—á–∏—â–∞–µ–º JSON –±—É—Ñ–µ—Ä, —Ç–∞–∫ –∫–∞–∫ —ç—Ç–æ –Ω–µ JSON
                    self._json_buffer = ""
                    # –ü–∞—Ä—Å–∏–º –∫–∞–∫ –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç (–º–æ–∂–µ—Ç –±—ã—Ç—å —Ñ–æ—Ä–º–∞—Ç {"text": "..."} –∏–ª–∏ –ø—Ä–æ—Å—Ç–æ —Ç–µ–∫—Å—Ç)
                    parsed = await self._parse_assistant_response(sentence, session_id)
                    sentence = parsed.text_response

                # –ï–¥–∏–Ω–∞—è –±—É—Ñ–µ—Ä–∏–∑–∞—Ü–∏—è: –Ω–∞–∫–∞–ø–ª–∏–≤–∞–µ–º, –∏–∑–≤–ª–µ–∫–∞–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è, –∞–≥—Ä–µ–≥–∏—Ä—É–µ–º –∫–æ—Ä–æ—Ç–∫–∏–µ
                # –í–ê–ñ–ù–û: –¥–∞–∂–µ –µ—Å–ª–∏ —ç—Ç–æ –¥–µ–π—Å—Ç–≤–∏–µ, text_response –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å —Ç–µ–∫—Å—Ç –¥–ª—è TTS
                if not sentence or not sentence.strip():
                    logger.warning(f"‚ö†Ô∏è text_response –ø—É—Å—Ç–æ–π –ø–æ—Å–ª–µ –ø–∞—Ä—Å–∏–Ω–≥–∞, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É TTS")
                    continue
                
                logger.info(f"üìù –û–±—Ä–∞–±–æ—Ç–∫–∞ text_response –¥–ª—è TTS: '{sentence[:100]}{'...' if len(sentence) > 100 else ''}' (len={len(sentence)})")
                    
                sanitized = await self._sanitize_for_tts(sentence)
                logger.info(f"üìù –ü–æ—Å–ª–µ —Å–∞–Ω–∏—Ç–∏–∑–∞—Ü–∏–∏: '{sanitized[:100] if sanitized else '(–ø—É—Å—Ç–æ)'}{'...' if sanitized and len(sanitized) > 100 else ''}' (len={len(sanitized) if sanitized else 0})")
                if sanitized:
                    # –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è —Ç–æ–ª—å–∫–æ –Ω–∞ —É—Ä–æ–≤–Ω–µ –æ—á–∏—â–µ–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ (–±–æ–ª–µ–µ –º—è–≥–∫–∞—è)
                    sanitized_hash = hash(sanitized.strip())
                    if sanitized_hash in self._processed_sentences:
                        logger.debug(f"üîÑ –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—á–∏—â–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç: '{sanitized[:50]}...'")
                        continue
                    self._processed_sentences.add(sanitized_hash)
                    
                    self._stream_buffer = (f"{self._stream_buffer}{self.sentence_joiner}{sanitized}" if self._stream_buffer else sanitized)
                    logger.info(f"üìù –î–æ–±–∞–≤–ª–µ–Ω–æ –≤ stream_buffer: len={len(self._stream_buffer)}, content='{self._stream_buffer[:100]}{'...' if len(self._stream_buffer) > 100 else ''}'")

                complete_sentences, remainder = await self._split_complete_sentences(self._stream_buffer)
                logger.info(f"üìù _split_complete_sentences: complete={len(complete_sentences)}, remainder_len={len(remainder) if remainder else 0}")
                self._stream_buffer = remainder

                for complete in complete_sentences:
                    # –ê–≥—Ä–µ–≥–∏—Ä—É–µ–º –∫–æ—Ä–æ—Ç–∫–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –¥–æ –ø–æ—Ä–æ–≥–æ–≤
                    candidate = complete if not self._pending_segment else f"{self._pending_segment}{self.sentence_joiner}{complete}"
                    words_count = await self._count_meaningful_words(candidate)
                    logger.info(f"üìù –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–µ–≥–º–µ–Ω—Ç–∞: candidate_len={len(candidate)}, words={words_count}, has_emitted={self._has_emitted}, min_words={self.stream_min_words if self._has_emitted else self.stream_first_sentence_min_words}, min_chars={self.stream_min_chars}")
                    if (not self._has_emitted and (words_count >= self.stream_first_sentence_min_words or len(candidate) >= self.stream_min_chars)) or \
                       (self._has_emitted and (words_count >= self.stream_min_words or len(candidate) >= self.stream_min_chars)):
                        # –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è —Ñ–∏–Ω–∞–ª—å–Ω—ã—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤ (—Ç–æ–ª—å–∫–æ –¥–ª—è –æ—á–µ–Ω—å –∫–æ—Ä–æ—Ç–∫–∏—Ö –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏–π)
                        to_emit = candidate.strip()
                        if len(to_emit) > 10:  # –¢–æ–ª—å–∫–æ –¥–ª—è –¥–ª–∏–Ω–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤ –ø—Ä–∏–º–µ–Ω—è–µ–º –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—é
                            complete_hash = hash(to_emit)
                            if complete_hash in self._processed_sentences:
                                logger.debug(f"üîÑ –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Å–µ–≥–º–µ–Ω—Ç: '{to_emit[:50]}...'")
                                continue
                            self._processed_sentences.add(complete_hash)
                        
                        # –ì–æ—Ç–æ–≤ –∫ —ç–º–∏—Å—Å–∏–∏
                        emitted_segment_counter += 1
                        self._pending_segment = ""
                        self._has_emitted = True

                        # –¢–µ–∫—Å—Ç
                        captured_segments.append(to_emit)
                        yield {
                            'success': True,
                            'text_response': to_emit,
                            'sentence_index': emitted_segment_counter
                        }

                        # –ê—É–¥–∏–æ (–≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º –∑–∞–≤–µ—Ä—à–∞—é—â—É—é –ø—É–Ω–∫—Ç—É–∞—Ü–∏—é –¥–ª—è TTS)
                        # –§–∞–∑–∞ 2: –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∞—É–¥–∏–æ-–≥–µ–Ω–µ—Ä–∞—Ü–∏—é, –µ—Å–ª–∏ text –ø—É—Å—Ç–æ–π
                        if to_emit.strip():
                            tts_text = to_emit if to_emit.endswith(self.end_punctuations) else f"{to_emit}."
                            sentence_audio_chunks = 0
                            async for audio_chunk in self._stream_audio_for_sentence(tts_text, emitted_segment_counter):
                                if not audio_chunk:
                                    continue
                                sentence_audio_chunks += 1
                                total_audio_chunks += 1
                                total_audio_bytes += len(audio_chunk)
                                yield {
                                    'success': True,
                                    'audio_chunk': audio_chunk,
                                    'sentence_index': emitted_segment_counter,
                                    'audio_chunk_index': sentence_audio_chunks
                                }
                            sentence_audio_map[emitted_segment_counter] = sentence_audio_chunks
                            logger.info(
                                f"üéß Segment #{emitted_segment_counter} ‚Üí audio_chunks={sentence_audio_chunks}, total_audio_chunks={total_audio_chunks}, total_bytes={total_audio_bytes}"
                            )
                        else:
                            # –ü—É—Å—Ç–æ–π —Ç–µ–∫—Å—Ç - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –∞—É–¥–∏–æ
                            logger.debug(f"‚è≠Ô∏è –ü—Ä–æ–ø—É—Å–∫ –∞—É–¥–∏–æ –¥–ª—è –ø—É—Å—Ç–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –≤ segment #{emitted_segment_counter}")
                    else:
                        # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –∫–æ–ø–∏—Ç—å
                        logger.debug(f"üìù –°–µ–≥–º–µ–Ω—Ç –Ω–µ –ø—Ä–æ—à—ë–ª –ø—Ä–æ–≤–µ—Ä–∫—É, –∫–æ–ø–∏–º –¥–∞–ª—å—à–µ: candidate_len={len(candidate)}, words={words_count}")
                        self._pending_segment = candidate

            # –§–∏–Ω–∞–ª—å–Ω—ã–π —Ñ–ª–∞—à: –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ—Å—Ç–∞–≤—à–∏–π—Å—è JSON –±—É—Ñ–µ—Ä, –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å
            if self._json_buffer and not self._json_parsed:
                import json
                is_potential_json = self._json_buffer.strip().startswith('{')
                if is_potential_json:
                    try:
                        parsed_json = json.loads(self._json_buffer.strip())
                        logger.info(f"‚úÖ –§–∏–Ω–∞–ª—å–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ JSON –±—É—Ñ–µ—Ä–∞: {len(self._json_buffer)} —Å–∏–º–≤–æ–ª–æ–≤")
                        parsed = await self._parse_assistant_response(parsed_json, session_id)
                        if parsed.command_payload and not self._command_payload_sent:
                            self._pending_command_payload = parsed.command_payload
                            self._log_command_detected(parsed, session_id)
                        # –î–æ–±–∞–≤–ª—è–µ–º text_response –≤ stream_buffer –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
                        if parsed.text_response:
                            self._stream_buffer = (f"{self._stream_buffer}{self.sentence_joiner}{parsed.text_response}" if self._stream_buffer else parsed.text_response)
                        self._json_buffer = ""
                        self._json_parsed = False
                    except (json.JSONDecodeError, ValueError):
                        # JSON –Ω–µ –≤–∞–ª–∏–¥–µ–Ω - –≤–æ–∑–º–æ–∂–Ω–æ, —ç—Ç–æ –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç
                        logger.debug(f"‚ö†Ô∏è JSON –±—É—Ñ–µ—Ä –Ω–µ –≤–∞–ª–∏–¥–µ–Ω, –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∫ –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç: {len(self._json_buffer)} —Å–∏–º–≤–æ–ª–æ–≤")
                        if self._json_buffer.strip():
                            # –ï—Å–ª–∏ –±—É—Ñ–µ—Ä –Ω–µ –ø—É—Å—Ç–æ–π –∏ –Ω–µ JSON - –¥–æ–±–∞–≤–ª—è–µ–º –∫–∞–∫ –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç
                            parsed = await self._parse_assistant_response(self._json_buffer, session_id)
                            if parsed.text_response:
                                self._stream_buffer = (f"{self._stream_buffer}{self.sentence_joiner}{parsed.text_response}" if self._stream_buffer else parsed.text_response)
                        self._json_buffer = ""
                else:
                    # –≠—Ç–æ –Ω–µ JSON - –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∫ –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç
                    logger.debug(f"üìù –§–∏–Ω–∞–ª—å–Ω—ã–π –±—É—Ñ–µ—Ä - –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç: {len(self._json_buffer)} —Å–∏–º–≤–æ–ª–æ–≤")
                    if self._json_buffer.strip():
                        parsed = await self._parse_assistant_response(self._json_buffer, session_id)
                        if parsed.text_response:
                            self._stream_buffer = (f"{self._stream_buffer}{self.sentence_joiner}{parsed.text_response}" if self._stream_buffer else parsed.text_response)
                    self._json_buffer = ""
            
            # –§–∏–Ω–∞–ª—å–Ω—ã–π —Ñ–ª–∞—à: —Å–Ω–∞—á–∞–ª–∞ –æ–±—Ä–∞–±–æ—Ç–∞–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∏–∑ –±—É—Ñ–µ—Ä–∞
            if self._stream_buffer:
                logger.info(f"üìù –§–∏–Ω–∞–ª—å–Ω—ã–π —Ñ–ª–∞—à: stream_buffer_len={len(self._stream_buffer)}, content='{self._stream_buffer[:100]}{'...' if len(self._stream_buffer) > 100 else ''}'")
                complete_sentences, remainder = await self._split_complete_sentences(self._stream_buffer)
                logger.info(f"üìù –§–∏–Ω–∞–ª—å–Ω—ã–π _split_complete_sentences: complete={len(complete_sentences)}, remainder_len={len(remainder) if remainder else 0}")
                self._stream_buffer = remainder
                for complete in complete_sentences:
                    candidate = complete if not self._pending_segment else f"{self._pending_segment}{self.sentence_joiner}{complete}"
                    words_count = await self._count_meaningful_words(candidate)
                    logger.info(f"üìù –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å–µ–≥–º–µ–Ω—Ç–∞: candidate_len={len(candidate)}, words={words_count}, has_emitted={self._has_emitted}")
                    if (not self._has_emitted and (words_count >= self.stream_first_sentence_min_words or len(candidate) >= self.stream_min_chars)) or \
                       (self._has_emitted and (words_count >= self.stream_min_words or len(candidate) >= self.stream_min_chars)):
                        emitted_segment_counter += 1
                        to_emit = candidate.strip()
                        self._pending_segment = ""
                        self._has_emitted = True
                        captured_segments.append(to_emit)
                        yield {'success': True, 'text_response': to_emit, 'sentence_index': emitted_segment_counter}
                        # –§–∞–∑–∞ 2: –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∞—É–¥–∏–æ-–≥–µ–Ω–µ—Ä–∞—Ü–∏—é, –µ—Å–ª–∏ text –ø—É—Å—Ç–æ–π
                        if to_emit.strip():
                            tts_text = to_emit if to_emit.endswith(self.end_punctuations) else f"{to_emit}."
                            sentence_audio_chunks = 0
                            async for audio_chunk in self._stream_audio_for_sentence(tts_text, emitted_segment_counter):
                                if not audio_chunk:
                                    continue
                                sentence_audio_chunks += 1
                                total_audio_chunks += 1
                                total_audio_bytes += len(audio_chunk)
                                yield {'success': True, 'audio_chunk': audio_chunk, 'sentence_index': emitted_segment_counter, 'audio_chunk_index': sentence_audio_chunks}
                            sentence_audio_map[emitted_segment_counter] = sentence_audio_chunks
                            logger.info(f"üéß Final segment #{emitted_segment_counter} ‚Üí audio_chunks={sentence_audio_chunks}, total_audio_chunks={total_audio_chunks}, total_bytes={total_audio_bytes}")
                        else:
                            logger.debug(f"‚è≠Ô∏è –ü—Ä–æ–ø—É—Å–∫ –∞—É–¥–∏–æ –¥–ª—è –ø—É—Å—Ç–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –≤ final segment #{emitted_segment_counter}")
                    else:
                        self._pending_segment = candidate

            # –ï—Å–ª–∏ –æ—Å—Ç–∞–ª—Å—è –Ω–µ–∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã–π –∞–≥—Ä–µ–≥–∞—Ç –∏–ª–∏ –æ—Å—Ç–∞—Ç–æ–∫ –≤ stream_buffer, —Ñ–æ—Ä—Å-—Ñ–ª–∞—à –µ—Å–ª–∏ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª–∏–Ω–Ω—ã–π
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ—Å—Ç–∞—Ç–æ–∫ –∏–∑ stream_buffer, –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å
            if self._stream_buffer and self._stream_buffer.strip():
                logger.info(f"üìù –û—Å—Ç–∞—Ç–æ–∫ –≤ stream_buffer –ø–æ—Å–ª–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Ñ–ª–∞—à–∞: len={len(self._stream_buffer)}, content='{self._stream_buffer[:100]}{'...' if len(self._stream_buffer) > 100 else ''}'")
                # –î–æ–±–∞–≤–ª—è–µ–º –æ—Å—Ç–∞—Ç–æ–∫ –∫ pending_segment, –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å
                if self._pending_segment:
                    self._pending_segment = f"{self._pending_segment}{self.sentence_joiner}{self._stream_buffer}"
                else:
                    self._pending_segment = self._stream_buffer
                self._stream_buffer = ""
            
            # –ï—Å–ª–∏ –æ—Å—Ç–∞–ª—Å—è –Ω–µ–∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã–π –∞–≥—Ä–µ–≥–∞—Ç, –º–æ–∂–Ω–æ —Ñ–æ—Ä—Å-—Ñ–ª–∞—à, –µ—Å–ª–∏ –æ—á–µ–Ω—å –¥–ª–∏–Ω–Ω—ã–π
            force_max = self.force_flush_max_chars
            logger.info(f"üìù –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–æ—Ä—Å-—Ñ–ª–∞—à–∞: pending_segment_len={len(self._pending_segment) if self._pending_segment else 0}, force_max={force_max}")
            # –ï—Å–ª–∏ force_max=0, –Ω–æ –µ—Å—Ç—å pending_segment –∏ –æ–Ω –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª–∏–Ω–Ω—ã–π, –≤—Å—ë —Ä–∞–≤–Ω–æ —ç–º–∏—Ç–∏–º
            if self._pending_segment and len(self._pending_segment.strip()) > 0:
                # –ï—Å–ª–∏ force_max > 0, –ø—Ä–æ–≤–µ—Ä—è–µ–º –¥–ª–∏–Ω—É, –∏–Ω–∞—á–µ —ç–º–∏—Ç–∏–º –≤—Å–µ–≥–¥–∞ (–µ—Å–ª–∏ –µ—Å—Ç—å —Ç–µ–∫—Å—Ç)
                if force_max == 0 or len(self._pending_segment) >= force_max:
                    logger.info(f"üìù –§–æ—Ä—Å-—Ñ–ª–∞—à pending_segment: len={len(self._pending_segment)}, force_max={force_max}")
                    emitted_segment_counter += 1
                    to_emit = self._pending_segment
                    self._pending_segment = ""
                    self._has_emitted = True
                    captured_segments.append(to_emit)
                    yield {'success': True, 'text_response': to_emit, 'sentence_index': emitted_segment_counter}
                    # –§–∞–∑–∞ 2: –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∞—É–¥–∏–æ-–≥–µ–Ω–µ—Ä–∞—Ü–∏—é, –µ—Å–ª–∏ text –ø—É—Å—Ç–æ–π
                    if to_emit.strip():
                        tts_text = to_emit if to_emit.endswith(self.end_punctuations) else f"{to_emit}."
                        sentence_audio_chunks = 0
                        async for audio_chunk in self._stream_audio_for_sentence(tts_text, emitted_segment_counter):
                            if not audio_chunk:
                                continue
                            sentence_audio_chunks += 1
                            total_audio_chunks += 1
                            total_audio_bytes += len(audio_chunk)
                            yield {'success': True, 'audio_chunk': audio_chunk, 'sentence_index': emitted_segment_counter, 'audio_chunk_index': sentence_audio_chunks}
                        sentence_audio_map[emitted_segment_counter] = sentence_audio_chunks
                        logger.info(f"üéß Forced final segment #{emitted_segment_counter} ‚Üí audio_chunks={sentence_audio_chunks}, total_audio_chunks={total_audio_chunks}, total_bytes={total_audio_bytes}")
                    else:
                        logger.debug(f"‚è≠Ô∏è –ü—Ä–æ–ø—É—Å–∫ –∞—É–¥–∏–æ –¥–ª—è –ø—É—Å—Ç–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –≤ forced segment #{emitted_segment_counter}")
                else:
                    logger.debug(f"üìù pending_segment –Ω–µ –ø—Ä–æ—à—ë–ª –ø—Ä–æ–≤–µ—Ä–∫—É —Ñ–æ—Ä—Å-—Ñ–ª–∞—à–∞: len={len(self._pending_segment)}, force_max={force_max}")

            full_text = " ".join(captured_segments).strip()

            # –§–∞–∑–∞ 2: –û—Ç–ø—Ä–∞–≤–ª—è–µ–º command_payload –æ–¥–∏–Ω —Ä–∞–∑ –≤ —Ñ–∏–Ω–∞–ª—å–Ω–æ–º –æ—Ç–≤–µ—Ç–µ
            final_result = {
                'success': True,
                'text_full_response': full_text,
                'sentences_processed': emitted_segment_counter,
                'audio_chunks_processed': total_audio_chunks,
                'audio_bytes_processed': total_audio_bytes,
                'sentence_audio_map': sentence_audio_map,
                'is_final': True
            }
            
            # –î–æ–±–∞–≤–ª—è–µ–º command_payload, –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å –∏ —Ñ–∏—á–∞-—Ñ–ª–∞–≥ –≤–∫–ª—é—á–µ–Ω
            if self._pending_command_payload and not self._command_payload_sent:
                config = get_config()
                if (config.features.forward_assistant_actions and 
                    not config.kill_switches.disable_forward_assistant_actions):
                    final_result['command_payload'] = self._pending_command_payload
                    self._command_payload_sent = True
                    self._log_command_complete(session_id)
                else:
                    logger.debug("–§–∏—á–∞-—Ñ–ª–∞–≥ forward_assistant_actions –≤—ã–∫–ª—é—á–µ–Ω –∏–ª–∏ kill-switch –∞–∫—Ç–∏–≤–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º command_payload")

            logger.info(
                f"‚úÖ –ó–∞–ø—Ä–æ—Å –æ–±—Ä–∞–±–æ—Ç–∞–Ω —É—Å–ø–µ—à–Ω–æ: segments={emitted_segment_counter}, audio_chunks={total_audio_chunks}, total_bytes={total_audio_bytes}"
            )
            yield final_result

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–∞ {session_id}: {e}")
            yield {
                'success': False,
                'error': str(e),
                'text_response': '',
            }

    async def _get_memory_context_parallel(self, hardware_id: str) -> Optional[Dict[str, Any]]:
        """
        –ù–µ–±–ª–æ–∫–∏—Ä—É—é—â–µ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø–∞–º—è—Ç–∏
        
        Args:
            hardware_id: –ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è
        """
        try:
            if not self.memory_workflow:
                logger.debug("MemoryWorkflow –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –ø–æ–ª—É—á–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏")
                return None
            
            logger.debug(f"–ü–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø–∞–º—è—Ç–∏ –¥–ª—è {hardware_id}")
            memory_context = await self.memory_workflow.get_memory_context_parallel(hardware_id)
            
            if memory_context:
                logger.debug(f"‚úÖ –ü–æ–ª—É—á–µ–Ω –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø–∞–º—è—Ç–∏: {len(memory_context)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤")
            else:
                logger.debug("‚ö†Ô∏è –ö–æ–Ω—Ç–µ–∫—Å—Ç –ø–∞–º—è—Ç–∏ –ø—É—Å—Ç")
            
            return memory_context
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø–∞–º—è—Ç–∏: {e}")
            return None

    async def _iter_processed_sentences(
        self,
        text: str,
        screenshot: Optional[str],
        memory_context: Optional[Dict[str, Any]]
    ) -> AsyncGenerator[str, None]:
        """–°—Ç—Ä–∏–º–∏–Ω–≥–æ–≤–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è —Å —É—á—ë—Ç–æ–º –ø–∞–º—è—Ç–∏ –∏ —Å–∫—Ä–∏–Ω—à–æ—Ç–∞."""
        enriched_text = self._enrich_with_memory(text, memory_context)

        screenshot_data: Optional[bytes] = None
        if screenshot:
            import base64
            try:
                screenshot_data = base64.b64decode(screenshot)
                logger.info(f"üì∏ –°–∫—Ä–∏–Ω—à–æ—Ç –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω: {len(screenshot_data)} bytes")
            except Exception as decode_error:
                logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞—Ç—å —Å–∫—Ä–∏–Ω—à–æ—Ç: {decode_error}")
                screenshot_data = None

        yielded_any = False
        if self.text_module and hasattr(self.text_module, 'process'):
            logger.info(f"üîÑ –°—Ç—Ä–∏–º–∏–Ω–≥ —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ Text Module: '{enriched_text[:80]}...'")
            try:
                async for chunk in self._stream_text_module(enriched_text, screenshot_data):
                    sentence = (self._extract_text_chunk(chunk) or '').strip()
                    if sentence:
                        yielded_any = True
                        logger.debug(f"üì® TextModule sentence: '{sentence[:120]}...'")
                        yield sentence
            except Exception as processing_error:
                logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ Text Module: {processing_error}. –ò—Å–ø–æ–ª—å–∑—É–µ–º fallback")
        elif self.text_module and hasattr(self.text_module, 'process_text_streaming'):
            # Legacy fallback –Ω–∞ –ø—Ä—è–º–æ–π –¥–æ—Å—Ç—É–ø –∫ TextProcessor
            logger.info(f"üîÑ Legacy —Å—Ç—Ä–∏–º–∏–Ω–≥ —Ç–µ–∫—Å—Ç–∞: '{enriched_text[:80]}...'")
            try:
                async for processed_sentence in self.text_module.process_text_streaming(enriched_text, screenshot_data):
                    sentence = (processed_sentence or '').strip()
                    if sentence:
                        yielded_any = True
                        logger.debug(f"üì® Legacy TextProcessor sentence: '{sentence[:120]}...'")
                        yield sentence
            except Exception as processing_error:
                logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ legacy TextProcessor: {processing_error}. –ò—Å–ø–æ–ª—å–∑—É–µ–º fallback")

        if not yielded_any:
            logger.debug("‚ö†Ô∏è TextProcessor –Ω–µ –≤–µ—Ä–Ω—É–ª –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π, –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback —Ä–∞–∑–±–∏–≤–∫—É")
            for fallback_sentence in self._split_into_sentences(enriched_text):
                if fallback_sentence:
                    yield fallback_sentence

    async def _sanitize_for_tts(self, text: str) -> str:
        """
        –û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è —Å–∏–Ω—Ç–µ–∑–∞ —Ä–µ—á–∏ —á–µ—Ä–µ–∑ –º–æ–¥—É–ª—å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        """
        if not text:
            return ""

        if self.text_filter_module and hasattr(self.text_filter_module, 'process'):
            try:
                result = await self.text_filter_module.process({
                    "operation": "clean_text",
                    "text": text,
                    "options": {
                        "remove_special_chars": True,
                        "remove_extra_whitespace": True,
                        "normalize_unicode": True,
                        "remove_control_chars": True
                    }
                })
                if isinstance(result, dict) and result.get("success") and result.get("cleaned_text") is not None:
                    return result.get("cleaned_text", "").strip()
            except Exception as err:
                logger.warning("‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ TextFilterModule: %s", err)

        return text.strip()

    async def _split_complete_sentences(self, text: str) -> tuple[list[str], str]:
        """
        –†–∞–∑–±–∏–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è —á–µ—Ä–µ–∑ –º–æ–¥—É–ª—å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        """
        if not text:
            return [], ""

        if self.text_filter_module and hasattr(self.text_filter_module, 'process'):
            try:
                result = await self.text_filter_module.process({
                    "operation": "split_sentences",
                    "text": text
                })
                if isinstance(result, dict) and result.get("success"):
                    return result.get("sentences", []), result.get("remainder", "")
            except Exception as err:
                logger.warning("‚ö†Ô∏è –û—à–∏–±–∫–∞ —Ä–∞–∑–±–∏–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ TextFilterModule: %s", err)

        stripped = text.strip()
        return ([stripped] if stripped else [], "")

    async def _count_meaningful_words(self, text: str) -> int:
        """
        –ü–æ–¥—Å—á—ë—Ç –∑–Ω–∞—á–∏–º—ã—Ö —Å–ª–æ–≤ —á–µ—Ä–µ–∑ –º–æ–¥—É–ª—å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        """
        if not text:
            return 0

        if self.text_filter_module and hasattr(self.text_filter_module, 'process'):
            try:
                result = await self.text_filter_module.process({
                    "operation": "count_meaningful_words",
                    "text": text
                })
                if isinstance(result, dict) and result.get("success"):
                    return int(result.get("count", 0))
            except Exception as err:
                logger.warning("‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–¥—Å—á—ë—Ç–∞ —Å–ª–æ–≤ —á–µ—Ä–µ–∑ TextFilterModule: %s", err)

        return len([w for w in text.split() if w.strip()])

    async def _stream_text_module(self, text: str, screenshot_data: Optional[bytes]):
        """–°—Ç—Ä–∏–º–∏–Ω–≥ –æ—Ç–≤–µ—Ç–æ–≤ –∏–∑ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –º–æ–¥—É–ª—è."""
        payload = {"text": text}
        if screenshot_data:
            payload["image_data"] = screenshot_data

        async for chunk in self._stream_module_results(self.text_module, payload):
            yield chunk

    async def _stream_audio_module(self, text: str):
        """–°—Ç—Ä–∏–º–∏–Ω–≥ –∞—É–¥–∏–æ —á–∞–Ω–∫–æ–≤ –∏–∑ –∞—É–¥–∏–æ –º–æ–¥—É–ª—è."""
        async for chunk in self._stream_module_results(self.audio_module, {"text": text}):
            yield chunk

    async def _stream_module_results(self, module, payload: Dict[str, Any]):
        """–£–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≤—ã–∑–æ–≤ module.process —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π async generator."""
        if not module or not hasattr(module, 'process'):
            return
        try:
            result = await module.process(payload)
            if result is None:
                return
            if hasattr(result, "__aiter__"):
                async for item in result:
                    yield item
            else:
                yield result
        except Exception as err:
            logger.warning("‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ –º–æ–¥—É–ª—è %s: %s", getattr(module, 'name', 'unknown'), err)

    def _extract_text_chunk(self, chunk: Any) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç–≤–µ—Ç –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –º–æ–¥—É–ª—è."""
        if chunk is None:
            return ""
        if isinstance(chunk, str):
            return chunk
        if isinstance(chunk, dict):
            for key in ("text", "text_response", "value", "chunk"):
                value = chunk.get(key)
                if isinstance(value, str):
                    return value
        return ""

    def _extract_audio_chunk(self, chunk: Any) -> bytes:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∞—É–¥–∏–æ –±–∞–π—Ç—ã –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –º–æ–¥—É–ª—è."""
        if chunk is None:
            return b""
        if isinstance(chunk, (bytes, bytearray)):
            return bytes(chunk)
        if isinstance(chunk, dict):
            for key in ("audio", "audio_chunk", "data", "value"):
                value = chunk.get(key)
                if isinstance(value, (bytes, bytearray)):
                    return bytes(value)
        return b""

    def _enrich_with_memory(self, text: str, memory_context: Optional[Dict[str, Any]]) -> str:
        """
        –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –ø–∞–º—è—Ç–∏
        
        Args:
            text: –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç
            memory_context: –ö–æ–Ω—Ç–µ–∫—Å—Ç –ø–∞–º—è—Ç–∏
        """
        if not memory_context:
            return text
        
        try:
            memory_info = memory_context.get('recent_context', '') if memory_context else ''
            if memory_info:
                enriched_text = f"–ö–æ–Ω—Ç–µ–∫—Å—Ç: {memory_info}\n\n{text}"
                logger.debug("–¢–µ–∫—Å—Ç –æ–±–æ–≥–∞—â–µ–Ω –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –ø–∞–º—è—Ç–∏")
                return enriched_text
            return text
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–±–æ–≥–∞—â–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –ø–∞–º—è—Ç—å—é: {e}")
            return text

    async def _stream_audio_for_sentence(self, sentence: str, sentence_index: int) -> AsyncGenerator[bytes, None]:
        """–°—Ç—Ä–∏–º–∏—Ç –∞—É–¥–∏–æ —á–∞–Ω–∫–∏ –¥–ª—è –æ–¥–Ω–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è."""
        if not sentence.strip():
            return
        if not self.audio_module:
            logger.warning("‚ö†Ô∏è AudioProcessor –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –∞—É–¥–∏–æ")
            return
        if hasattr(self.audio_module, 'process'):
            try:
                logger.info(f"üîä –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∞—É–¥–∏–æ –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è #{sentence_index}: '{sentence[:80]}...'")
                chunk_count = 0
                async for chunk in self._stream_audio_module(sentence):
                    audio_chunk = self._extract_audio_chunk(chunk)
                    if audio_chunk:
                        chunk_count += 1
                        logger.info(f"üîä Audio chunk #{chunk_count} –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è #{sentence_index}: {len(audio_chunk)} bytes")
                        yield audio_chunk
                logger.info(f"‚úÖ –ê—É–¥–∏–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è #{sentence_index}: {chunk_count} —á–∞–Ω–∫–æ–≤")
            except Exception as audio_error:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∞—É–¥–∏–æ –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è #{sentence_index}: {audio_error}")
        elif hasattr(self.audio_module, 'generate_speech_streaming'):
            # Legacy fallback
            try:
                logger.info(f"üîä Legacy –∞—É–¥–∏–æ –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è #{sentence_index}: '{sentence[:80]}...'")
                chunk_count = 0
                async for audio_chunk in self.audio_module.generate_speech_streaming(sentence):
                    if audio_chunk:
                        chunk_count += 1
                        logger.info(f"üîä Audio chunk #{chunk_count} –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è #{sentence_index}: {len(audio_chunk)} bytes")
                        yield audio_chunk
                logger.info(f"‚úÖ Legacy –∞—É–¥–∏–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è #{sentence_index}: {chunk_count} —á–∞–Ω–∫–æ–≤")
            except Exception as audio_error:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ legacy –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∞—É–¥–∏–æ –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è #{sentence_index}: {audio_error}")
    
    async def _parse_assistant_response(self, response: Union[str, Dict[str, Any]], session_id: str):
        """
        –ü–∞—Ä—Å–∏–Ω–≥ –æ—Ç–≤–µ—Ç–∞ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è text –∏ command_payload (–§–∞–∑–∞ 2)
        
        Args:
            response: –û—Ç–≤–µ—Ç –æ—Ç —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –º–æ–¥—É–ª—è (—Å—Ç—Ä–æ–∫–∞ –∏–ª–∏ —Å–ª–æ–≤–∞—Ä—å)
            session_id: ID —Å–µ—Å—Å–∏–∏ –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
            
        Returns:
            ParsedResponse —Å text_response –∏ –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–º command_payload
        """
        try:
            config = get_config()
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–∏—á–∞-—Ñ–ª–∞–≥ –∏ kill-switch
            if (not config.features.forward_assistant_actions or 
                config.kill_switches.disable_forward_assistant_actions):
                # –§–∏—á–∞ –≤—ã–∫–ª—é—á–µ–Ω–∞ - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç
                if isinstance(response, dict):
                    return self._assistant_parser.parse(response.get('text', str(response)))
                return self._assistant_parser.parse(response)
            
            # –ü–∞—Ä—Å–∏–º –æ—Ç–≤–µ—Ç
            return self._assistant_parser.parse(response)
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ—Ç–≤–µ—Ç–∞ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞: {e}, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç")
            # Fallback –Ω–∞ –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç
            if isinstance(response, dict):
                text = response.get('text', str(response))
            else:
                text = str(response)
            return self._assistant_parser.parse(text)
    
    def _log_command_detected(self, parsed, session_id: str):
        """
        –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –∫–æ–º–∞–Ω–¥—ã (–§–∞–∑–∞ 2)
        
        Args:
            parsed: ParsedResponse —Å command_payload
            session_id: ID —Å–µ—Å—Å–∏–∏
        """
        if not parsed.command_payload:
            return
        
        payload = parsed.command_payload.get('payload', {})
        command = payload.get('command', 'unknown')
        args = payload.get('args', {})
        
        log_structured(
            logger,
            logging.INFO,
            f"Command detected: {command}",
            scope="command",
            method="parse_assistant_response",
            decision="start",
            ctx={
                "session_id": session_id,
                "command": command,
                "args": args
            }
        )
    
    def _log_command_complete(self, session_id: str):
        """
        –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ–≥–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∫–æ–º–∞–Ω–¥—ã (–§–∞–∑–∞ 2)
        
        Args:
            session_id: ID —Å–µ—Å—Å–∏–∏
        """
        if not self._pending_command_payload:
            return
        
        payload = self._pending_command_payload.get('payload', {})
        command = payload.get('command', 'unknown')
        
        log_structured(
            logger,
            logging.INFO,
            f"Command forwarded: {command}",
            scope="command",
            method="process_request_streaming",
            decision="complete",
            ctx={
                "session_id": session_id,
                "command": command
            }
        )
    
    def _split_into_sentences(self, text: str) -> list[str]:
        """
        –†–∞–∑–±–∏–≤–∫–∞ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
        
        Args:
            text: –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç
            
        Returns:
            –°–ø–∏—Å–æ–∫ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
        """
        try:
            # –ü—Ä–æ—Å—Ç–∞—è —Ä–∞–∑–±–∏–≤–∫–∞ –ø–æ —Ç–æ—á–∫–∞–º, –≤–æ—Å–∫–ª–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–º –∏ –≤–æ–ø—Ä–æ—Å–∏—Ç–µ–ª—å–Ω—ã–º –∑–Ω–∞–∫–∞–º
            import re
            sentences = re.split(r'[.!?]+', text)
            
            # –û—á–∏—â–∞–µ–º –æ—Ç –ø—É—Å—Ç—ã—Ö —Å—Ç—Ä–æ–∫ –∏ –ª–∏—à–Ω–∏—Ö –ø—Ä–æ–±–µ–ª–æ–≤
            clean_sentences = [s.strip() for s in sentences if s.strip()]
            
            logger.debug(f"–¢–µ–∫—Å—Ç —Ä–∞–∑–±–∏—Ç –Ω–∞ {len(clean_sentences)} –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π")
            return clean_sentences
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Ä–∞–∑–±–∏–≤–∫–∏ —Ç–µ–∫—Å—Ç–∞: {e}")
            return [text]  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –≤–µ—Å—å —Ç–µ–∫—Å—Ç –∫–∞–∫ –æ–¥–Ω–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ
    
    async def cleanup(self):
        """–û—á–∏—Å—Ç–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤"""
        try:
            logger.info("–û—á–∏—Å—Ç–∫–∞ StreamingWorkflowIntegration...")
            self.is_initialized = False
            logger.info("‚úÖ StreamingWorkflowIntegration –æ—á–∏—â–µ–Ω")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ StreamingWorkflowIntegration: {e}")
