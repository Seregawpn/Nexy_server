#!/usr/bin/env python3
"""
StreamingWorkflowIntegration - —É–ø—Ä–∞–≤–ª—è–µ—Ç –ø–æ—Ç–æ–∫–æ–º: —Ç–µ–∫—Å—Ç ‚Üí –∞—É–¥–∏–æ ‚Üí –∫–ª–∏–µ–Ω—Ç
"""

import logging
import asyncio
from typing import Dict, Any, AsyncGenerator, Optional, Union
from datetime import datetime

from config.unified_config import WorkflowConfig, get_config
from integrations.core.assistant_response_parser import AssistantResponseParser
from utils.logging_formatter import log_structured

# MVP 7: Subscription Module
try:
    from modules.subscription.core.subscription_module import SubscriptionModule
    SUBSCRIPTION_MODULE_AVAILABLE = True
except ImportError as e:
    logger.warning(f"[MVP7] SubscriptionModule not available: {e}")
    SUBSCRIPTION_MODULE_AVAILABLE = False
    SubscriptionModule = None

logger = logging.getLogger(__name__)


class StreamingWorkflowIntegration:
    """
    –£–ø—Ä–∞–≤–ª—è–µ—Ç –ø–æ—Ç–æ–∫–æ–º –æ–±—Ä–∞–±–æ—Ç–∫–∏: –ø–æ–ª—É—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ ‚Üí –æ–±—Ä–∞–±–æ—Ç–∫–∞ ‚Üí –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∞—É–¥–∏–æ ‚Üí —Å—Ç—Ä–∏–º–∏–Ω–≥ –∫–ª–∏–µ–Ω—Ç—É
    """
    
    def __init__(
        self,
        text_processor=None,
        audio_processor=None,
        memory_workflow=None,
        text_filter_manager=None,
        workflow_config: Optional[Union[WorkflowConfig, Dict[str, Any]]] = None,
        coordinator=None,
    ):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è StreamingWorkflowIntegration
        
        Args:
            text_processor: –ú–æ–¥—É–ª—å –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞ (UniversalModuleInterface)
            audio_processor: –ú–æ–¥—É–ª—å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∞—É–¥–∏–æ (UniversalModuleInterface)
            memory_workflow: Workflow –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –ø–∞–º—è—Ç—å—é
            text_filter_manager: –ú–æ–¥—É–ª—å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞ (UniversalModuleInterface)
            coordinator: ModuleCoordinator –¥–ª—è –¥–æ—Å—Ç—É–ø–∞ –∫ –º–æ–¥—É–ª—è–º (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        """
        # –£–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–æ–¥—É–ª–∏ (–Ω–∞–∑–≤–∞–Ω–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –æ—Å—Ç–∞–≤–ª–µ–Ω—ã –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)
        self.text_module = text_processor
        self.audio_module = audio_processor
        self.memory_workflow = memory_workflow
        self.text_filter_module = text_filter_manager
        self.coordinator = coordinator  # –î–ª—è –¥–æ—Å—Ç—É–ø–∞ –∫ browser_use –º–æ–¥—É–ª—é
        self.is_initialized = False
        
        # MVP 7: Subscription Module
        self.subscription_module = None
        if SUBSCRIPTION_MODULE_AVAILABLE:
            try:
                import os
                db_url = os.getenv('DATABASE_URL')
                if db_url:
                    self.subscription_module = SubscriptionModule(db_url)
                    logger.info("[MVP7] SubscriptionModule initialized")
                else:
                    logger.warning("[MVP7] DATABASE_URL not set, subscription features disabled")
            except Exception as e:
                logger.warning(f"[MVP7] Failed to initialize SubscriptionModule: {e}")
        
        # –ï–¥–∏–Ω–∞—è –Ω–µ–±–ª–æ–∫–∏—Ä—É—é—â–∞—è –±—É—Ñ–µ—Ä–∏–∑–∞—Ü–∏—è –∏ –∫—Ä–∏—Ç–µ—Ä–∏–∏ —Ñ–ª–∞—à–∏–Ω–≥–∞ (–¥–ª—è —Ç–µ–∫—Å—Ç–∞ –∏ TTS –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ)
        self._stream_buffer: str = ""
        self._has_emitted: bool = False
        self._pending_segment: str = ""
        self._processed_sentences: set = set()  # –î–ª—è –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏
        
        # MCP command payload (–§–∞–∑–∞ 2)
        self._pending_command_payload: Optional[Dict[str, Any]] = None
        self._command_payload_sent: bool = False
        self._assistant_parser = AssistantResponseParser()
        # –ë—É—Ñ–µ—Ä –¥–ª—è –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è JSON –æ—Ç–≤–µ—Ç–æ–≤ –æ—Ç LLM
        self._json_buffer: str = ""
        self._json_parsed: bool = False
        
        # ‚ö†Ô∏è NEW: –û—á–µ—Ä–µ–¥—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ MCP –ø–æ session_id –¥–ª—è –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
        # –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è Messages –∫–æ–º–∞–Ω–¥ (read_messages, send_message), –∫–æ—Ç–æ—Ä—ã–µ –≤—ã–ø–æ–ª–Ω—è—é—Ç—Å—è –Ω–∞ –∫–ª–∏–µ–Ω—Ç–µ
        # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–æ–±–∞–≤–ª—è—é—Ç—Å—è —á–µ—Ä–µ–∑ process_mcp_result() –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç—Å—è –ø–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –ø–æ—Ç–æ–∫–∞
        self._mcp_result_queues: Dict[str, asyncio.Queue] = {}
        self._pending_mcp_results: Dict[str, bool] = {}  # –§–ª–∞–≥ –æ–∂–∏–¥–∞–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –¥–ª—è session_id
        
        # –¶–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –ø–æ—Ä–æ–≥–∏
        if workflow_config is None:
            workflow_config = get_config().get_workflow_thresholds()

        if isinstance(workflow_config, WorkflowConfig):
            cfg = workflow_config
        else:
            cfg = WorkflowConfig(**workflow_config)

        self.stream_min_chars: int = cfg.stream_min_chars
        self.stream_min_words: int = cfg.stream_min_words
        self.stream_first_sentence_min_words: int = cfg.stream_first_sentence_min_words
        self.stream_punct_flush_strict: bool = bool(cfg.stream_punct_flush_strict)
        self.force_flush_max_chars: int = cfg.force_flush_max_chars
        self.sentence_joiner: str = " "
        self.end_punctuations = ('.', '!', '?')
        
        logger.info("StreamingWorkflowIntegration —Å–æ–∑–¥–∞–Ω")
    
    async def initialize(self) -> bool:
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏
        
        Returns:
            True –µ—Å–ª–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —É—Å–ø–µ—à–Ω–∞, False –∏–Ω–∞—á–µ
        """
        try:
            logger.info("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è StreamingWorkflowIntegration...")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –º–æ–¥—É–ª–µ–π
            if not self.text_module:
                logger.warning("‚ö†Ô∏è TextProcessor –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω")
            
            if not self.audio_module:
                logger.warning("‚ö†Ô∏è AudioProcessor –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω")
            
            if not self.memory_workflow:
                logger.warning("‚ö†Ô∏è MemoryWorkflow –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω")
            
            if not self.text_filter_module:
                logger.warning("‚ö†Ô∏è TextFilterManager –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω")
            
            self.is_initialized = True
            logger.info("‚úÖ StreamingWorkflowIntegration –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω —É—Å–ø–µ—à–Ω–æ")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ StreamingWorkflowIntegration: {e}")
            return False
    
    async def process_request_streaming(self, request_data: Dict[str, Any]) -> AsyncGenerator[Dict[str, Any], None]:
        """–ü–æ—Ç–æ–∫–æ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–∞: –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∏ –∞—É–¥–∏–æ —Å—Ç—Ä–∏–º—è—Ç—Å—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ."""
        if not self.is_initialized:
            logger.error("‚ùå StreamingWorkflowIntegration –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
            yield {
                'success': False,
                'error': 'StreamingWorkflowIntegration not initialized',
                'text_response': '',
            }
            return

        session_id = request_data.get('session_id', 'unknown')
        
        # ‚ö†Ô∏è NEW: –°–æ–∑–¥–∞–µ–º –æ—á–µ—Ä–µ–¥—å –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ MCP –¥–ª—è —ç—Ç–æ–π —Å–µ—Å—Å–∏–∏
        self._mcp_result_queues[session_id] = asyncio.Queue()
        self._pending_mcp_results[session_id] = False
        logger.info(
            "[F-2025-016-messages] Created MCP result queue for session=%s",
            session_id
        )
        
        try:
            logger.info(f"üîÑ –ù–∞—á–∞–ª–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–∞: {session_id}")
            logger.info(f"‚Üí Input text len={len(request_data.get('text','') or '')}, has_screenshot={bool(request_data.get('screenshot'))}")
            logger.info(f"‚Üí Input text content: '{request_data.get('text', '')[:100]}...'")

            logger.info("üîç –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê –ú–û–î–£–õ–ï–ô:")
            logger.info(f"   ‚Üí text_processor: {self.text_module is not None}")
            logger.info(f"   ‚Üí audio_processor: {self.audio_module is not None}")
            if self.text_module:
                logger.info(f"   ‚Üí text_processor.is_initialized: {getattr(self.text_module, 'is_initialized', 'NO_ATTR')}")
            if self.audio_module:
                logger.info(f"   ‚Üí audio_processor.is_initialized: {getattr(self.audio_module, 'is_initialized', 'NO_ATTR')}")

            hardware_id = request_data.get('hardware_id', 'unknown')
            
            # MVP 7: –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–≤–æ—Ç –∏ –ø–æ–ª—É—á–µ–Ω–∏–µ subscription context
            subscription_context_text = ""
            try:
                if self.subscription_module:
                    # 1. –ü–æ–ª—É—á–∞–µ–º –∏–ª–∏ —Å–æ–∑–¥–∞–µ–º –ø–æ–¥–ø–∏—Å–∫—É (–≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç paid_trial –¥–ª—è –Ω–æ–≤–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è)
                    subscription = self.subscription_module.get_or_create_subscription(hardware_id)
                    
                    # 2. –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–≤–æ—Ç—ã
                    quota_result = self.subscription_module.check_quota(hardware_id)
                    
                    if not quota_result.get('allowed', False):
                        # –ö–≤–æ—Ç–∞ –ø—Ä–µ–≤—ã—à–µ–Ω–∞ - –±–ª–æ–∫–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å
                        error_message = quota_result.get('message', 'Quota exceeded')
                        logger.warning(f"[MVP7] Quota exceeded for {hardware_id[:8]}...: {error_message}")
                        
                        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—à–∏–±–∫—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
                        yield {
                            'success': False,
                            'error': error_message,
                            'text_response': f"I'm sorry, but {error_message}. Please subscribe for unlimited access.",
                            'session_id': session_id,
                            'feature_id': 'F-2025-017-stripe-payment'
                        }
                        return  # –ü—Ä–µ—Ä—ã–≤–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É
                    
                    # 3. –ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è LLM
                    context_data = self.subscription_module.get_subscription_context(hardware_id)
                    subscription_context_text = context_data.get('formatted_text', '')
                    
                    if subscription_context_text:
                        logger.info(f"[MVP7] Subscription context added for {hardware_id[:8]}...")
            except Exception as e:
                logger.warning(f"[MVP7] Subscription context error: {e}")
                # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –±–µ–∑ subscription context (fallback)
            
            memory_context = await self._get_memory_context_parallel(hardware_id)

            # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ –ø–µ—Ä–µ–¥ –Ω–æ–≤–æ–π —Å–µ—Å—Å–∏–µ–π,
            # –∏–Ω–∞—á–µ –æ—Å—Ç–∞—Ç–∫–∏ –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–µ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤—ã–∑—ã–≤–∞—é—Ç –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ —á–∞–Ω–∫–æ–≤
            self._stream_buffer = ""
            self._pending_segment = ""
            self._has_emitted = False
            self._processed_sentences.clear()
            # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ MCP –∫–æ–º–∞–Ω–¥—ã (–§–∞–∑–∞ 2)
            self._pending_command_payload = None
            self._command_payload_sent = False
            # –°–±—Ä–∞—Å—ã–≤–∞–µ–º –±—É—Ñ–µ—Ä –¥–ª—è –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è JSON –æ—Ç–≤–µ—Ç–æ–≤ –æ—Ç LLM
            self._json_buffer = ""
            self._json_parsed = False

            captured_segments: list[str] = []
            input_sentence_counter = 0
            emitted_segment_counter = 0
            total_audio_chunks = 0
            total_audio_bytes = 0
            sentence_audio_map: dict[int, int] = {}

            async for sentence in self._iter_processed_sentences(
                request_data.get('text', ''),
                request_data.get('screenshot'),
                memory_context,
                subscription_context_text  # MVP 7: –î–æ–±–∞–≤–ª—è–µ–º subscription context
            ):
                input_sentence_counter += 1
                logger.info(f"üìù In sentence #{input_sentence_counter}: '{sentence[:120]}{'...' if len(sentence) > 120 else ''}' (len={len(sentence)})")

                # –ù–∞–∫–æ–ø–ª–µ–Ω–∏–µ JSON: –¥–æ–±–∞–≤–ª—è–µ–º —á–∞—Å—Ç—å –≤ –±—É—Ñ–µ—Ä
                self._json_buffer += sentence
                
                # –û—á–∏—â–∞–µ–º –æ—Ç markdown –ø–µ—Ä–µ–¥ –ø—Ä–æ–≤–µ—Ä–∫–æ–π
                cleaned_buffer = self._extract_json_from_markdown(self._json_buffer)
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è –ª–∏ –±—É—Ñ–µ—Ä —Å JSON (–º–æ–∂–µ—Ç –±—ã—Ç—å `{` –∏–ª–∏ markdown-–±–ª–æ–∫)
                is_potential_json = cleaned_buffer.strip().startswith('{')
                
                if is_potential_json:
                    # –ü—ã—Ç–∞–µ–º—Å—è —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω—ã–π JSON (–ø–æ—Å–ª–µ —É–¥–∞–ª–µ–Ω–∏—è markdown-—Ä–∞–∑–º–µ—Ç–∫–∏)
                    parsed_json = None
                    try:
                        import json
                        parsed_json = json.loads(cleaned_buffer)
                        # JSON –≤–∞–ª–∏–¥–µ–Ω - –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ
                        logger.info(f"‚úÖ JSON –ø–æ–ª–Ω–æ—Å—Ç—å—é –Ω–∞–∫–æ–ø–ª–µ–Ω –∏ —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω: {len(self._json_buffer)} —Å–∏–º–≤–æ–ª–æ–≤ (–ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏: {len(cleaned_buffer)})")
                        self._json_parsed = True
                    except (json.JSONDecodeError, ValueError):
                        # JSON –µ—â—ë –Ω–µ –ø–æ–ª–Ω—ã–π - –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –Ω–∞–∫–∞–ø–ª–∏–≤–∞—Ç—å
                        logger.debug(f"üì¶ –ù–∞–∫–æ–ø–ª–µ–Ω–∏–µ JSON: {len(self._json_buffer)} —Å–∏–º–≤–æ–ª–æ–≤ (–µ—â—ë –Ω–µ –ø–æ–ª–Ω—ã–π, –æ—á–∏—â–µ–Ω–Ω—ã–π: {len(cleaned_buffer)})")
                        continue
                    
                    # JSON –ø–æ–ª–Ω–æ—Å—Ç—å—é –Ω–∞–∫–æ–ø–ª–µ–Ω - –ø–∞—Ä—Å–∏–º –µ–≥–æ
                    parsed = await self._parse_assistant_response(parsed_json, session_id)
                    if parsed.command_payload and not self._command_payload_sent:
                        command = parsed.command_payload.get('payload', {}).get('command')
                        
                        # MVP 8 & 10: –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–æ–º–∞–Ω–¥ –ø–æ–¥–ø–∏—Å–∫–∏
                        if command in ('create_subscription', 'cancel_subscription', 'manage_subscription'):
                            hardware_id = request_data.get('hardware_id', 'unknown')
                            result = await self._execute_subscription_command(
                                command=command,
                                hardware_id=hardware_id,
                                session_id=session_id,
                                args=parsed.command_payload.get('payload', {}).get('args', {})
                            )
                            
                            if result:
                                # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∫–æ–º–∞–Ω–¥—ã
                                if result.get('text_response'):
                                    yield {
                                        'success': True,
                                        'text_response': result['text_response'],
                                        'session_id': session_id,
                                        'feature_id': 'F-2025-017-stripe-payment'
                                    }
                                    
                                    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∞—É–¥–∏–æ –¥–ª—è –æ—Ç–≤–µ—Ç–∞
                                    if result['text_response'].strip():
                                        async for audio_chunk in self._stream_audio_for_sentence(result['text_response'].strip(), 0):
                                            if audio_chunk:
                                                yield {
                                                    'audio_chunk': audio_chunk,
                                                    'session_id': session_id,
                                                }
                                
                                # MVP 9 & 10: –ï—Å–ª–∏ –µ—Å—Ç—å checkout_url –∏–ª–∏ portal_url, –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º action_message —Å open_url –∫–æ–º–∞–Ω–¥–æ–π
                                url_to_open = result.get('checkout_url') or result.get('portal_url')
                                if url_to_open:
                                    import json
                                    
                                    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º action_message –¥–ª—è –æ—Ç–∫—Ä—ã—Ç–∏—è URL –≤ –±—Ä–∞—É–∑–µ—Ä–µ
                                    yield {
                                        'action_message': {
                                            'action_json': json.dumps({
                                                'command': 'open_url',
                                                'args': {
                                                    'url': url_to_open
                                                }
                                            }),
                                            'session_id': session_id,
                                            'feature_id': 'F-2025-017-stripe-payment'
                                        },
                                        'session_id': session_id,
                                        'feature_id': 'F-2025-017-stripe-payment'
                                    }
                                    
                                    # –¢–∞–∫–∂–µ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º subscription_checkout –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ (—Ç–æ–ª—å–∫–æ –¥–ª—è checkout)
                                    if result.get('checkout_url'):
                                        yield {
                                            'subscription_checkout': {
                                                'checkout_url': result['checkout_url'],
                                                'session_id': result.get('session_id')
                                            },
                                            'session_id': session_id,
                                            'feature_id': 'F-2025-017-stripe-payment'
                                        }
                                
                                self._command_payload_sent = True
                                # –ó–∞–≤–µ—Ä—à–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –ø–æ—Å–ª–µ –∫–æ–º–∞–Ω–¥—ã –ø–æ–¥–ø–∏—Å–∫–∏
                                return
                        
                        # –û–±—Ä–∞–±–æ—Ç–∫–∞ browser_use –∫–æ–º–∞–Ω–¥—ã (–¶–∏–∫–ª 3) - –≤—ã–∑—ã–≤–∞–µ–º –º–æ–¥—É–ª—å —Å—Ä–∞–∑—É
                        elif command == 'browser_use':
                            if self.coordinator and self.coordinator.has('browser_use'):
                                logger.info("[F-2025-015-browser-use] Browser-use command detected, calling module")
                                browser_module = self.coordinator.get('browser_use')
                                hardware_id = request_data.get('hardware_id', 'unknown')
                                
                                # –í—ã–∑—ã–≤–∞–µ–º –º–æ–¥—É–ª—å –∏ —Å—Ç—Ä–∏–º–∏–º –ø—Ä–æ–≥—Ä–µ—Å—Å
                                async for progress in browser_module.process({
                                    'args': parsed.command_payload['payload']['args'],
                                    'session_id': session_id,
                                    'hardware_id': hardware_id,
                                    'feature_id': 'F-2025-015-browser-use'
                                }):
                                    description = progress.get('description', '')
                                    
                                    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º browser_progress —Å–æ–±—ã—Ç–∏–µ
                                    yield {
                                        'browser_progress': progress,
                                        'text_chunk': description,
                                        'session_id': session_id,
                                    }
                                    
                                    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –∞—É–¥–∏–æ –¥–ª—è description (–µ—Å–ª–∏ –µ—Å—Ç—å)
                                    if description and description.strip():
                                        async for audio_chunk in self._stream_audio_for_sentence(description.strip(), 0):
                                            if audio_chunk:
                                                yield {
                                                    'audio_chunk': audio_chunk,
                                                    'session_id': session_id,
                                                }
                                
                                self._command_payload_sent = True
                                # –ó–∞–≤–µ—Ä—à–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –ø–æ—Å–ª–µ browser-use
                                return
                            else:
                                # Coordinator –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω - —Å–æ—Ö—Ä–∞–Ω—è–µ–º –¥–ª—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
                                logger.warning("[F-2025-015-browser-use] Browser-use module not available (stub fallback)")
                                self._pending_command_payload = parsed.command_payload
                                self._log_command_detected(parsed, session_id)
                        else:
                            # –û–±—ã—á–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã - —Å–æ—Ö—Ä–∞–Ω—è–µ–º –¥–ª—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
                            self._pending_command_payload = parsed.command_payload
                            self._log_command_detected(parsed, session_id)

                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ text_response –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
                    sentence = parsed.text_response

                    # [–ù–û–í–û–ï –ò–ó–ú–ï–ù–ï–ù–ò–ï] –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è —Ç–µ–∫—Å—Ç–∞ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è –∫–æ–º–∞–Ω–¥—ã
                    if parsed.command_payload and sentence and sentence.strip():
                        logger.info(f"üé§ –û–±–Ω–∞—Ä—É–∂–µ–Ω —Ç–µ–∫—Å—Ç –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è –¥–ª—è –∫–æ–º–∞–Ω–¥—ã: '{sentence}'")
                        emitted_segment_counter += 1
                        captured_segments.append(sentence.strip())
                        
                        # –ù–µ–º–µ–¥–ª–µ–Ω–Ω–æ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç –∏ –∞—É–¥–∏–æ, –º–∏–Ω—É—è –±—É—Ñ–µ—Ä
                        yield { 'success': True, 'text_response': sentence.strip(), 'sentence_index': emitted_segment_counter }
                        
                        tts_text = sentence.strip() if sentence.strip().endswith(self.end_punctuations) else f"{sentence.strip()}."
                        sentence_audio_chunks = 0
                        async for audio_chunk in self._stream_audio_for_sentence(tts_text, emitted_segment_counter):
                            if audio_chunk:
                                sentence_audio_chunks += 1
                                total_audio_chunks += 1
                                total_audio_bytes += len(audio_chunk)
                                yield { 'success': True, 'audio_chunk': audio_chunk, 'sentence_index': emitted_segment_counter, 'audio_chunk_index': sentence_audio_chunks }
                        
                        sentence_audio_map[emitted_segment_counter] = sentence_audio_chunks
                        logger.info(f"üéß Command confirmation audio generated for segment #{emitted_segment_counter}")

                        # –û—á–∏—â–∞–µ–º –±—É—Ñ–µ—Ä –∏ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –æ—Å—Ç–∞–ª—å–Ω—É—é —á–∞—Å—Ç—å —Ü–∏–∫–ª–∞, —Ç–∞–∫ –∫–∞–∫ —ç—Ç–æ—Ç —á–∞–Ω–∫ –æ–±—Ä–∞–±–æ—Ç–∞–Ω
                        self._json_buffer = ""
                        self._json_parsed = False
                        continue
                    
                    # –û—á–∏—â–∞–µ–º JSON –±—É—Ñ–µ—Ä –ø–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥–∞
                    self._json_buffer = ""
                    self._json_parsed = False
                else:
                    # –≠—Ç–æ –Ω–µ JSON - –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∫ –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç (–ø–µ—Ä–µ–¥–∞—ë–º —á–∞—Å—Ç—è–º–∏)
                    logger.debug(f"üìù –û–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç (–Ω–µ JSON): {len(sentence)} —Å–∏–º–≤–æ–ª–æ–≤, –ø–µ—Ä–µ–¥–∞—ë–º —á–∞—Å—Ç—è–º–∏")
                    # –û—á–∏—â–∞–µ–º JSON –±—É—Ñ–µ—Ä, —Ç–∞–∫ –∫–∞–∫ —ç—Ç–æ –Ω–µ JSON
                    self._json_buffer = ""
                    # –ü–∞—Ä—Å–∏–º –∫–∞–∫ –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç (–º–æ–∂–µ—Ç –±—ã—Ç—å —Ñ–æ—Ä–º–∞—Ç {"text": "..."} –∏–ª–∏ –ø—Ä–æ—Å—Ç–æ —Ç–µ–∫—Å—Ç)
                    parsed = await self._parse_assistant_response(sentence, session_id)
                    sentence = parsed.text_response

                # –ï–¥–∏–Ω–∞—è –±—É—Ñ–µ—Ä–∏–∑–∞—Ü–∏—è: –Ω–∞–∫–∞–ø–ª–∏–≤–∞–µ–º, –∏–∑–≤–ª–µ–∫–∞–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è, –∞–≥—Ä–µ–≥–∏—Ä—É–µ–º –∫–æ—Ä–æ—Ç–∫–∏–µ
                # –í–ê–ñ–ù–û: –¥–∞–∂–µ –µ—Å–ª–∏ —ç—Ç–æ –¥–µ–π—Å—Ç–≤–∏–µ, text_response –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å —Ç–µ–∫—Å—Ç –¥–ª—è TTS
                if not sentence or not sentence.strip():
                    logger.warning(f"‚ö†Ô∏è text_response –ø—É—Å—Ç–æ–π –ø–æ—Å–ª–µ –ø–∞—Ä—Å–∏–Ω–≥–∞, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É TTS")
                    continue
                
                # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: –µ—Å–ª–∏ sentence –≤—ã–≥–ª—è–¥–∏—Ç –∫–∞–∫ JSON, –ø—Ä–æ–±—É–µ–º –µ–≥–æ —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å
                # –≠—Ç–æ –∑–∞—â–∏—Ç–∞ –æ—Ç —Å–ª—É—á–∞–µ–≤, –∫–æ–≥–¥–∞ JSON –Ω–µ –±—ã–ª —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω —Ä–∞–Ω–µ–µ –∏ –ø–æ–ø–∞–ª –≤ stream_buffer
                if sentence.strip().startswith('{') or '{"text"' in sentence or '"text":' in sentence:
                    # –í–æ–∑–º–æ–∂–Ω–æ, —ç—Ç–æ JSON, –∫–æ—Ç–æ—Ä—ã–π –Ω–µ –±—ã–ª —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω - –ø—Ä–æ–±—É–µ–º —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å
                    try:
                        import json
                        cleaned = self._extract_json_from_markdown(sentence)
                        if cleaned.strip().startswith('{'):
                            parsed_json = json.loads(cleaned)
                            parsed = await self._parse_assistant_response(parsed_json, session_id)
                            sentence = parsed.text_response
                            logger.info(f"‚úÖ JSON —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω –∏ —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω –Ω–∞ —ç—Ç–∞–ø–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ TTS: text_response='{sentence[:100] if sentence else '(–ø—É—Å—Ç–æ)'}...' (len={len(sentence) if sentence else 0})")
                    except (json.JSONDecodeError, ValueError):
                        # –ù–µ JSON –∏–ª–∏ –Ω–µ–ø–æ–ª–Ω—ã–π - –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å
                        pass
                
                logger.info(f"üìù –û–±—Ä–∞–±–æ—Ç–∫–∞ text_response –¥–ª—è TTS: '{sentence[:100]}{'...' if len(sentence) > 100 else ''}' (len={len(sentence)})")
                    
                sanitized = await self._sanitize_for_tts(sentence)
                if sanitized:
                    # –ù–ï –¥–æ–±–∞–≤–ª—è–µ–º –≤ _processed_sentences –∑–¥–µ—Å—å - —Ç–æ–ª—å–∫–æ –ø—Ä–∏ —ç–º–∏—Å—Å–∏–∏
                    # –≠—Ç–æ –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç –ø—Ä–æ–ø—É—Å–∫ –ø–µ—Ä–≤–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∏–∑-–∑–∞ –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏
                    self._stream_buffer = (f"{self._stream_buffer}{self.sentence_joiner}{sanitized}" if self._stream_buffer else sanitized)

                complete_sentences, remainder = await self._split_complete_sentences(self._stream_buffer)
                self._stream_buffer = remainder

                for complete in complete_sentences:
                    # –ê–≥—Ä–µ–≥–∏—Ä—É–µ–º –∫–æ—Ä–æ—Ç–∫–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –¥–æ –ø–æ—Ä–æ–≥–æ–≤
                    candidate = complete if not self._pending_segment else f"{self._pending_segment}{self.sentence_joiner}{complete}"
                    words_count = await self._count_meaningful_words(candidate)
                    if (not self._has_emitted and (words_count >= self.stream_first_sentence_min_words or len(candidate) >= self.stream_min_chars)) or \
                       (self._has_emitted and (words_count >= self.stream_min_words or len(candidate) >= self.stream_min_chars)):
                        # –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è —Ñ–∏–Ω–∞–ª—å–Ω—ã—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤ (—Ç–æ–ª—å–∫–æ –¥–ª—è –æ—á–µ–Ω—å –∫–æ—Ä–æ—Ç–∫–∏—Ö –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏–π)
                        to_emit = candidate.strip()
                        if len(to_emit) > 10:  # –¢–æ–ª—å–∫–æ –¥–ª—è –¥–ª–∏–Ω–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤ –ø—Ä–∏–º–µ–Ω—è–µ–º –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—é
                            complete_hash = hash(to_emit)
                            if complete_hash in self._processed_sentences:
                                logger.debug(f"üîÑ –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Å–µ–≥–º–µ–Ω—Ç: '{to_emit[:50]}...'")
                                continue
                            self._processed_sentences.add(complete_hash)
                        
                        # –ì–æ—Ç–æ–≤ –∫ —ç–º–∏—Å—Å–∏–∏
                        emitted_segment_counter += 1
                        self._pending_segment = ""
                        self._has_emitted = True

                        # –¢–µ–∫—Å—Ç
                        captured_segments.append(to_emit)
                        yield {
                            'success': True,
                            'text_response': to_emit,
                            'sentence_index': emitted_segment_counter
                        }

                        # –ê—É–¥–∏–æ (–≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º –∑–∞–≤–µ—Ä—à–∞—é—â—É—é –ø—É–Ω–∫—Ç—É–∞—Ü–∏—é –¥–ª—è TTS)
                        # –§–∞–∑–∞ 2: –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∞—É–¥–∏–æ-–≥–µ–Ω–µ—Ä–∞—Ü–∏—é, –µ—Å–ª–∏ text –ø—É—Å—Ç–æ–π
                        if to_emit.strip():
                            tts_text = to_emit if to_emit.endswith(self.end_punctuations) else f"{to_emit}."
                            sentence_audio_chunks = 0
                            async for audio_chunk in self._stream_audio_for_sentence(tts_text, emitted_segment_counter):
                                if not audio_chunk:
                                    continue
                                sentence_audio_chunks += 1
                                total_audio_chunks += 1
                                total_audio_bytes += len(audio_chunk)
                                yield {
                                    'success': True,
                                    'audio_chunk': audio_chunk,
                                    'sentence_index': emitted_segment_counter,
                                    'audio_chunk_index': sentence_audio_chunks
                                }
                            sentence_audio_map[emitted_segment_counter] = sentence_audio_chunks
                            logger.info(
                                f"üéß Segment #{emitted_segment_counter} ‚Üí audio_chunks={sentence_audio_chunks}, total_audio_chunks={total_audio_chunks}, total_bytes={total_audio_bytes}"
                            )
                        else:
                            # –ü—É—Å—Ç–æ–π —Ç–µ–∫—Å—Ç - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –∞—É–¥–∏–æ
                            logger.debug(f"‚è≠Ô∏è –ü—Ä–æ–ø—É—Å–∫ –∞—É–¥–∏–æ –¥–ª—è –ø—É—Å—Ç–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –≤ segment #{emitted_segment_counter}")
                    else:
                        # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –∫–æ–ø–∏—Ç—å
                        self._pending_segment = candidate

            # –§–∏–Ω–∞–ª—å–Ω—ã–π —Ñ–ª–∞—à: –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ—Å—Ç–∞–≤—à–∏–π—Å—è JSON –±—É—Ñ–µ—Ä, –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å
            if self._json_buffer and not self._json_parsed:
                import json
                # –û—á–∏—â–∞–µ–º –æ—Ç markdown –ø–µ—Ä–µ–¥ –ø—Ä–æ–≤–µ—Ä–∫–æ–π
                cleaned_buffer = self._extract_json_from_markdown(self._json_buffer)
                is_potential_json = cleaned_buffer.strip().startswith('{')
                if is_potential_json:
                    try:
                        parsed_json = json.loads(cleaned_buffer)
                        logger.info(f"‚úÖ –§–∏–Ω–∞–ª—å–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ JSON –±—É—Ñ–µ—Ä–∞: {len(self._json_buffer)} —Å–∏–º–≤–æ–ª–æ–≤ (–ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏: {len(cleaned_buffer)})")
                        parsed = await self._parse_assistant_response(parsed_json, session_id)
                        if parsed.command_payload and not self._command_payload_sent:
                            self._pending_command_payload = parsed.command_payload
                            self._log_command_detected(parsed, session_id)
                        # –î–æ–±–∞–≤–ª—è–µ–º text_response –≤ stream_buffer –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
                        if parsed.text_response:
                            self._stream_buffer = (f"{self._stream_buffer}{self.sentence_joiner}{parsed.text_response}" if self._stream_buffer else parsed.text_response)
                        self._json_buffer = ""
                        self._json_parsed = False
                    except (json.JSONDecodeError, ValueError):
                        # JSON –Ω–µ –≤–∞–ª–∏–¥–µ–Ω - –≤–æ–∑–º–æ–∂–Ω–æ, —ç—Ç–æ –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç
                        logger.debug(f"‚ö†Ô∏è JSON –±—É—Ñ–µ—Ä –Ω–µ –≤–∞–ª–∏–¥–µ–Ω, –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∫ –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç: {len(self._json_buffer)} —Å–∏–º–≤–æ–ª–æ–≤")
                        if self._json_buffer.strip():
                            # –ï—Å–ª–∏ –±—É—Ñ–µ—Ä –Ω–µ –ø—É—Å—Ç–æ–π –∏ –Ω–µ JSON - –¥–æ–±–∞–≤–ª—è–µ–º –∫–∞–∫ –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç
                            parsed = await self._parse_assistant_response(self._json_buffer, session_id)
                            if parsed.text_response:
                                self._stream_buffer = (f"{self._stream_buffer}{self.sentence_joiner}{parsed.text_response}" if self._stream_buffer else parsed.text_response)
                        self._json_buffer = ""
                else:
                    # –≠—Ç–æ –Ω–µ JSON - –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∫ –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç
                    logger.debug(f"üìù –§–∏–Ω–∞–ª—å–Ω—ã–π –±—É—Ñ–µ—Ä - –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç: {len(self._json_buffer)} —Å–∏–º–≤–æ–ª–æ–≤")
                    if self._json_buffer.strip():
                        parsed = await self._parse_assistant_response(self._json_buffer, session_id)
                        if parsed.text_response:
                            self._stream_buffer = (f"{self._stream_buffer}{self.sentence_joiner}{parsed.text_response}" if self._stream_buffer else parsed.text_response)
                    self._json_buffer = ""
            
            # –§–∏–Ω–∞–ª—å–Ω—ã–π —Ñ–ª–∞—à: —Å–Ω–∞—á–∞–ª–∞ –æ–±—Ä–∞–±–æ—Ç–∞–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∏–∑ –±—É—Ñ–µ—Ä–∞
            # –í–ê–ñ–ù–û: –ø—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –ª–∏ stream_buffer JSON-–æ–±—ä–µ–∫—Ç–æ–º
            if self._stream_buffer:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –ª–∏ stream_buffer JSON-–æ–±—ä–µ–∫—Ç–æ–º
                stream_cleaned = self._extract_json_from_markdown(self._stream_buffer)
                if stream_cleaned.strip().startswith('{'):
                    try:
                        import json
                        parsed_json = json.loads(stream_cleaned)
                        logger.info(f"‚úÖ JSON –æ–±–Ω–∞—Ä—É–∂–µ–Ω –≤ stream_buffer –ø—Ä–∏ —Ñ–∏–Ω–∞–ª—å–Ω–æ–º —Ñ–ª–∞—à–µ: {len(self._stream_buffer)} —Å–∏–º–≤–æ–ª–æ–≤")
                        parsed = await self._parse_assistant_response(parsed_json, session_id)
                        if parsed.text_response:
                            self._stream_buffer = parsed.text_response
                            logger.info(f"üìù –ó–∞–º–µ–Ω—ë–Ω stream_buffer –Ω–∞ —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω–Ω—ã–π text_response: '{self._stream_buffer[:100]}...' (len={len(self._stream_buffer)})")
                    except (json.JSONDecodeError, ValueError):
                        # –ù–µ JSON –∏–ª–∏ –Ω–µ–ø–æ–ª–Ω—ã–π - –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å
                        pass
                
                complete_sentences, remainder = await self._split_complete_sentences(self._stream_buffer)
                self._stream_buffer = remainder
                for complete in complete_sentences:
                    candidate = complete if not self._pending_segment else f"{self._pending_segment}{self.sentence_joiner}{complete}"
                    words_count = await self._count_meaningful_words(candidate)
                    # –ï—Å–ª–∏ –µ—Å—Ç—å command_payload, –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ —ç–º–∏—Ç–∏—Ä—É–µ–º –¥–∞–∂–µ –∫–æ—Ä–æ—Ç–∫–∏–π —Ç–µ–∫—Å—Ç
                    has_command = self._pending_command_payload and not self._command_payload_sent
                    should_emit = (
                        (not self._has_emitted and (words_count >= self.stream_first_sentence_min_words or len(candidate) >= self.stream_min_chars)) or
                        (self._has_emitted and (words_count >= self.stream_min_words or len(candidate) >= self.stream_min_chars)) or
                        (has_command and candidate.strip())  # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è —ç–º–∏—Å—Å–∏—è –¥–ª—è –∫–æ–º–∞–Ω–¥
                    )
                    
                    if should_emit:
                        emitted_segment_counter += 1
                        to_emit = candidate.strip()
                        self._pending_segment = ""
                        self._has_emitted = True
                        captured_segments.append(to_emit)
                        yield {'success': True, 'text_response': to_emit, 'sentence_index': emitted_segment_counter}
                        # –§–∞–∑–∞ 2: –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∞—É–¥–∏–æ-–≥–µ–Ω–µ—Ä–∞—Ü–∏—é, –µ—Å–ª–∏ text –ø—É—Å—Ç–æ–π
                        if to_emit.strip():
                            tts_text = to_emit if to_emit.endswith(self.end_punctuations) else f"{to_emit}."
                            sentence_audio_chunks = 0
                            async for audio_chunk in self._stream_audio_for_sentence(tts_text, emitted_segment_counter):
                                if not audio_chunk:
                                    continue
                                sentence_audio_chunks += 1
                                total_audio_chunks += 1
                                total_audio_bytes += len(audio_chunk)
                                yield {'success': True, 'audio_chunk': audio_chunk, 'sentence_index': emitted_segment_counter, 'audio_chunk_index': sentence_audio_chunks}
                            sentence_audio_map[emitted_segment_counter] = sentence_audio_chunks
                            logger.info(f"üéß Final segment #{emitted_segment_counter} ‚Üí audio_chunks={sentence_audio_chunks}, total_audio_chunks={total_audio_chunks}, total_bytes={total_audio_bytes}")
                        else:
                            logger.debug(f"‚è≠Ô∏è –ü—Ä–æ–ø—É—Å–∫ –∞—É–¥–∏–æ –¥–ª—è –ø—É—Å—Ç–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –≤ final segment #{emitted_segment_counter}")
                    else:
                        self._pending_segment = candidate
                
                # –ï—Å–ª–∏ –æ—Å—Ç–∞–ª—Å—è remainder –≤ stream_buffer, –¥–æ–±–∞–≤–ª—è–µ–º –µ–≥–æ –≤ pending_segment
                if remainder and remainder.strip():
                    if self._pending_segment:
                        self._pending_segment = f"{self._pending_segment}{self.sentence_joiner}{remainder}"
                    else:
                        self._pending_segment = remainder

            # –ï—Å–ª–∏ –æ—Å—Ç–∞–ª—Å—è –Ω–µ–∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã–π –∞–≥—Ä–µ–≥–∞—Ç, –º–æ–∂–Ω–æ —Ñ–æ—Ä—Å-—Ñ–ª–∞—à, –µ—Å–ª–∏ –æ—á–µ–Ω—å –¥–ª–∏–Ω–Ω—ã–π
            # –ò–õ–ò –µ—Å–ª–∏ –µ—Å—Ç—å command_payload (–Ω—É–∂–Ω–æ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ—Å—Ç–∏ —Ç–µ–∫—Å—Ç –¥–ª—è –¥–µ–π—Å—Ç–≤–∏—è)
            force_max = self.force_flush_max_chars
            has_command = self._pending_command_payload and not self._command_payload_sent
            should_force_flush = (
                (force_max > 0 and len(self._pending_segment) >= force_max) or
                (has_command and self._pending_segment and self._pending_segment.strip())
            )
            
            if should_force_flush:
                emitted_segment_counter += 1
                to_emit = self._pending_segment
                self._pending_segment = ""
                self._has_emitted = True
                captured_segments.append(to_emit)
                yield {'success': True, 'text_response': to_emit, 'sentence_index': emitted_segment_counter}
                # –§–∞–∑–∞ 2: –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∞—É–¥–∏–æ-–≥–µ–Ω–µ—Ä–∞—Ü–∏—é, –µ—Å–ª–∏ text –ø—É—Å—Ç–æ–π
                if to_emit.strip():
                    tts_text = to_emit if to_emit.endswith(self.end_punctuations) else f"{to_emit}."
                    sentence_audio_chunks = 0
                    async for audio_chunk in self._stream_audio_for_sentence(tts_text, emitted_segment_counter):
                        if not audio_chunk:
                            continue
                        sentence_audio_chunks += 1
                        total_audio_chunks += 1
                        total_audio_bytes += len(audio_chunk)
                        yield {'success': True, 'audio_chunk': audio_chunk, 'sentence_index': emitted_segment_counter, 'audio_chunk_index': sentence_audio_chunks}
                    sentence_audio_map[emitted_segment_counter] = sentence_audio_chunks
                    logger.info(f"üéß Forced final segment #{emitted_segment_counter} ‚Üí audio_chunks={sentence_audio_chunks}, total_audio_chunks={total_audio_chunks}, total_bytes={total_audio_bytes}")
                else:
                    logger.debug(f"‚è≠Ô∏è –ü—Ä–æ–ø—É—Å–∫ –∞—É–¥–∏–æ –¥–ª—è –ø—É—Å—Ç–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –≤ forced segment #{emitted_segment_counter}")

            full_text = " ".join(captured_segments).strip()

            # –§–∞–∑–∞ 2: –û—Ç–ø—Ä–∞–≤–ª—è–µ–º command_payload –æ–¥–∏–Ω —Ä–∞–∑ –≤ —Ñ–∏–Ω–∞–ª—å–Ω–æ–º –æ—Ç–≤–µ—Ç–µ
            final_result = {
                'success': True,
                'text_full_response': full_text,
                'sentences_processed': emitted_segment_counter,
                'audio_chunks_processed': total_audio_chunks,
                'audio_bytes_processed': total_audio_bytes,
                'sentence_audio_map': sentence_audio_map,
                'is_final': True
            }
            
            # –î–æ–±–∞–≤–ª—è–µ–º command_payload, –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å –∏ —Ñ–∏—á–∞-—Ñ–ª–∞–≥ –≤–∫–ª—é—á–µ–Ω
            if self._pending_command_payload and not self._command_payload_sent:
                command = self._pending_command_payload.get('payload', {}).get('command')
                
                # browser_use –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è –≤—ã—à–µ –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ —Å—Ç—Ä–∏–º–∏–Ω–≥–∞ (—Å—Ç—Ä–æ–∫–∏ 196-219)
                # –≠—Ç–∞ –≤–µ—Ç–∫–∞ –Ω–µ –¥–æ—Å—Ç–∏–≥–∞–µ—Ç—Å—è –¥–ª—è browser_use, —Ç–∞–∫ –∫–∞–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–∞–µ—Ç—Å—è —á–µ—Ä–µ–∑ return
                if command == 'browser_use':
                    # browser_use —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω –≤—ã—à–µ, —ç—Ç–∞ –≤–µ—Ç–∫–∞ –Ω–µ –¥–æ–ª–∂–Ω–∞ –¥–æ—Å—Ç–∏–≥–∞—Ç—å—Å—è
                    logger.warning("[F-2025-015-browser-use] browser_use command reached final_result handler (unexpected - should be handled in streaming)")
                    self._command_payload_sent = True
                else:
                    # –û–±—ã—á–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è –¥—Ä—É–≥–∏—Ö –∫–æ–º–∞–Ω–¥ (open_app, close_app)
                    config = get_config()
                    if (config.features.forward_assistant_actions and 
                        not config.kill_switches.disable_forward_assistant_actions):
                        final_result['command_payload'] = self._pending_command_payload
                        self._command_payload_sent = True
                        self._log_command_complete(session_id)
                    else:
                        logger.debug("–§–∏—á–∞-—Ñ–ª–∞–≥ forward_assistant_actions –≤—ã–∫–ª—é—á–µ–Ω –∏–ª–∏ kill-switch –∞–∫—Ç–∏–≤–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º command_payload")

            logger.info(
                f"‚úÖ –ó–∞–ø—Ä–æ—Å –æ–±—Ä–∞–±–æ—Ç–∞–Ω —É—Å–ø–µ—à–Ω–æ: segments={emitted_segment_counter}, audio_chunks={total_audio_chunks}, total_bytes={total_audio_bytes}"
            )
            
            # Quota Checker: –ò–Ω–∫—Ä–µ–º–µ–Ω—Ç–∏—Ä—É–µ–º —Å—á–µ—Ç—á–∏–∫–∏ –ø–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–∞
            try:
                if self.subscription_module and hardware_id:
                    increment_result = self.subscription_module.increment_usage(hardware_id)
                    if increment_result.get('success'):
                        logger.debug(f"[QuotaChecker] Usage incremented for {hardware_id[:8]}...")
                    else:
                        logger.debug(f"[QuotaChecker] Usage not incremented: {increment_result.get('error', 'unknown')}")
            except Exception as e:
                logger.warning(f"[QuotaChecker] Error incrementing usage: {e}")
            
            yield final_result
            
            # ‚ö†Ô∏è NEW: –ü–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –ø–æ—Ç–æ–∫–∞, –∂–¥–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ MCP (–¥–ª—è Messages –∫–æ–º–∞–Ω–¥)
            # –≠—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ç –∫–ª–∏–µ–Ω—Ç–∞ (read_messages, send_message)
            try:
                logger.info(
                    "[F-2025-016-messages] Main stream completed, waiting for MCP results: session=%s",
                    session_id
                )
                
                # –ñ–¥–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç MCP —Å —Ç–∞–π–º–∞—É—Ç–æ–º (30 —Å–µ–∫—É–Ω–¥)
                # –ï—Å–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä–∏–¥–µ—Ç, –æ–±—Ä–∞–±–æ—Ç–∞–µ–º –µ–≥–æ —á–µ—Ä–µ–∑ LLM –∏ —Å–≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º TTS
                mcp_result = await asyncio.wait_for(
                    self._mcp_result_queues[session_id].get(),
                    timeout=30.0
                )
                
                logger.info(
                    "[F-2025-016-messages] MCP result received: session=%s, command=%s, success=%s",
                    session_id,
                    mcp_result.get("command", "unknown"),
                    mcp_result.get("success", False)
                )
                
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç —á–µ—Ä–µ–∑ LLM –∏ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º TTS
                async for response in self._process_mcp_result_through_llm(
                    mcp_result,
                    session_id,
                    request_data.get('hardware_id', 'unknown')
                ):
                    yield response
                    
            except asyncio.TimeoutError:
                logger.info(
                    "[F-2025-016-messages] Timeout waiting for MCP result: session=%s (no MCP command or result delayed)",
                    session_id
                )
                # –≠—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ, –µ—Å–ª–∏ –∫–æ–º–∞–Ω–¥–∞ –Ω–µ –±—ã–ª–∞ Messages –∫–æ–º–∞–Ω–¥–æ–π –∏–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –Ω–µ –ø—Ä–∏—à–µ–ª
                # –û—á–∏—â–∞–µ–º —Ñ–ª–∞–≥ –æ–∂–∏–¥–∞–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
                self._pending_mcp_results.pop(session_id, None)
            except asyncio.CancelledError:
                # –ü—Ä–µ—Ä—ã–≤–∞–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞ - –æ—á–∏—â–∞–µ–º —Ä–µ—Å—É—Ä—Å—ã
                logger.info(
                    "[F-2025-016-messages] Request cancelled while waiting for MCP result: session=%s",
                    session_id
                )
                # –û—á–∏—Å—Ç–∫–∞ –±—É–¥–µ—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∞ –≤ finally –±–ª–æ–∫–µ
                raise  # –ü—Ä–æ–±—Ä–∞—Å—ã–≤–∞–µ–º CancelledError –¥–∞–ª—å—à–µ
            except Exception as e:
                logger.error(
                    "[F-2025-016-messages] Error waiting for MCP result: session=%s, error=%s",
                    session_id,
                    e,
                    exc_info=True
                )
                # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ, –Ω–µ –±–ª–æ–∫–∏—Ä—É—è –æ—Å–Ω–æ–≤–Ω–æ–π –ø–æ—Ç–æ–∫
                # –û—á–∏—â–∞–µ–º —Ñ–ª–∞–≥ –æ–∂–∏–¥–∞–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –ø—Ä–∏ –æ—à–∏–±–∫–µ
                self._pending_mcp_results.pop(session_id, None)

        except asyncio.CancelledError:
            # –ü—Ä–µ—Ä—ã–≤–∞–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞ - –æ—á–∏—â–∞–µ–º —Ä–µ—Å—É—Ä—Å—ã –∏ –≤—ã—Ö–æ–¥–∏–º
            logger.info(
                "[F-2025-016-messages] Request cancelled: session=%s",
                session_id
            )
            # –û—á–∏—Å—Ç–∫–∞ –±—É–¥–µ—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∞ –≤ finally –±–ª–æ–∫–µ
            raise  # –ü—Ä–æ–±—Ä–∞—Å—ã–≤–∞–µ–º CancelledError –¥–∞–ª—å—à–µ
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–∞ {session_id}: {e}")
            yield {
                'success': False,
                'error': str(e),
                'text_response': '',
            }
        finally:
            # ‚ö†Ô∏è NEW: –û—á–∏—â–∞–µ–º –æ—á–µ—Ä–µ–¥—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ MCP –¥–ª—è —ç—Ç–æ–π —Å–µ—Å—Å–∏–∏
            # –≠—Ç–æ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç —Ç–æ–≥–æ, –∫–∞–∫ –∑–∞–≤–µ—Ä—à–∏–ª—Å—è –º–µ—Ç–æ–¥ (–Ω–æ—Ä–º–∞–ª—å–Ω–æ, —á–µ—Ä–µ–∑ return, –∏–ª–∏ —á–µ—Ä–µ–∑ –∏—Å–∫–ª—é—á–µ–Ω–∏–µ)
            if session_id in self._mcp_result_queues:
                self._mcp_result_queues.pop(session_id, None)
                logger.info(
                    "[F-2025-016-messages] Cleaned up MCP result queue: session=%s",
                    session_id
                )
            if session_id in self._pending_mcp_results:
                self._pending_mcp_results.pop(session_id, None)

    async def process_mcp_result(
        self,
        session_id: str,
        mcp_result: Dict[str, Any]
    ) -> None:
        """
        –î–æ–±–∞–≤–ª—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç MCP –∫–æ–º–∞–Ω–¥—ã –≤ –æ—á–µ—Ä–µ–¥—å –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏.
        
        –í—ã–∑—ã–≤–∞–µ—Ç—Å—è –∏–∑ SendMcpActionResult handler –≤ grpc_server.py.
        –†–µ–∑—É–ª—å—Ç–∞—Ç –±—É–¥–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∞–Ω –ø–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –ø–æ—Ç–æ–∫–∞ –≤ process_request_streaming.
        
        ‚ö†Ô∏è –í–ê–ñ–ù–û: –ù–µ –∏–∑–º–µ–Ω—è–µ—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –ª–æ–≥–∏–∫—É –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏—è –∏ –¥—Ä—É–≥–∏—Ö —Ñ—É–Ω–∫—Ü–∏–π.
        
        Args:
            session_id: ID —Å–µ—Å—Å–∏–∏ (REQUIRED)
            mcp_result: –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º MCP –∫–æ–º–∞–Ω–¥—ã:
                - command: str - –∫–æ–º–∞–Ω–¥–∞ ("read_messages" –∏–ª–∏ "send_message")
                - result_text: Optional[str] - —Ç–µ–∫—Å—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ (–µ—Å–ª–∏ success=True)
                - error: Optional[str] - —Ç–µ–∫—Å—Ç –æ—à–∏–±–∫–∏ (–µ—Å–ª–∏ success=False)
                - success: bool - —É—Å–ø–µ—à–Ω–æ –ª–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞ –∫–æ–º–∞–Ω–¥–∞
                - feature_id: Optional[str] - Feature ID –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
        """
        if not session_id:
            logger.warning(
                "[F-2025-016-messages] process_mcp_result called without session_id"
            )
            return
        
        if session_id not in self._mcp_result_queues:
            logger.warning(
                "[F-2025-016-messages] No active queue for MCP result: session=%s (stream may have ended)",
                session_id
            )
            return
        
        command = mcp_result.get("command", "unknown")
        success = mcp_result.get("success", False)
        feature_id = mcp_result.get("feature_id", "F-2025-016-messages-integration")
        
        logger.info(
            "[%s] Adding MCP result to queue: session=%s, command=%s, success=%s",
            feature_id,
            session_id,
            command,
            success
        )
        
        try:
            # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ –æ—á–µ—Ä–µ–¥—å (–Ω–µ–±–ª–æ–∫–∏—Ä—É—é—â–∞—è –æ–ø–µ—Ä–∞—Ü–∏—è)
            self._mcp_result_queues[session_id].put_nowait(mcp_result)
            self._pending_mcp_results[session_id] = True
            logger.info(
                "[%s] MCP result added to queue successfully: session=%s",
                feature_id,
                session_id
            )
        except asyncio.QueueFull:
            logger.error(
                "[%s] MCP result queue is full: session=%s (unexpected)",
                feature_id,
                session_id
            )
        except Exception as e:
            logger.error(
                "[%s] Error adding MCP result to queue: session=%s, error=%s",
                feature_id,
                session_id,
                e,
                exc_info=True
            )
    
    def _determine_error_type(self, error: Optional[str], error_msg: str) -> str:
        """
        –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–∏–ø –æ—à–∏–±–∫–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–æ–æ–±—â–µ–Ω–∏—è –æ–± –æ—à–∏–±–∫–µ.
        
        Args:
            error: –ö–æ–¥ –æ—à–∏–±–∫–∏ (–µ—Å–ª–∏ –µ—Å—Ç—å)
            error_msg: –¢–µ–∫—Å—Ç –æ—à–∏–±–∫–∏
            
        Returns:
            –¢–∏–ø –æ—à–∏–±–∫–∏: "contact_not_found", "ambiguous_contact", "timeout", 
                       "access_denied", "no_phone_numbers", "technical", "unknown"
        """
        error_lower = error_msg.lower()
        
        # Contact not found
        if "contact not found" in error_lower or "contactnotfound" in error_lower:
            return "contact_not_found"
        
        # Ambiguous contact (multiple matches)
        if "multiple" in error_lower and "contact" in error_lower:
            return "ambiguous_contact"
        
        # Timeout
        if "timeout" in error_lower or error == "timeout":
            return "timeout"
        
        # Access denied / permissions
        if "access" in error_lower and "denied" in error_lower:
            return "access_denied"
        if "permission" in error_lower or "full disk access" in error_lower:
            return "access_denied"
        
        # No phone numbers
        if "no phone" in error_lower or "nophonenumbers" in error_lower:
            return "no_phone_numbers"
        
        # Technical / execution errors
        if error in ("execution_error", "mcp_error") or "error" in error_lower:
            return "technical"
        
        return "unknown"
    
    def _create_error_prompt(
        self,
        command: str,
        error_type: str,
        error_msg: str,
        feature_id: str
    ) -> str:
        """
        –°–æ–∑–¥–∞–µ—Ç –¥–µ—Ç–∞–ª—å–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è LLM –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–∏–ø–∞ –æ—à–∏–±–∫–∏.
        
        ‚ö†Ô∏è –í–ê–ñ–ù–û: –í—Å–µ –ø—Ä–æ–º–ø—Ç—ã –î–û–õ–ñ–ù–´ –±—ã—Ç—å –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º —è–∑—ã–∫–µ.
        
        Args:
            command: –ö–æ–º–∞–Ω–¥–∞, –∫–æ—Ç–æ—Ä–∞—è –≤—ã–∑–≤–∞–ª–∞ –æ—à–∏–±–∫—É ("read_messages" –∏–ª–∏ "send_message")
            error_type: –¢–∏–ø –æ—à–∏–±–∫–∏ (–∏–∑ _determine_error_type)
            error_msg: –¢–µ–∫—Å—Ç –æ—à–∏–±–∫–∏
            feature_id: Feature ID –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
            
        Returns:
            –ü—Ä–æ–º–ø—Ç –¥–ª—è LLM –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º —è–∑—ã–∫–µ
        """
        action = "read messages" if command == "read_messages" else "send a message"
        
        if error_type == "contact_not_found":
            return (
                f"The user asked to {action}, but the contact was not found.\n\n"
                f"Error details: {error_msg}\n\n"
                f"Please explain to the user in a friendly way that the contact could not be found. "
                f"Suggest that they:\n"
                f"- Check the spelling of the contact name\n"
                f"- Try using a different name or nickname\n"
                f"- Verify the contact exists in their Contacts app\n"
                f"Format your response as plain text (no JSON, no commands). "
                f"Be helpful and concise (1-2 sentences)."
            )
        
        elif error_type == "ambiguous_contact":
            return (
                f"The user asked to {action}, but multiple contacts match the name.\n\n"
                f"Error details: {error_msg}\n\n"
                f"Please explain to the user that there are multiple contacts with that name. "
                f"Suggest that they provide more specific information (e.g., full name, phone number, or email). "
                f"Format your response as plain text (no JSON, no commands). "
                f"Be helpful and concise (1-2 sentences)."
            )
        
        elif error_type == "timeout":
            return (
                f"The user asked to {action}, but the operation timed out.\n\n"
                f"Error details: {error_msg}\n\n"
                f"Please explain to the user that the operation took too long and may not have completed. "
                f"Suggest that they try again. "
                f"Format your response as plain text (no JSON, no commands). "
                f"Be helpful and concise (1-2 sentences)."
            )
        
        elif error_type == "access_denied":
            return (
                f"The user asked to {action}, but access to Messages or Contacts was denied.\n\n"
                f"Error details: {error_msg}\n\n"
                f"Please explain to the user that the app needs permission to access Messages or Contacts. "
                f"Suggest that they check System Settings > Privacy & Security > Full Disk Access "
                f"and ensure the app has the necessary permissions. "
                f"Format your response as plain text (no JSON, no commands). "
                f"Be helpful and concise (1-2 sentences)."
            )
        
        elif error_type == "no_phone_numbers":
            return (
                f"The user asked to send a message, but the contact has no phone numbers.\n\n"
                f"Error details: {error_msg}\n\n"
                f"Please explain to the user that the contact doesn't have a phone number associated with it. "
                f"Suggest that they add a phone number to the contact in the Contacts app, "
                f"or try sending via email or another method. "
                f"Format your response as plain text (no JSON, no commands). "
                f"Be helpful and concise (1-2 sentences)."
            )
        
        elif error_type == "technical":
            return (
                f"The user asked to {action}, but a technical error occurred.\n\n"
                f"Error details: {error_msg}\n\n"
                f"Please explain to the user that a technical issue prevented the operation. "
                f"Suggest that they try again in a moment. If the problem persists, "
                f"they may need to check their Messages app or restart the assistant. "
                f"Format your response as plain text (no JSON, no commands). "
                f"Be helpful and concise (1-2 sentences)."
            )
        
        else:  # unknown
            return (
                f"The user asked to {action}, but an error occurred.\n\n"
                f"Error details: {error_msg}\n\n"
                f"Please explain to the user that something went wrong in a friendly, helpful way. "
                f"Possible reasons: contact not found, ambiguous contact name, access denied, timeout, or technical issue. "
                f"Suggest that they try again or check the contact name. "
                f"Format your response as plain text (no JSON, no commands). "
                f"Be helpful and concise (1-2 sentences)."
            )
    
    async def _process_mcp_result_through_llm(
        self,
        mcp_result: Dict[str, Any],
        session_id: str,
        hardware_id: str
    ) -> AsyncGenerator[Dict[str, Any], None]:
        """
        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç MCP –∫–æ–º–∞–Ω–¥—ã —á–µ—Ä–µ–∑ LLM –∏ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç TTS.

        –≠—Ç–æ—Ç –º–µ—Ç–æ–¥ –≤—ã–∑—ã–≤–∞–µ—Ç—Å—è –ø–æ—Å–ª–µ –ø–æ–ª—É—á–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –∏–∑ –æ—á–µ—Ä–µ–¥–∏.
        –û–Ω —Ñ–æ—Ä–º–∏—Ä—É–µ—Ç –ø—Ä–æ–º–ø—Ç –¥–ª—è LLM, –ø–æ–ª—É—á–∞–µ—Ç –æ—Ç–≤–µ—Ç, –∏ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∞—É–¥–∏–æ –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è.

        ‚ö†Ô∏è –í–ê–ñ–ù–û: –í—Å–µ –ø—Ä–æ–º–ø—Ç—ã –∏ —Å–∏—Å—Ç–µ–º–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è –î–û–õ–ñ–ù–´ –±—ã—Ç—å –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º —è–∑—ã–∫–µ.

        Args:
            mcp_result: –†–µ–∑—É–ª—å—Ç–∞—Ç MCP –∫–æ–º–∞–Ω–¥—ã –∏–∑ –æ—á–µ—Ä–µ–¥–∏
            session_id: ID —Å–µ—Å—Å–∏–∏
            hardware_id: ID –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è

        Yields:
            Dict —Å text_response –∏ audio_chunk –¥–ª—è —Å—Ç—Ä–∏–º–∏–Ω–≥–∞ –∫–ª–∏–µ–Ω—Ç—É
        """
        command = mcp_result.get("command", "unknown")
        result_text = mcp_result.get("result_text", "")
        error = mcp_result.get("error")
        success = mcp_result.get("success", False)
        feature_id = mcp_result.get("feature_id", "F-2025-016-messages-integration")

        logger.info(
            "[%s] Processing MCP result through LLM: session=%s, command=%s, success=%s",
            feature_id,
            session_id,
            command,
            success
        )
        
        # ‚ö†Ô∏è CRITICAL: –õ–æ–≥–∏—Ä—É–µ–º result_text –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
        logger.info(
            "[%s] MCP result_text (first 500 chars): %s",
            feature_id,
            result_text[:500] if result_text else "(empty)"
        )
        
        try:
            # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è LLM –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ MCP
            # ‚ö†Ô∏è –í–ê–ñ–ù–û: –í—Å–µ –ø—Ä–æ–º–ø—Ç—ã –î–û–õ–ñ–ù–´ –±—ã—Ç—å –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º —è–∑—ã–∫–µ
            if command == "read_messages":
                if success and result_text:
                    # ‚ö†Ô∏è –£—Å–ø–µ—à–Ω–æ–µ —á—Ç–µ–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏–π - LLM –¥–æ–ª–∂–µ–Ω –ø—Ä–æ—á–∏—Ç–∞—Ç—å –∏—Ö VERBATIM (–¥–æ—Å–ª–æ–≤–Ω–æ)
                    # –í–ê–ñ–ù–û: –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –¥–æ–ª–∂–µ–Ω —É—Å–ª—ã—à–∞—Ç—å —Ç–æ—á–Ω—ã–π —Ç–µ–∫—Å—Ç —Å–æ–æ–±—â–µ–Ω–∏–π, –Ω–µ –ø–µ—Ä–µ—Å–∫–∞–∑
                    llm_prompt = (
                        f"The user asked to read messages. The Messages app returned the following result:\n\n"
                        f"{result_text}\n\n"
                        f"CRITICAL INSTRUCTIONS:\n"
                        f"- Read these messages VERBATIM (word-for-word) to the user\n"
                        f"- DO NOT summarize, paraphrase, or rephrase the message content\n"
                        f"- DO NOT add your own interpretation or commentary\n"
                        f"- Read the actual message text EXACTLY as shown in the result\n"
                        f"- If the result shows multiple messages, read each one separately\n"
                        f"- Use natural, conversational tone, but keep the message content unchanged\n"
                        f"- Format your response as plain text (no JSON, no commands, no markdown)\n"
                        f"- Start directly with reading the messages (e.g., 'Last message from Sofia: Hello, how are you?')"
                    )
                else:
                    # –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ - LLM –¥–æ–ª–∂–µ–Ω –æ–±—ä—è—Å–Ω–∏—Ç—å –ø—Ä–æ–±–ª–µ–º—É —Å –¥–µ—Ç–∞–ª—å–Ω—ã–º–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏
                    error_msg = error or "Unknown error occurred"
                    error_type = self._determine_error_type(error, result_text or error_msg)
                    llm_prompt = self._create_error_prompt("read_messages", error_type, result_text or error_msg, feature_id)
            elif command == "send_message":
                if success and result_text:
                    # –£—Å–ø–µ—à–Ω–∞—è –æ—Ç–ø—Ä–∞–≤–∫–∞ - LLM –¥–æ–ª–∂–µ–Ω –ø–æ–¥—Ç–≤–µ—Ä–¥–∏—Ç—å —Å —É–∫–∞–∑–∞–Ω–∏–µ–º –∫–æ–Ω—Ç–∞–∫—Ç–∞ –ò —Ç–µ–∫—Å—Ç–∞ —Å–æ–æ–±—â–µ–Ω–∏—è
                    # ‚ö†Ô∏è –í–ê–ñ–ù–û: result_text –æ—Ç MCP —Å–µ—Ä–≤–µ—Ä–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç –∫–æ–Ω—Ç–∞–∫—Ç –∏ —Ç–µ–∫—Å—Ç —Å–æ–æ–±—â–µ–Ω–∏—è
                    # –§–æ—Ä–º–∞—Ç: "‚úÖ Message sent successfully to {contact} ({phone})\n\nMessage: {message_text}"
                    # LLM –¥–æ–ª–∂–µ–Ω –∏–∑–≤–ª–µ—á—å —ç—Ç–∏ –¥–∞–Ω–Ω—ã–µ –∏ –≤–∫–ª—é—á–∏—Ç—å –∏—Ö –≤ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ
                    llm_prompt = (
                        f"The user asked to send a message. The Messages app returned the following result:\n\n"
                        f"{result_text}\n\n"
                        f"CRITICAL INSTRUCTIONS:\n"
                        f"- Extract the contact name from the result above (it appears after 'Message sent successfully to')\n"
                        f"- Extract the message text from the result above (it appears after 'Message:')\n"
                        f"- You MUST include BOTH the contact name AND the message text in your confirmation\n"
                        f"- Format: 'Message sent to [contact name]: [message text]'\n"
                        f"- Example: If result shows 'Message sent successfully to Sofia (1234567890)\\n\\nMessage: Hello', "
                        f"your response should be: 'Message sent to Sofia: Hello'\n"
                        f"- Use natural, conversational tone, but include both pieces of information\n"
                        f"- Format your response as plain text (no JSON, no commands, no markdown)\n"
                        f"- Start directly with the confirmation (e.g., 'Message sent to Sofia: Hello, how are you?')"
                    )
                else:
                    # –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ - LLM –¥–æ–ª–∂–µ–Ω –æ–±—ä—è—Å–Ω–∏—Ç—å –ø—Ä–æ–±–ª–µ–º—É —Å –¥–µ—Ç–∞–ª—å–Ω—ã–º–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏
                    error_msg = error or "Unknown error occurred"
                    error_type = self._determine_error_type(error, result_text or error_msg)
                    llm_prompt = self._create_error_prompt("send_message", error_type, result_text or error_msg, feature_id)
            else:
                # –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –∫–æ–º–∞–Ω–¥–∞
                logger.warning(
                    "[%s] Unknown MCP command in result: %s",
                    feature_id,
                    command
                )
                llm_prompt = (
                    f"A command was executed, but the result format is unexpected. "
                    f"Please inform the user that the operation completed, but details are unavailable. "
                    f"Format your response as plain text (no JSON, no commands)."
                )
            
            # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç –æ—Ç LLM —á–µ—Ä–µ–∑ text_module
            if not self.text_module:
                logger.error(
                    "[%s] Text module not available for LLM processing",
                    feature_id
                )
                yield {
                    'success': False,
                    'error': 'Text module not available',
                    'text_response': 'I apologize, but I cannot process the result right now.',
                }
                return
            
            # –í—ã–∑—ã–≤–∞–µ–º text_module –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø—Ä–æ–º–ø—Ç–∞ —á–µ—Ä–µ–∑ LLM
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ—Ç –∂–µ –º–µ—Ö–∞–Ω–∏–∑–º, —á—Ç–æ –∏ –¥–ª—è –æ–±—ã—á–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
            llm_response_text = ""
            try:
                # –ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø–∞–º—è—Ç–∏ –¥–ª—è –æ–±–æ–≥–∞—â–µ–Ω–∏—è –ø—Ä–æ–º–ø—Ç–∞
                # ‚ö†Ô∏è CRITICAL: –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ memory_context - —ç—Ç–æ —Å–ª–æ–≤–∞—Ä—å, –∞ –Ω–µ —Å—Ç—Ä–æ–∫–∞
                memory_context_raw = await self._get_memory_context_parallel(hardware_id)
                memory_context = None
                if memory_context_raw:
                    if isinstance(memory_context_raw, dict):
                        memory_context = memory_context_raw
                    else:
                        logger.warning(
                            "[%s] Memory context is not a dict (type=%s), skipping memory enrichment",
                            feature_id,
                            type(memory_context_raw).__name__
                        )
                        memory_context = None
                
                # –§–æ—Ä–º–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è text_module
                text_request_data = {
                    'text': llm_prompt,
                    'screenshot': None,  # –ù–µ—Ç —Å–∫—Ä–∏–Ω—à–æ—Ç–∞ –¥–ª—è MCP —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                    'hardware_id': hardware_id,
                    'session_id': session_id,
                }
                
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —á–µ—Ä–µ–∑ text_module (LLM)
                # ‚ö†Ô∏è CRITICAL: –î–ª—è MCP —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –Ω–∞–∫–∞–ø–ª–∏–≤–∞–µ–º –ø–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç LLM –ø–µ—Ä–µ–¥ –ø–∞—Ä—Å–∏–Ω–≥–æ–º
                # LLM –º–æ–∂–µ—Ç –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å JSON, –Ω–æ –Ω–∞–º –Ω—É–∂–µ–Ω —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç –¥–ª—è TTS
                full_llm_response = ""
                async for sentence in self._iter_processed_sentences(
                    text_request_data.get('text', ''),
                    text_request_data.get('screenshot'),
                    memory_context
                ):
                    # –ù–∞–∫–∞–ø–ª–∏–≤–∞–µ–º –ø–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç
                    full_llm_response += sentence
                
                # –ü–æ—Å–ª–µ –ø–æ–ª—É—á–µ–Ω–∏—è –ø–æ–ª–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞, –ø—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç
                # –ï—Å–ª–∏ —ç—Ç–æ JSON, –ø–∞—Ä—Å–∏–º –µ–≥–æ; –µ—Å–ª–∏ –Ω–µ—Ç - –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–∞–∫ –µ—Å—Ç—å
                if full_llm_response.strip().startswith('{'):
                    # –ü–æ—Ö–æ–∂–µ –Ω–∞ JSON - –ø—ã—Ç–∞–µ–º—Å—è —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å
                    try:
                        parsed = await self._parse_assistant_response(full_llm_response, session_id)
                        llm_response_text = parsed.text_response or full_llm_response
                    except Exception as parse_error:
                        logger.warning(
                            "[%s] Failed to parse LLM response as JSON, using as text: %s",
                            feature_id,
                            parse_error
                        )
                        llm_response_text = full_llm_response
                else:
                    # –ù–µ JSON - –∏—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞–ø—Ä—è–º—É—é
                    llm_response_text = full_llm_response
                
                # –ï—Å–ª–∏ –ø–æ—Å–ª–µ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Ç–µ–∫—Å—Ç –ø—É—Å—Ç–æ–π –∏–ª–∏ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π, –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç
                if not llm_response_text or len(llm_response_text.strip()) < 3:
                    logger.warning(
                        "[%s] Parsed text too short, using original response: parsed_len=%d, original_len=%d",
                        feature_id,
                        len(llm_response_text) if llm_response_text else 0,
                        len(full_llm_response)
                    )
                    llm_response_text = full_llm_response
                
                # –û—á–∏—â–∞–µ–º —Ç–µ–∫—Å—Ç –¥–ª—è TTS
                sanitized = await self._sanitize_for_tts(llm_response_text)
                if not sanitized or not sanitized.strip():
                    logger.warning(
                        "[%s] Sanitized text is empty, skipping TTS generation",
                        feature_id
                    )
                    return
                
                # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç
                yield {
                    'success': True,
                    'text_response': sanitized.strip(),
                    'session_id': session_id,
                }
                
                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –∞—É–¥–∏–æ
                tts_text = sanitized.strip()
                if not tts_text.endswith(self.end_punctuations):
                    tts_text = f"{tts_text}."
                
                async for audio_chunk in self._stream_audio_for_sentence(tts_text, 0):
                    if audio_chunk:
                        yield {
                            'success': True,
                            'audio_chunk': audio_chunk,
                            'session_id': session_id,
                        }
                
                logger.info(
                    "[%s] MCP result processed through LLM: session=%s, response_len=%d",
                    feature_id,
                    session_id,
                    len(llm_response_text)
                )
                
            except asyncio.CancelledError:
                # –ü—Ä–µ—Ä—ã–≤–∞–Ω–∏–µ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ —á–µ—Ä–µ–∑ LLM
                logger.info(
                    "[%s] MCP result processing cancelled: session=%s, command=%s",
                    feature_id,
                    session_id,
                    command
                )
                # –ü—Ä–æ–±—Ä–∞—Å—ã–≤–∞–µ–º CancelledError –¥–∞–ª—å—à–µ –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
                raise
            except Exception as llm_error:
                logger.error(
                    "[%s] Error processing MCP result through LLM: session=%s, error=%s",
                    feature_id,
                    session_id,
                    llm_error,
                    exc_info=True
                )
                # Fallback: –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –ø—Ä–æ—Å—Ç–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ
                fallback_text = "I apologize, but I encountered an error processing the result."
                yield {
                    'success': True,
                    'text_response': fallback_text,
                    'session_id': session_id,
                }
                async for audio_chunk in self._stream_audio_for_sentence(fallback_text, 0):
                    if audio_chunk:
                        yield {
                            'success': True,
                            'audio_chunk': audio_chunk,
                            'session_id': session_id,
                        }
        
        except asyncio.CancelledError:
            # –ü—Ä–µ—Ä—ã–≤–∞–Ω–∏–µ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ —á–µ—Ä–µ–∑ LLM (–≤–Ω–µ—à–Ω–∏–π —É—Ä–æ–≤–µ–Ω—å)
            logger.info(
                "[%s] MCP result processing cancelled (outer): session=%s, command=%s",
                feature_id,
                session_id,
                command
            )
            raise
        except Exception as e:
            logger.error(
                "[%s] Unexpected error in _process_mcp_result_through_llm: session=%s, error=%s",
                feature_id,
                session_id,
                e,
                exc_info=True
            )
            yield {
                'success': False,
                'error': str(e),
                'text_response': 'I apologize, but I encountered an unexpected error.',
                'session_id': session_id,
            }

    async def _get_memory_context_parallel(self, hardware_id: str) -> Optional[Dict[str, Any]]:
        """
        –ù–µ–±–ª–æ–∫–∏—Ä—É—é—â–µ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø–∞–º—è—Ç–∏
        
        Args:
            hardware_id: –ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è
        """
        try:
            if not self.memory_workflow:
                logger.debug("MemoryWorkflow –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –ø–æ–ª—É—á–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏")
                return None
            
            logger.debug(f"–ü–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø–∞–º—è—Ç–∏ –¥–ª—è {hardware_id}")
            memory_context = await self.memory_workflow.get_memory_context_parallel(hardware_id)
            
            if memory_context:
                logger.debug(f"‚úÖ –ü–æ–ª—É—á–µ–Ω –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø–∞–º—è—Ç–∏: {len(memory_context)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤")
            else:
                logger.debug("‚ö†Ô∏è –ö–æ–Ω—Ç–µ–∫—Å—Ç –ø–∞–º—è—Ç–∏ –ø—É—Å—Ç")
            
            return memory_context
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø–∞–º—è—Ç–∏: {e}")
            return None

    async def _iter_processed_sentences(
        self,
        text: str,
        screenshot: Optional[str],
        memory_context: Optional[Dict[str, Any]],
        subscription_context: str = ""  # MVP 7: Subscription context (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)
    ) -> AsyncGenerator[str, None]:
        """–°—Ç—Ä–∏–º–∏–Ω–≥–æ–≤–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è —Å —É—á—ë—Ç–æ–º –ø–∞–º—è—Ç–∏, subscription context –∏ —Å–∫—Ä–∏–Ω—à–æ—Ç–∞."""
        # MVP 7: –û–±–æ–≥–∞—â–∞–µ–º —Ç–µ–∫—Å—Ç subscription context –∏ memory context
        if subscription_context:
            enriched_text = self._enrich_with_subscription_and_memory(text, subscription_context, memory_context)
        else:
            enriched_text = self._enrich_with_memory(text, memory_context)

        screenshot_data: Optional[bytes] = None
        if screenshot:
            import base64
            try:
                screenshot_data = base64.b64decode(screenshot)
                logger.info(f"üì∏ –°–∫—Ä–∏–Ω—à–æ—Ç –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω: {len(screenshot_data)} bytes")
            except Exception as decode_error:
                logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞—Ç—å —Å–∫—Ä–∏–Ω—à–æ—Ç: {decode_error}")
                screenshot_data = None

        yielded_any = False
        if self.text_module and hasattr(self.text_module, 'process'):
            logger.info(f"üîÑ –°—Ç—Ä–∏–º–∏–Ω–≥ —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ Text Module: '{enriched_text[:80]}...'")
            try:
                async for chunk in self._stream_text_module(enriched_text, screenshot_data):
                    sentence = (self._extract_text_chunk(chunk) or '').strip()
                    if sentence:
                        yielded_any = True
                        logger.debug(f"üì® TextModule sentence: '{sentence[:120]}...'")
                        yield sentence
            except Exception as processing_error:
                logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ Text Module: {processing_error}. –ò—Å–ø–æ–ª—å–∑—É–µ–º fallback")
        elif self.text_module and hasattr(self.text_module, 'process_text_streaming'):
            # Legacy fallback –Ω–∞ –ø—Ä—è–º–æ–π –¥–æ—Å—Ç—É–ø –∫ TextProcessor
            logger.info(f"üîÑ Legacy —Å—Ç—Ä–∏–º–∏–Ω–≥ —Ç–µ–∫—Å—Ç–∞: '{enriched_text[:80]}...'")
            try:
                async for processed_sentence in self.text_module.process_text_streaming(enriched_text, screenshot_data):
                    sentence = (processed_sentence or '').strip()
                    if sentence:
                        yielded_any = True
                        logger.debug(f"üì® Legacy TextProcessor sentence: '{sentence[:120]}...'")
                        yield sentence
            except Exception as processing_error:
                logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ legacy TextProcessor: {processing_error}. –ò—Å–ø–æ–ª—å–∑—É–µ–º fallback")

        if not yielded_any:
            logger.debug("‚ö†Ô∏è TextProcessor –Ω–µ –≤–µ—Ä–Ω—É–ª –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π, –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback —Ä–∞–∑–±–∏–≤–∫—É")
            for fallback_sentence in self._split_into_sentences(enriched_text):
                if fallback_sentence:
                    yield fallback_sentence

    async def _sanitize_for_tts(self, text: str) -> str:
        """
        –û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è —Å–∏–Ω—Ç–µ–∑–∞ —Ä–µ—á–∏ —á–µ—Ä–µ–∑ –º–æ–¥—É–ª—å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        """
        if not text:
            return ""

        if self.text_filter_module and hasattr(self.text_filter_module, 'process'):
            try:
                result = await self.text_filter_module.process({
                    "operation": "clean_text",
                    "text": text,
                    "options": {
                        "remove_special_chars": True,
                        "remove_extra_whitespace": True,
                        "normalize_unicode": True,
                        "remove_control_chars": True
                    }
                })
                if isinstance(result, dict) and result.get("success") and result.get("cleaned_text") is not None:
                    return result.get("cleaned_text", "").strip()
            except Exception as err:
                logger.warning("‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ TextFilterModule: %s", err)

        return text.strip()

    async def _split_complete_sentences(self, text: str) -> tuple[list[str], str]:
        """
        –†–∞–∑–±–∏–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è —á–µ—Ä–µ–∑ –º–æ–¥—É–ª—å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        """
        if not text:
            return [], ""

        if self.text_filter_module and hasattr(self.text_filter_module, 'process'):
            try:
                result = await self.text_filter_module.process({
                    "operation": "split_sentences",
                    "text": text
                })
                if isinstance(result, dict) and result.get("success"):
                    return result.get("sentences", []), result.get("remainder", "")
            except Exception as err:
                logger.warning("‚ö†Ô∏è –û—à–∏–±–∫–∞ —Ä–∞–∑–±–∏–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ TextFilterModule: %s", err)

        stripped = text.strip()
        return ([stripped] if stripped else [], "")

    async def _count_meaningful_words(self, text: str) -> int:
        """
        –ü–æ–¥—Å—á—ë—Ç –∑–Ω–∞—á–∏–º—ã—Ö —Å–ª–æ–≤ —á–µ—Ä–µ–∑ –º–æ–¥—É–ª—å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        """
        if not text:
            return 0

        if self.text_filter_module and hasattr(self.text_filter_module, 'process'):
            try:
                result = await self.text_filter_module.process({
                    "operation": "count_meaningful_words",
                    "text": text
                })
                if isinstance(result, dict) and result.get("success"):
                    return int(result.get("count", 0))
            except Exception as err:
                logger.warning("‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–¥—Å—á—ë—Ç–∞ —Å–ª–æ–≤ —á–µ—Ä–µ–∑ TextFilterModule: %s", err)

        return len([w for w in text.split() if w.strip()])

    async def _stream_text_module(self, text: str, screenshot_data: Optional[bytes]):
        """–°—Ç—Ä–∏–º–∏–Ω–≥ –æ—Ç–≤–µ—Ç–æ–≤ –∏–∑ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –º–æ–¥—É–ª—è."""
        payload = {"text": text}
        if screenshot_data:
            payload["image_data"] = screenshot_data

        async for chunk in self._stream_module_results(self.text_module, payload):
            yield chunk

    async def _stream_audio_module(self, text: str):
        """–°—Ç—Ä–∏–º–∏–Ω–≥ –∞—É–¥–∏–æ —á–∞–Ω–∫–æ–≤ –∏–∑ –∞—É–¥–∏–æ –º–æ–¥—É–ª—è."""
        async for chunk in self._stream_module_results(self.audio_module, {"text": text}):
            yield chunk

    async def _stream_module_results(self, module, payload: Dict[str, Any]):
        """–£–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≤—ã–∑–æ–≤ module.process —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π async generator."""
        if not module or not hasattr(module, 'process'):
            return
        try:
            result = await module.process(payload)
            if result is None:
                return
            if hasattr(result, "__aiter__"):
                async for item in result:
                    yield item
            else:
                yield result
        except Exception as err:
            logger.warning("‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ –º–æ–¥—É–ª—è %s: %s", getattr(module, 'name', 'unknown'), err)

    def _extract_text_chunk(self, chunk: Any) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç–≤–µ—Ç –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –º–æ–¥—É–ª—è."""
        if chunk is None:
            return ""
        if isinstance(chunk, str):
            return chunk
        if isinstance(chunk, dict):
            for key in ("text", "text_response", "value", "chunk"):
                value = chunk.get(key)
                if isinstance(value, str):
                    return value
        return ""

    def _extract_audio_chunk(self, chunk: Any) -> bytes:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∞—É–¥–∏–æ –±–∞–π—Ç—ã –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –º–æ–¥—É–ª—è."""
        if chunk is None:
            return b""
        if isinstance(chunk, (bytes, bytearray)):
            return bytes(chunk)
        if isinstance(chunk, dict):
            for key in ("audio", "audio_chunk", "audio_data", "data", "value"):
                value = chunk.get(key)
                if isinstance(value, (bytes, bytearray)):
                    return bytes(value)
        return b""

    def _enrich_with_subscription_and_memory(
        self,
        text: str,
        subscription_context: str,
        memory_context: Optional[Dict[str, Any]]
    ) -> str:
        """
        –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ —Å subscription context –∏ memory context.
        
        –ü–æ—Ä—è–¥–æ–∫:
        1) subscription_context
        2) memory_context
        3) —Ç–µ–∫—Å—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        """
        if not subscription_context:
            return self._enrich_with_memory(text, memory_context)
        
        enriched_text = self._enrich_with_memory(text, memory_context)
        if enriched_text:
            return f"{subscription_context}\n\n{enriched_text}"
        return subscription_context

    def _enrich_with_memory(self, text: str, memory_context: Optional[Dict[str, Any]]) -> str:
        """
        –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –ø–∞–º—è—Ç–∏

        Args:
            text: –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç
            memory_context: –ö–æ–Ω—Ç–µ–∫—Å—Ç –ø–∞–º—è—Ç–∏ (–¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å–ª–æ–≤–∞—Ä–µ–º)
        """
        if not memory_context:
            return text

        # ‚ö†Ô∏è CRITICAL: –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ memory_context - —ç—Ç–æ —Å–ª–æ–≤–∞—Ä—å
        if not isinstance(memory_context, dict):
            logger.warning(
                f"‚ö†Ô∏è Memory context is not a dict (type={type(memory_context).__name__}), skipping enrichment"
            )
            return text

        try:
            memory_info = memory_context.get('recent_context', '') if memory_context else ''
            if memory_info:
                enriched_text = f"–ö–æ–Ω—Ç–µ–∫—Å—Ç: {memory_info}\n\n{text}"
                logger.debug("–¢–µ–∫—Å—Ç –æ–±–æ–≥–∞—â–µ–Ω –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –ø–∞–º—è—Ç–∏")
                return enriched_text
            return text
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–±–æ–≥–∞—â–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –ø–∞–º—è—Ç—å—é: {e}")
            return text

    async def _stream_audio_for_sentence(self, sentence: str, sentence_index: int) -> AsyncGenerator[bytes, None]:
        """–°—Ç—Ä–∏–º–∏—Ç –∞—É–¥–∏–æ —á–∞–Ω–∫–∏ –¥–ª—è –æ–¥–Ω–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è."""
        if not sentence.strip():
            return
        if not self.audio_module:
            logger.warning("‚ö†Ô∏è AudioProcessor –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –∞—É–¥–∏–æ")
            return
        if hasattr(self.audio_module, 'process'):
            try:
                logger.info(f"üîä –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∞—É–¥–∏–æ –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è #{sentence_index}: '{sentence[:80]}...'")
                chunk_count = 0
                async for chunk in self._stream_audio_module(sentence):
                    audio_chunk = self._extract_audio_chunk(chunk)
                    if audio_chunk:
                        chunk_count += 1
                        logger.info(f"üîä Audio chunk #{chunk_count} –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è #{sentence_index}: {len(audio_chunk)} bytes")
                        yield audio_chunk
                logger.info(f"‚úÖ –ê—É–¥–∏–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è #{sentence_index}: {chunk_count} —á–∞–Ω–∫–æ–≤")
            except Exception as audio_error:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∞—É–¥–∏–æ –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è #{sentence_index}: {audio_error}")
        elif hasattr(self.audio_module, 'generate_speech_streaming'):
            # Legacy fallback
            try:
                logger.info(f"üîä Legacy –∞—É–¥–∏–æ –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è #{sentence_index}: '{sentence[:80]}...'")
                chunk_count = 0
                async for audio_chunk in self.audio_module.generate_speech_streaming(sentence):
                    if audio_chunk:
                        chunk_count += 1
                        logger.info(f"üîä Audio chunk #{chunk_count} –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è #{sentence_index}: {len(audio_chunk)} bytes")
                        yield audio_chunk
                logger.info(f"‚úÖ Legacy –∞—É–¥–∏–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è #{sentence_index}: {chunk_count} —á–∞–Ω–∫–æ–≤")
            except Exception as audio_error:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ legacy –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∞—É–¥–∏–æ –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è #{sentence_index}: {audio_error}")
    
    async def _parse_assistant_response(self, response: Union[str, Dict[str, Any]], session_id: str):
        """
        –ü–∞—Ä—Å–∏–Ω–≥ –æ—Ç–≤–µ—Ç–∞ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è text –∏ command_payload (–§–∞–∑–∞ 2)
        
        Args:
            response: –û—Ç–≤–µ—Ç –æ—Ç —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –º–æ–¥—É–ª—è (—Å—Ç—Ä–æ–∫–∞ –∏–ª–∏ —Å–ª–æ–≤–∞—Ä—å)
            session_id: ID —Å–µ—Å—Å–∏–∏ –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
            
        Returns:
            ParsedResponse —Å text_response –∏ –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–º command_payload
        """
        try:
            config = get_config()
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–∏—á–∞-—Ñ–ª–∞–≥ –∏ kill-switch
            if (not config.features.forward_assistant_actions or 
                config.kill_switches.disable_forward_assistant_actions):
                # –§–∏—á–∞ –≤—ã–∫–ª—é—á–µ–Ω–∞ - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç
                if isinstance(response, dict):
                    return self._assistant_parser.parse(response.get('text', str(response)))
                return self._assistant_parser.parse(response)
            
            # –ü–∞—Ä—Å–∏–º –æ—Ç–≤–µ—Ç, –ø–µ—Ä–µ–¥–∞–≤–∞—è session_id –¥–ª—è –ø–æ–¥—Å—Ç–∞–Ω–æ–≤–∫–∏ –≤ action-–æ—Ç–≤–µ—Ç—ã
            return self._assistant_parser.parse(response, session_id=session_id)
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ—Ç–≤–µ—Ç–∞ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞: {e}, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç")
            # Fallback –Ω–∞ –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç
            if isinstance(response, dict):
                text = response.get('text', str(response))
            else:
                text = str(response)
            return self._assistant_parser.parse(text)
    
    def _log_command_detected(self, parsed, session_id: str):
        """
        –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –∫–æ–º–∞–Ω–¥—ã (–§–∞–∑–∞ 2)
        
        Args:
            parsed: ParsedResponse —Å command_payload
            session_id: ID —Å–µ—Å—Å–∏–∏
        """
        if not parsed.command_payload:
            return
        
        payload = parsed.command_payload.get('payload', {})
        command = payload.get('command', 'unknown')
        args = payload.get('args', {})
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º feature_id –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∫–æ–º–∞–Ω–¥—ã
        if command == 'open_app':
            feature_id = 'F-2025-013-open-app'
        elif command == 'close_app':
            feature_id = 'F-2025-014-close-app'
        elif command in ('create_subscription', 'cancel_subscription'):
            feature_id = 'F-2025-017-stripe-payment'
        else:
            feature_id = 'F-2025-016-mcp-app-opening-integration'
        
        log_structured(
            logger,
            logging.INFO,
            f"[{feature_id}] Command detected: {command}",
            scope="command",
            method="parse_assistant_response",
            decision="start",
            ctx={
                "session_id": session_id,
                "command": command,
                "args": args,
                "feature_id": feature_id
            }
        )
    
    def _log_command_complete(self, session_id: str):
        """
        –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ–≥–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∫–æ–º–∞–Ω–¥—ã (–§–∞–∑–∞ 2)
        
        Args:
            session_id: ID —Å–µ—Å—Å–∏–∏
        """
        if not self._pending_command_payload:
            return
        
        payload = self._pending_command_payload.get('payload', {})
        command = payload.get('command', 'unknown')
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º feature_id –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∫–æ–º–∞–Ω–¥—ã
        if command == 'open_app':
            feature_id = 'F-2025-013-open-app'
        elif command == 'close_app':
            feature_id = 'F-2025-014-close-app'
        elif command in ('create_subscription', 'cancel_subscription'):
            feature_id = 'F-2025-017-stripe-payment'
        else:
            feature_id = 'F-2025-016-mcp-app-opening-integration'
        
        log_structured(
            logger,
            logging.INFO,
            f"[{feature_id}] Command forwarded: {command}",
            scope="command",
            method="process_request_streaming",
            decision="complete",
            ctx={
                "session_id": session_id,
                "command": command,
                "feature_id": feature_id
            }
        )
    
    def _extract_json_from_markdown(self, text: str) -> str:
        """
        –£–¥–∞–ª—è–µ—Ç Markdown-–æ–±—ë—Ä—Ç–∫–∏ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —á–∏—Å—Ç—ã–π JSON —Ç–µ–∫—Å—Ç.
        –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ä–∞–∑–ª–∏—á–Ω—ã–µ –≤–∞—Ä–∏–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–æ–≤ LLM:
        - ```json {...}```
        - ``` {...}```
        - json {...}
        - –¢–µ–∫—Å—Ç –¥–æ/–ø–æ—Å–ª–µ JSON
        - –ß–∞—Å—Ç–∏—á–Ω—ã–π JSON (–¥–ª—è –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è)
        - JSON —Å –ª–∏—à–Ω–∏–º–∏ –ø—Ä–æ–±–µ–ª–∞–º–∏/–ø–µ—Ä–µ–Ω–æ—Å–∞–º–∏
        - JSON —Å trailing commas (—É–¥–∞–ª—è—é—Ç—Å—è)
        - JSON —Å –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è–º–∏ (—É–¥–∞–ª—è—é—Ç—Å—è)
        
        Args:
            text: –¢–µ–∫—Å—Ç, –∫–æ—Ç–æ—Ä—ã–π –º–æ–∂–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å JSON –≤ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–∞—Ö
            
        Returns:
            –ß–∏—Å—Ç—ã–π JSON —Ç–µ–∫—Å—Ç –±–µ–∑ markdown-—Ä–∞–∑–º–µ—Ç–∫–∏ –∏ –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤
        """
        if not text:
            return ""

        import re
        
        text = str(text).strip()

        # –í–∞—Ä–∏–∞–Ω—Ç 1: Markdown code fence ```json ... ``` –∏–ª–∏ ``` ... ```
        if text.startswith("```"):
            # –£–¥–∞–ª—è–µ–º –æ—Ç–∫—Ä—ã–≤–∞—é—â–∏–π fence
            text = text[3:]
            text = text.lstrip()
            
            # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π —è–∑—ã–∫ (json/JSON/JSONC –∏ —Ç.–¥.)
            lowered = text.lower()
            if lowered.startswith("json"):
                text = text[4:]
            text = text.lstrip()
            
            # –£–¥–∞–ª—è–µ–º –≤–µ–¥—É—â–∏–µ –ø–µ—Ä–µ–≤–æ–¥—ã —Å—Ç—Ä–æ–∫–∏
            while text.startswith(("\n", "\r")):
                text = text[1:]
            
            # –£–¥–∞–ª—è–µ–º –∑–∞–∫—Ä—ã–≤–∞—é—â–∏–π fence (–º–æ–∂–µ—Ç –±—ã—Ç—å –≤ –∫–æ–Ω—Ü–µ –∏–ª–∏ –≤ —Å–µ—Ä–µ–¥–∏–Ω–µ –¥–ª—è —á–∞—Å—Ç–∏—á–Ω–æ–≥–æ JSON)
            text = text.rstrip()
            if text.endswith("```"):
                text = text[:-3]
            text = text.strip()

        # –í–∞—Ä–∏–∞–Ω—Ç 2: –¢–µ–∫—Å—Ç –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å "json" (–±–µ–∑ markdown)
        # –£–¥–∞–ª—è–µ–º "json" –µ—Å–ª–∏ –æ–Ω —Å—Ç–æ–∏—Ç –ø–µ—Ä–µ–¥ JSON –æ–±—ä–µ–∫—Ç–æ–º
        text_lower = text.lower()
        if text_lower.startswith("json") and len(text) > 4:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –ø–æ—Å–ª–µ "json" –∏–¥—ë—Ç –ø—Ä–æ–±–µ–ª/–ø–µ—Ä–µ–Ω–æ—Å –∏ –∑–∞—Ç–µ–º {
            after_json = text[4:].lstrip()
            if after_json.startswith("{") or after_json.startswith("\n{") or after_json.startswith("\r{"):
                text = after_json

        # –í–∞—Ä–∏–∞–Ω—Ç 3: –¢–µ–∫—Å—Ç –¥–æ/–ø–æ—Å–ª–µ JSON - –∏–∑–≤–ª–µ–∫–∞–µ–º —Ç–æ–ª—å–∫–æ JSON –æ–±—ä–µ–∫—Ç
        # –ò—â–µ–º –ø–µ—Ä–≤—É—é –æ—Ç–∫—Ä—ã–≤–∞—é—â—É—é —Å–∫–æ–±–∫—É –∏ –ø–æ—Å–ª–µ–¥–Ω—é—é –∑–∞–∫—Ä—ã–≤–∞—é—â—É—é
        first_brace = text.find("{")
        last_brace = text.rfind("}")
        
        if first_brace != -1 and last_brace != -1 and first_brace < last_brace:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º JSON –æ–±—ä–µ–∫—Ç
            json_candidate = text[first_brace:last_brace + 1]
            
            # –û—á–∏—â–∞–µ–º –æ—Ç –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤ –≤–æ–∫—Ä—É–≥
            json_candidate = json_candidate.strip()
            
            # –£–¥–∞–ª—è–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã:
            # 1. –£–¥–∞–ª—è–µ–º –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ (// –∏ /* */) - —Ö–æ—Ç—è JSON –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç, LLM –º–æ–∂–µ—Ç –∏—Ö –¥–æ–±–∞–≤–∏—Ç—å
            json_candidate = re.sub(r'//.*?$', '', json_candidate, flags=re.MULTILINE)  # –û–¥–Ω–æ—Å—Ç—Ä–æ—á–Ω—ã–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏
            json_candidate = re.sub(r'/\*.*?\*/', '', json_candidate, flags=re.DOTALL)  # –ú–Ω–æ–≥–æ—Å—Ç—Ä–æ—á–Ω—ã–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏
            
            # 2. –£–¥–∞–ª—è–µ–º trailing commas –ø–µ—Ä–µ–¥ –∑–∞–∫—Ä—ã–≤–∞—é—â–∏–º–∏ —Å–∫–æ–±–∫–∞–º–∏/—Ñ–∏–≥—É—Ä–Ω—ã–º–∏ —Å–∫–æ–±–∫–∞–º–∏
            json_candidate = re.sub(r',\s*}', '}', json_candidate)  # Trailing comma –ø–µ—Ä–µ–¥ }
            json_candidate = re.sub(r',\s*]', ']', json_candidate)  # Trailing comma –ø–µ—Ä–µ–¥ ]
            
            # 3. –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø—Ä–æ–±–µ–ª—ã –∏ –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫
            json_candidate = re.sub(r'\n\s*\n', '\n', json_candidate)  # –£–¥–∞–ª—è–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
            json_candidate = re.sub(r'[ \t]+', ' ', json_candidate)  # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø—Ä–æ–±–µ–ª—ã
            
            # 4. –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –≤–æ–∫—Ä—É–≥ –¥–≤–æ–µ—Ç–æ—á–∏–π –∏ –∑–∞–ø—è—Ç—ã—Ö
            json_candidate = re.sub(r'\s*:\s*', ': ', json_candidate)  # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø—Ä–æ–±–µ–ª—ã –≤–æ–∫—Ä—É–≥ :
            json_candidate = re.sub(r'\s*,\s*', ', ', json_candidate)  # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø—Ä–æ–±–µ–ª—ã –≤–æ–∫—Ä—É–≥ ,
            
            return json_candidate

        # –ï—Å–ª–∏ JSON –æ–±—ä–µ–∫—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—á–∏—â–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
        # (–º–æ–∂–µ—Ç –±—ã—Ç—å —á–∞—Å—Ç–∏—á–Ω—ã–π JSON –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è)
        return text.strip()

    def _split_into_sentences(self, text: str) -> list[str]:
        """
        –†–∞–∑–±–∏–≤–∫–∞ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
        
        Args:
            text: –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç
            
        Returns:
            –°–ø–∏—Å–æ–∫ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
        """
        try:
            # –ü—Ä–æ—Å—Ç–∞—è —Ä–∞–∑–±–∏–≤–∫–∞ –ø–æ —Ç–æ—á–∫–∞–º, –≤–æ—Å–∫–ª–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–º –∏ –≤–æ–ø—Ä–æ—Å–∏—Ç–µ–ª—å–Ω—ã–º –∑–Ω–∞–∫–∞–º
            import re
            sentences = re.split(r'[.!?]+', text)
            
            # –û—á–∏—â–∞–µ–º –æ—Ç –ø—É—Å—Ç—ã—Ö —Å—Ç—Ä–æ–∫ –∏ –ª–∏—à–Ω–∏—Ö –ø—Ä–æ–±–µ–ª–æ–≤
            clean_sentences = [s.strip() for s in sentences if s.strip()]
            
            logger.debug(f"–¢–µ–∫—Å—Ç —Ä–∞–∑–±–∏—Ç –Ω–∞ {len(clean_sentences)} –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π")
            return clean_sentences
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Ä–∞–∑–±–∏–≤–∫–∏ —Ç–µ–∫—Å—Ç–∞: {e}")
            return [text]  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –≤–µ—Å—å —Ç–µ–∫—Å—Ç –∫–∞–∫ –æ–¥–Ω–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ
    
    async def cleanup(self):
        """–û—á–∏—Å—Ç–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤"""
        try:
            logger.info("–û—á–∏—Å—Ç–∫–∞ StreamingWorkflowIntegration...")
            self.is_initialized = False
            logger.info("‚úÖ StreamingWorkflowIntegration –æ—á–∏—â–µ–Ω")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ StreamingWorkflowIntegration: {e}")

    async def _get_memory_context_parallel(self, hardware_id: str) -> Optional[Dict[str, Any]]:
        """
        –ù–µ–±–ª–æ–∫–∏—Ä—É—é—â–µ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø–∞–º—è—Ç–∏
        
        Args:
            hardware_id: –ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è
        """
        try:
            if not self.memory_workflow:
                logger.debug("MemoryWorkflow –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –ø–æ–ª—É—á–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏")
                return None
            
            logger.debug(f"–ü–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø–∞–º—è—Ç–∏ –¥–ª—è {hardware_id}")
            memory_context = await self.memory_workflow.get_memory_context_parallel(hardware_id)
            
            if memory_context:
                logger.debug(f"‚úÖ –ü–æ–ª—É—á–µ–Ω –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø–∞–º—è—Ç–∏: {len(memory_context)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤")
            else:
                logger.debug("‚ö†Ô∏è –ö–æ–Ω—Ç–µ–∫—Å—Ç –ø–∞–º—è—Ç–∏ –ø—É—Å—Ç")
            
            return memory_context
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø–∞–º—è—Ç–∏: {e}")
            return None

    async def _iter_processed_sentences(
        self,
        text: str,
        screenshot: Optional[str],
        memory_context: Optional[Dict[str, Any]],
        subscription_context: str = ""  # MVP 7: Subscription context (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)
    ) -> AsyncGenerator[str, None]:
        """–°—Ç—Ä–∏–º–∏–Ω–≥–æ–≤–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è —Å —É—á—ë—Ç–æ–º –ø–∞–º—è—Ç–∏, subscription context –∏ —Å–∫—Ä–∏–Ω—à–æ—Ç–∞."""
        # MVP 7: –û–±–æ–≥–∞—â–∞–µ–º —Ç–µ–∫—Å—Ç subscription context –∏ memory context
        if subscription_context:
            enriched_text = self._enrich_with_subscription_and_memory(text, subscription_context, memory_context)
        else:
            enriched_text = self._enrich_with_memory(text, memory_context)

        screenshot_data: Optional[bytes] = None
        if screenshot:
            import base64
            try:
                screenshot_data = base64.b64decode(screenshot)
                logger.info(f"üì∏ –°–∫—Ä–∏–Ω—à–æ—Ç –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω: {len(screenshot_data)} bytes")
            except Exception as decode_error:
                logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞—Ç—å —Å–∫—Ä–∏–Ω—à–æ—Ç: {decode_error}")
                screenshot_data = None

        yielded_any = False
        if self.text_module and hasattr(self.text_module, 'process'):
            logger.info(f"üîÑ –°—Ç—Ä–∏–º–∏–Ω–≥ —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ Text Module: '{enriched_text[:80]}...'")
            try:
                async for chunk in self._stream_text_module(enriched_text, screenshot_data):
                    sentence = (self._extract_text_chunk(chunk) or '').strip()
                    if sentence:
                        yielded_any = True
                        logger.debug(f"üì® TextModule sentence: '{sentence[:120]}...'")
                        yield sentence
            except Exception as processing_error:
                logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ Text Module: {processing_error}. –ò—Å–ø–æ–ª—å–∑—É–µ–º fallback")
        elif self.text_module and hasattr(self.text_module, 'process_text_streaming'):
            # Legacy fallback –Ω–∞ –ø—Ä—è–º–æ–π –¥–æ—Å—Ç—É–ø –∫ TextProcessor
            logger.info(f"üîÑ Legacy —Å—Ç—Ä–∏–º–∏–Ω–≥ —Ç–µ–∫—Å—Ç–∞: '{enriched_text[:80]}...'")
            try:
                async for processed_sentence in self.text_module.process_text_streaming(enriched_text, screenshot_data):
                    sentence = (processed_sentence or '').strip()
                    if sentence:
                        yielded_any = True
                        logger.debug(f"üì® Legacy TextProcessor sentence: '{sentence[:120]}...'")
                        yield sentence
            except Exception as processing_error:
                logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ legacy TextProcessor: {processing_error}. –ò—Å–ø–æ–ª—å–∑—É–µ–º fallback")

        if not yielded_any:
            logger.debug("‚ö†Ô∏è TextProcessor –Ω–µ –≤–µ—Ä–Ω—É–ª –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π, –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback —Ä–∞–∑–±–∏–≤–∫—É")
            for fallback_sentence in self._split_into_sentences(enriched_text):
                if fallback_sentence:
                    yield fallback_sentence

    async def _sanitize_for_tts(self, text: str) -> str:
        """
        –û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è —Å–∏–Ω—Ç–µ–∑–∞ —Ä–µ—á–∏ —á–µ—Ä–µ–∑ –º–æ–¥—É–ª—å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        """
        if not text:
            return ""

        if self.text_filter_module and hasattr(self.text_filter_module, 'process'):
            try:
                result = await self.text_filter_module.process({
                    "operation": "clean_text",
                    "text": text,
                    "options": {
                        "remove_special_chars": True,
                        "remove_extra_whitespace": True,
                        "normalize_unicode": True,
                        "remove_control_chars": True
                    }
                })
                if isinstance(result, dict) and result.get("success") and result.get("cleaned_text") is not None:
                    return result.get("cleaned_text", "").strip()
            except Exception as err:
                logger.warning("‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ TextFilterModule: %s", err)

        return text.strip()

    async def _split_complete_sentences(self, text: str) -> tuple[list[str], str]:
        """
        –†–∞–∑–±–∏–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è —á–µ—Ä–µ–∑ –º–æ–¥—É–ª—å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        """
        if not text:
            return [], ""

        if self.text_filter_module and hasattr(self.text_filter_module, 'process'):
            try:
                result = await self.text_filter_module.process({
                    "operation": "split_sentences",
                    "text": text
                })
                if isinstance(result, dict) and result.get("success"):
                    return result.get("sentences", []), result.get("remainder", "")
            except Exception as err:
                logger.warning("‚ö†Ô∏è –û—à–∏–±–∫–∞ —Ä–∞–∑–±–∏–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ TextFilterModule: %s", err)

        stripped = text.strip()
        return ([stripped] if stripped else [], "")

    async def _count_meaningful_words(self, text: str) -> int:
        """
        –ü–æ–¥—Å—á—ë—Ç –∑–Ω–∞—á–∏–º—ã—Ö —Å–ª–æ–≤ —á–µ—Ä–µ–∑ –º–æ–¥—É–ª—å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        """
        if not text:
            return 0

        if self.text_filter_module and hasattr(self.text_filter_module, 'process'):
            try:
                result = await self.text_filter_module.process({
                    "operation": "count_meaningful_words",
                    "text": text
                })
                if isinstance(result, dict) and result.get("success"):
                    return int(result.get("count", 0))
            except Exception as err:
                logger.warning("‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–¥—Å—á—ë—Ç–∞ —Å–ª–æ–≤ —á–µ—Ä–µ–∑ TextFilterModule: %s", err)

        return len([w for w in text.split() if w.strip()])

    async def _stream_text_module(self, text: str, screenshot_data: Optional[bytes]):
        """–°—Ç—Ä–∏–º–∏–Ω–≥ –æ—Ç–≤–µ—Ç–æ–≤ –∏–∑ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –º–æ–¥—É–ª—è."""
        payload = {"text": text}
        if screenshot_data:
            payload["image_data"] = screenshot_data

        async for chunk in self._stream_module_results(self.text_module, payload):
            yield chunk

    async def _stream_audio_module(self, text: str):
        """–°—Ç—Ä–∏–º–∏–Ω–≥ –∞—É–¥–∏–æ —á–∞–Ω–∫–æ–≤ –∏–∑ –∞—É–¥–∏–æ –º–æ–¥—É–ª—è."""
        async for chunk in self._stream_module_results(self.audio_module, {"text": text}):
            yield chunk

    async def _stream_module_results(self, module, payload: Dict[str, Any]):
        """–£–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≤—ã–∑–æ–≤ module.process —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π async generator."""
        if not module or not hasattr(module, 'process'):
            return
        try:
            result = await module.process(payload)
            if result is None:
                return
            if hasattr(result, "__aiter__"):
                async for item in result:
                    yield item
            else:
                yield result
        except Exception as err:
            logger.warning("‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ –º–æ–¥—É–ª—è %s: %s", getattr(module, 'name', 'unknown'), err)

    def _extract_text_chunk(self, chunk: Any) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç–≤–µ—Ç –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –º–æ–¥—É–ª—è."""
        if chunk is None:
            return ""
        if isinstance(chunk, str):
            return chunk
        if isinstance(chunk, dict):
            for key in ("text", "text_response", "value", "chunk"):
                value = chunk.get(key)
                if isinstance(value, str):
                    return value
        return ""

    def _extract_audio_chunk(self, chunk: Any) -> bytes:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∞—É–¥–∏–æ –±–∞–π—Ç—ã –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –º–æ–¥—É–ª—è."""
        if chunk is None:
            return b""
        if isinstance(chunk, (bytes, bytearray)):
            return bytes(chunk)
        if isinstance(chunk, dict):
            for key in ("audio", "audio_chunk", "audio_data", "data", "value"):
                value = chunk.get(key)
                if isinstance(value, (bytes, bytearray)):
                    return bytes(value)
        return b""

    def _enrich_with_memory(self, text: str, memory_context: Optional[Dict[str, Any]]) -> str:
        """
        –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –ø–∞–º—è—Ç–∏

        Args:
            text: –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç
            memory_context: –ö–æ–Ω—Ç–µ–∫—Å—Ç –ø–∞–º—è—Ç–∏ (–¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å–ª–æ–≤–∞—Ä–µ–º)
        """
        if not memory_context:
            return text

        # ‚ö†Ô∏è CRITICAL: –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ memory_context - —ç—Ç–æ —Å–ª–æ–≤–∞—Ä—å
        if not isinstance(memory_context, dict):
            logger.warning(
                f"‚ö†Ô∏è Memory context is not a dict (type={type(memory_context).__name__}), skipping enrichment"
            )
            return text

        try:
            memory_info = memory_context.get('recent_context', '') if memory_context else ''
            if memory_info:
                enriched_text = f"–ö–æ–Ω—Ç–µ–∫—Å—Ç: {memory_info}\n\n{text}"
                logger.debug("–¢–µ–∫—Å—Ç –æ–±–æ–≥–∞—â–µ–Ω –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –ø–∞–º—è—Ç–∏")
                return enriched_text
            return text
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–±–æ–≥–∞—â–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –ø–∞–º—è—Ç—å—é: {e}")
            return text

    async def _stream_audio_for_sentence(self, sentence: str, sentence_index: int) -> AsyncGenerator[bytes, None]:
        """–°—Ç—Ä–∏–º–∏—Ç –∞—É–¥–∏–æ —á–∞–Ω–∫–∏ –¥–ª—è –æ–¥–Ω–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è."""
        if not sentence.strip():
            return
        if not self.audio_module:
            logger.warning("‚ö†Ô∏è AudioProcessor –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –∞—É–¥–∏–æ")
            return
        if hasattr(self.audio_module, 'process'):
            try:
                logger.info(f"üîä –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∞—É–¥–∏–æ –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è #{sentence_index}: '{sentence[:80]}...'")
                chunk_count = 0
                async for chunk in self._stream_audio_module(sentence):
                    audio_chunk = self._extract_audio_chunk(chunk)
                    if audio_chunk:
                        chunk_count += 1
                        logger.info(f"üîä Audio chunk #{chunk_count} –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è #{sentence_index}: {len(audio_chunk)} bytes")
                        yield audio_chunk
                logger.info(f"‚úÖ –ê—É–¥–∏–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è #{sentence_index}: {chunk_count} —á–∞–Ω–∫–æ–≤")
            except Exception as audio_error:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∞—É–¥–∏–æ –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è #{sentence_index}: {audio_error}")
        elif hasattr(self.audio_module, 'generate_speech_streaming'):
            # Legacy fallback
            try:
                logger.info(f"üîä Legacy –∞—É–¥–∏–æ –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è #{sentence_index}: '{sentence[:80]}...'")
                chunk_count = 0
                async for audio_chunk in self.audio_module.generate_speech_streaming(sentence):
                    if audio_chunk:
                        chunk_count += 1
                        logger.info(f"üîä Audio chunk #{chunk_count} –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è #{sentence_index}: {len(audio_chunk)} bytes")
                        yield audio_chunk
                logger.info(f"‚úÖ Legacy –∞—É–¥–∏–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è #{sentence_index}: {chunk_count} —á–∞–Ω–∫–æ–≤")
            except Exception as audio_error:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ legacy –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∞—É–¥–∏–æ –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è #{sentence_index}: {audio_error}")
    
    async def _parse_assistant_response(self, response: Union[str, Dict[str, Any]], session_id: str):
        """
        –ü–∞—Ä—Å–∏–Ω–≥ –æ—Ç–≤–µ—Ç–∞ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è text –∏ command_payload (–§–∞–∑–∞ 2)
        
        Args:
            response: –û—Ç–≤–µ—Ç –æ—Ç —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –º–æ–¥—É–ª—è (—Å—Ç—Ä–æ–∫–∞ –∏–ª–∏ —Å–ª–æ–≤–∞—Ä—å)
            session_id: ID —Å–µ—Å—Å–∏–∏ –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
            
        Returns:
            ParsedResponse —Å text_response –∏ –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–º command_payload
        """
        try:
            config = get_config()
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–∏—á–∞-—Ñ–ª–∞–≥ –∏ kill-switch
            if (not config.features.forward_assistant_actions or 
                config.kill_switches.disable_forward_assistant_actions):
                # –§–∏—á–∞ –≤—ã–∫–ª—é—á–µ–Ω–∞ - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç
                if isinstance(response, dict):
                    return self._assistant_parser.parse(response.get('text', str(response)))
                return self._assistant_parser.parse(response)
            
            # –ü–∞—Ä—Å–∏–º –æ—Ç–≤–µ—Ç, –ø–µ—Ä–µ–¥–∞–≤–∞—è session_id –¥–ª—è –ø–æ–¥—Å—Ç–∞–Ω–æ–≤–∫–∏ –≤ action-–æ—Ç–≤–µ—Ç—ã
            return self._assistant_parser.parse(response, session_id=session_id)
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ—Ç–≤–µ—Ç–∞ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞: {e}, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç")
            # Fallback –Ω–∞ –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç
            if isinstance(response, dict):
                text = response.get('text', str(response))
            else:
                text = str(response)
            return self._assistant_parser.parse(text)
    
    def _log_command_detected(self, parsed, session_id: str):
        """
        –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –∫–æ–º–∞–Ω–¥—ã (–§–∞–∑–∞ 2)
        
        Args:
            parsed: ParsedResponse —Å command_payload
            session_id: ID —Å–µ—Å—Å–∏–∏
        """
        if not parsed.command_payload:
            return
        
        payload = parsed.command_payload.get('payload', {})
        command = payload.get('command', 'unknown')
        args = payload.get('args', {})
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º feature_id –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∫–æ–º–∞–Ω–¥—ã
        if command == 'open_app':
            feature_id = 'F-2025-013-open-app'
        elif command == 'close_app':
            feature_id = 'F-2025-014-close-app'
        elif command in ('create_subscription', 'cancel_subscription'):
            feature_id = 'F-2025-017-stripe-payment'
        else:
            feature_id = 'F-2025-016-mcp-app-opening-integration'
        
        log_structured(
            logger,
            logging.INFO,
            f"[{feature_id}] Command detected: {command}",
            scope="command",
            method="parse_assistant_response",
            decision="start",
            ctx={
                "session_id": session_id,
                "command": command,
                "args": args,
                "feature_id": feature_id
            }
        )
    
    def _log_command_complete(self, session_id: str):
        """
        –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ–≥–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∫–æ–º–∞–Ω–¥—ã (–§–∞–∑–∞ 2)
        
        Args:
            session_id: ID —Å–µ—Å—Å–∏–∏
        """
        if not self._pending_command_payload:
            return
        
        payload = self._pending_command_payload.get('payload', {})
        command = payload.get('command', 'unknown')
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º feature_id –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∫–æ–º–∞–Ω–¥—ã
        if command == 'open_app':
            feature_id = 'F-2025-013-open-app'
        elif command == 'close_app':
            feature_id = 'F-2025-014-close-app'
        elif command in ('create_subscription', 'cancel_subscription'):
            feature_id = 'F-2025-017-stripe-payment'
        else:
            feature_id = 'F-2025-016-mcp-app-opening-integration'
        
        log_structured(
            logger,
            logging.INFO,
            f"[{feature_id}] Command forwarded: {command}",
            scope="command",
            method="process_request_streaming",
            decision="complete",
            ctx={
                "session_id": session_id,
                "command": command,
                "feature_id": feature_id
            }
        )
    
    def _extract_json_from_markdown(self, text: str) -> str:
        """
        –£–¥–∞–ª—è–µ—Ç Markdown-–æ–±—ë—Ä—Ç–∫–∏ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —á–∏—Å—Ç—ã–π JSON —Ç–µ–∫—Å—Ç.
        –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ä–∞–∑–ª–∏—á–Ω—ã–µ –≤–∞—Ä–∏–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–æ–≤ LLM:
        - ```json {...}```
        - ``` {...}```
        - json {...}
        - –¢–µ–∫—Å—Ç –¥–æ/–ø–æ—Å–ª–µ JSON
        - –ß–∞—Å—Ç–∏—á–Ω—ã–π JSON (–¥–ª—è –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è)
        - JSON —Å –ª–∏—à–Ω–∏–º–∏ –ø—Ä–æ–±–µ–ª–∞–º–∏/–ø–µ—Ä–µ–Ω–æ—Å–∞–º–∏
        - JSON —Å trailing commas (—É–¥–∞–ª—è—é—Ç—Å—è)
        - JSON —Å –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è–º–∏ (—É–¥–∞–ª—è—é—Ç—Å—è)
        
        Args:
            text: –¢–µ–∫—Å—Ç, –∫–æ—Ç–æ—Ä—ã–π –º–æ–∂–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å JSON –≤ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–∞—Ö
            
        Returns:
            –ß–∏—Å—Ç—ã–π JSON —Ç–µ–∫—Å—Ç –±–µ–∑ markdown-—Ä–∞–∑–º–µ—Ç–∫–∏ –∏ –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤
        """
        if not text:
            return ""

        import re
        
        text = str(text).strip()

        # –í–∞—Ä–∏–∞–Ω—Ç 1: Markdown code fence ```json ... ``` –∏–ª–∏ ``` ... ```
        if text.startswith("```"):
            # –£–¥–∞–ª—è–µ–º –æ—Ç–∫—Ä—ã–≤–∞—é—â–∏–π fence
            text = text[3:]
            text = text.lstrip()
            
            # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π —è–∑—ã–∫ (json/JSON/JSONC –∏ —Ç.–¥.)
            lowered = text.lower()
            if lowered.startswith("json"):
                text = text[4:]
            text = text.lstrip()
            
            # –£–¥–∞–ª—è–µ–º –≤–µ–¥—É—â–∏–µ –ø–µ—Ä–µ–≤–æ–¥—ã —Å—Ç—Ä–æ–∫–∏
            while text.startswith(("\n", "\r")):
                text = text[1:]
            
            # –£–¥–∞–ª—è–µ–º –∑–∞–∫—Ä—ã–≤–∞—é—â–∏–π fence (–º–æ–∂–µ—Ç –±—ã—Ç—å –≤ –∫–æ–Ω—Ü–µ –∏–ª–∏ –≤ —Å–µ—Ä–µ–¥–∏–Ω–µ –¥–ª—è —á–∞—Å—Ç–∏—á–Ω–æ–≥–æ JSON)
            text = text.rstrip()
            if text.endswith("```"):
                text = text[:-3]
            text = text.strip()

        # –í–∞—Ä–∏–∞–Ω—Ç 2: –¢–µ–∫—Å—Ç –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å "json" (–±–µ–∑ markdown)
        # –£–¥–∞–ª—è–µ–º "json" –µ—Å–ª–∏ –æ–Ω —Å—Ç–æ–∏—Ç –ø–µ—Ä–µ–¥ JSON –æ–±—ä–µ–∫—Ç–æ–º
        text_lower = text.lower()
        if text_lower.startswith("json") and len(text) > 4:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –ø–æ—Å–ª–µ "json" –∏–¥—ë—Ç –ø—Ä–æ–±–µ–ª/–ø–µ—Ä–µ–Ω–æ—Å –∏ –∑–∞—Ç–µ–º {
            after_json = text[4:].lstrip()
            if after_json.startswith("{") or after_json.startswith("\n{") or after_json.startswith("\r{"):
                text = after_json

        # –í–∞—Ä–∏–∞–Ω—Ç 3: –¢–µ–∫—Å—Ç –¥–æ/–ø–æ—Å–ª–µ JSON - –∏–∑–≤–ª–µ–∫–∞–µ–º —Ç–æ–ª—å–∫–æ JSON –æ–±—ä–µ–∫—Ç
        # –ò—â–µ–º –ø–µ—Ä–≤—É—é –æ—Ç–∫—Ä—ã–≤–∞—é—â—É—é —Å–∫–æ–±–∫—É –∏ –ø–æ—Å–ª–µ–¥–Ω—é—é –∑–∞–∫—Ä—ã–≤–∞—é—â—É—é
        first_brace = text.find("{")
        last_brace = text.rfind("}")
        
        if first_brace != -1 and last_brace != -1 and first_brace < last_brace:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º JSON –æ–±—ä–µ–∫—Ç
            json_candidate = text[first_brace:last_brace + 1]
            
            # –û—á–∏—â–∞–µ–º –æ—Ç –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤ –≤–æ–∫—Ä—É–≥
            json_candidate = json_candidate.strip()
            
            # –£–¥–∞–ª—è–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã:
            # 1. –£–¥–∞–ª—è–µ–º –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ (// –∏ /* */) - —Ö–æ—Ç—è JSON –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç, LLM –º–æ–∂–µ—Ç –∏—Ö –¥–æ–±–∞–≤–∏—Ç—å
            json_candidate = re.sub(r'//.*?$', '', json_candidate, flags=re.MULTILINE)  # –û–¥–Ω–æ—Å—Ç—Ä–æ—á–Ω—ã–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏
            json_candidate = re.sub(r'/\*.*?\*/', '', json_candidate, flags=re.DOTALL)  # –ú–Ω–æ–≥–æ—Å—Ç—Ä–æ—á–Ω—ã–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏
            
            # 2. –£–¥–∞–ª—è–µ–º trailing commas –ø–µ—Ä–µ–¥ –∑–∞–∫—Ä—ã–≤–∞—é—â–∏–º–∏ —Å–∫–æ–±–∫–∞–º–∏/—Ñ–∏–≥—É—Ä–Ω—ã–º–∏ —Å–∫–æ–±–∫–∞–º–∏
            json_candidate = re.sub(r',\s*}', '}', json_candidate)  # Trailing comma –ø–µ—Ä–µ–¥ }
            json_candidate = re.sub(r',\s*]', ']', json_candidate)  # Trailing comma –ø–µ—Ä–µ–¥ ]
            
            # 3. –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø—Ä–æ–±–µ–ª—ã –∏ –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫
            json_candidate = re.sub(r'\n\s*\n', '\n', json_candidate)  # –£–¥–∞–ª—è–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
            json_candidate = re.sub(r'[ \t]+', ' ', json_candidate)  # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø—Ä–æ–±–µ–ª—ã
            
            # 4. –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –≤–æ–∫—Ä—É–≥ –¥–≤–æ–µ—Ç–æ—á–∏–π –∏ –∑–∞–ø—è—Ç—ã—Ö
            json_candidate = re.sub(r'\s*:\s*', ': ', json_candidate)  # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø—Ä–æ–±–µ–ª—ã –≤–æ–∫—Ä—É–≥ :
            json_candidate = re.sub(r'\s*,\s*', ', ', json_candidate)  # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø—Ä–æ–±–µ–ª—ã –≤–æ–∫—Ä—É–≥ ,
            
            return json_candidate

        # –ï—Å–ª–∏ JSON –æ–±—ä–µ–∫—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—á–∏—â–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
        # (–º–æ–∂–µ—Ç –±—ã—Ç—å —á–∞—Å—Ç–∏—á–Ω—ã–π JSON –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è)
        return text.strip()

    def _split_into_sentences(self, text: str) -> list[str]:
        """
        –†–∞–∑–±–∏–≤–∫–∞ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
        
        Args:
            text: –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç
            
        Returns:
            –°–ø–∏—Å–æ–∫ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
        """
        try:
            # –ü—Ä–æ—Å—Ç–∞—è —Ä–∞–∑–±–∏–≤–∫–∞ –ø–æ —Ç–æ—á–∫–∞–º, –≤–æ—Å–∫–ª–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–º –∏ –≤–æ–ø—Ä–æ—Å–∏—Ç–µ–ª—å–Ω—ã–º –∑–Ω–∞–∫–∞–º
            import re
            sentences = re.split(r'[.!?]+', text)
            
            # –û—á–∏—â–∞–µ–º –æ—Ç –ø—É—Å—Ç—ã—Ö —Å—Ç—Ä–æ–∫ –∏ –ª–∏—à–Ω–∏—Ö –ø—Ä–æ–±–µ–ª–æ–≤
            clean_sentences = [s.strip() for s in sentences if s.strip()]
            
            logger.debug(f"–¢–µ–∫—Å—Ç —Ä–∞–∑–±–∏—Ç –Ω–∞ {len(clean_sentences)} –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π")
            return clean_sentences
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Ä–∞–∑–±–∏–≤–∫–∏ —Ç–µ–∫—Å—Ç–∞: {e}")
            return [text]  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –≤–µ—Å—å —Ç–µ–∫—Å—Ç –∫–∞–∫ –æ–¥–Ω–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ
    
    async def cleanup(self):
        """–û—á–∏—Å—Ç–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤"""
        try:
            logger.info("–û—á–∏—Å—Ç–∫–∞ StreamingWorkflowIntegration...")
            self.is_initialized = False
            logger.info("‚úÖ StreamingWorkflowIntegration –æ—á–∏—â–µ–Ω")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ StreamingWorkflowIntegration: {e}")

    async def _get_memory_context_parallel(self, hardware_id: str) -> Optional[Dict[str, Any]]:
        """
        –ù–µ–±–ª–æ–∫–∏—Ä—É—é—â–µ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø–∞–º—è—Ç–∏
        
        Args:
            hardware_id: –ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è
        """
        try:
            if not self.memory_workflow:
                logger.debug("MemoryWorkflow –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –ø–æ–ª—É—á–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏")
                return None
            
            logger.debug(f"–ü–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø–∞–º—è—Ç–∏ –¥–ª—è {hardware_id}")
            memory_context = await self.memory_workflow.get_memory_context_parallel(hardware_id)
            
            if memory_context:
                logger.debug(f"‚úÖ –ü–æ–ª—É—á–µ–Ω –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø–∞–º—è—Ç–∏: {len(memory_context)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤")
            else:
                logger.debug("‚ö†Ô∏è –ö–æ–Ω—Ç–µ–∫—Å—Ç –ø–∞–º—è—Ç–∏ –ø—É—Å—Ç")
            
            return memory_context
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø–∞–º—è—Ç–∏: {e}")
            return None

    async def _iter_processed_sentences(
        self,
        text: str,
        screenshot: Optional[str],
        memory_context: Optional[Dict[str, Any]],
        subscription_context: str = ""  # MVP 7: Subscription context (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)
    ) -> AsyncGenerator[str, None]:
        """–°—Ç—Ä–∏–º–∏–Ω–≥–æ–≤–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è —Å —É—á—ë—Ç–æ–º –ø–∞–º—è—Ç–∏, subscription context –∏ —Å–∫—Ä–∏–Ω—à–æ—Ç–∞."""
        # MVP 7: –û–±–æ–≥–∞—â–∞–µ–º —Ç–µ–∫—Å—Ç subscription context –∏ memory context
        if subscription_context:
            enriched_text = self._enrich_with_subscription_and_memory(text, subscription_context, memory_context)
        else:
            enriched_text = self._enrich_with_memory(text, memory_context)

        screenshot_data: Optional[bytes] = None
        if screenshot:
            import base64
            try:
                screenshot_data = base64.b64decode(screenshot)
                logger.info(f"üì∏ –°–∫—Ä–∏–Ω—à–æ—Ç –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω: {len(screenshot_data)} bytes")
            except Exception as decode_error:
                logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞—Ç—å —Å–∫—Ä–∏–Ω—à–æ—Ç: {decode_error}")
                screenshot_data = None

        yielded_any = False
        if self.text_module and hasattr(self.text_module, 'process'):
            logger.info(f"üîÑ –°—Ç—Ä–∏–º–∏–Ω–≥ —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ Text Module: '{enriched_text[:80]}...'")
            try:
                async for chunk in self._stream_text_module(enriched_text, screenshot_data):
                    sentence = (self._extract_text_chunk(chunk) or '').strip()
                    if sentence:
                        yielded_any = True
                        logger.debug(f"üì® TextModule sentence: '{sentence[:120]}...'")
                        yield sentence
            except Exception as processing_error:
                logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ Text Module: {processing_error}. –ò—Å–ø–æ–ª—å–∑—É–µ–º fallback")
        elif self.text_module and hasattr(self.text_module, 'process_text_streaming'):
            # Legacy fallback –Ω–∞ –ø—Ä—è–º–æ–π –¥–æ—Å—Ç—É–ø –∫ TextProcessor
            logger.info(f"üîÑ Legacy —Å—Ç—Ä–∏–º–∏–Ω–≥ —Ç–µ–∫—Å—Ç–∞: '{enriched_text[:80]}...'")
            try:
                async for processed_sentence in self.text_module.process_text_streaming(enriched_text, screenshot_data):
                    sentence = (processed_sentence or '').strip()
                    if sentence:
                        yielded_any = True
                        logger.debug(f"üì® Legacy TextProcessor sentence: '{sentence[:120]}...'")
                        yield sentence
            except Exception as processing_error:
                logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ legacy TextProcessor: {processing_error}. –ò—Å–ø–æ–ª—å–∑—É–µ–º fallback")

        if not yielded_any:
            logger.debug("‚ö†Ô∏è TextProcessor –Ω–µ –≤–µ—Ä–Ω—É–ª –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π, –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback —Ä–∞–∑–±–∏–≤–∫—É")
            for fallback_sentence in self._split_into_sentences(enriched_text):
                if fallback_sentence:
                    yield fallback_sentence

    async def _sanitize_for_tts(self, text: str) -> str:
        """
        –û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è —Å–∏–Ω—Ç–µ–∑–∞ —Ä–µ—á–∏ —á–µ—Ä–µ–∑ –º–æ–¥—É–ª—å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        """
        if not text:
            return ""

        if self.text_filter_module and hasattr(self.text_filter_module, 'process'):
            try:
                result = await self.text_filter_module.process({
                    "operation": "clean_text",
                    "text": text,
                    "options": {
                        "remove_special_chars": True,
                        "remove_extra_whitespace": True,
                        "normalize_unicode": True,
                        "remove_control_chars": True
                    }
                })
                if isinstance(result, dict) and result.get("success") and result.get("cleaned_text") is not None:
                    return result.get("cleaned_text", "").strip()
            except Exception as err:
                logger.warning("‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ TextFilterModule: %s", err)

        return text.strip()

    async def _split_complete_sentences(self, text: str) -> tuple[list[str], str]:
        """
        –†–∞–∑–±–∏–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è —á–µ—Ä–µ–∑ –º–æ–¥—É–ª—å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        """
        if not text:
            return [], ""

        if self.text_filter_module and hasattr(self.text_filter_module, 'process'):
            try:
                result = await self.text_filter_module.process({
                    "operation": "split_sentences",
                    "text": text
                })
                if isinstance(result, dict) and result.get("success"):
                    return result.get("sentences", []), result.get("remainder", "")
            except Exception as err:
                logger.warning("‚ö†Ô∏è –û—à–∏–±–∫–∞ —Ä–∞–∑–±–∏–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ TextFilterModule: %s", err)

        stripped = text.strip()
        return ([stripped] if stripped else [], "")

    async def _count_meaningful_words(self, text: str) -> int:
        """
        –ü–æ–¥—Å—á—ë—Ç –∑–Ω–∞—á–∏–º—ã—Ö —Å–ª–æ–≤ —á–µ—Ä–µ–∑ –º–æ–¥—É–ª—å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        """
        if not text:
            return 0

        if self.text_filter_module and hasattr(self.text_filter_module, 'process'):
            try:
                result = await self.text_filter_module.process({
                    "operation": "count_meaningful_words",
                    "text": text
                })
                if isinstance(result, dict) and result.get("success"):
                    return int(result.get("count", 0))
            except Exception as err:
                logger.warning("‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–¥—Å—á—ë—Ç–∞ —Å–ª–æ–≤ —á–µ—Ä–µ–∑ TextFilterModule: %s", err)

        return len([w for w in text.split() if w.strip()])

    async def _stream_text_module(self, text: str, screenshot_data: Optional[bytes]):
        """–°—Ç—Ä–∏–º–∏–Ω–≥ –æ—Ç–≤–µ—Ç–æ–≤ –∏–∑ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –º–æ–¥—É–ª—è."""
        payload = {"text": text}
        if screenshot_data:
            payload["image_data"] = screenshot_data

        async for chunk in self._stream_module_results(self.text_module, payload):
            yield chunk

    async def _stream_audio_module(self, text: str):
        """–°—Ç—Ä–∏–º–∏–Ω–≥ –∞—É–¥–∏–æ —á–∞–Ω–∫–æ–≤ –∏–∑ –∞—É–¥–∏–æ –º–æ–¥—É–ª—è."""
        async for chunk in self._stream_module_results(self.audio_module, {"text": text}):
            yield chunk

    async def _stream_module_results(self, module, payload: Dict[str, Any]):
        """–£–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≤—ã–∑–æ–≤ module.process —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π async generator."""
        if not module or not hasattr(module, 'process'):
            return
        try:
            result = await module.process(payload)
            if result is None:
                return
            if hasattr(result, "__aiter__"):
                async for item in result:
                    yield item
            else:
                yield result
        except Exception as err:
            logger.warning("‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ –º–æ–¥—É–ª—è %s: %s", getattr(module, 'name', 'unknown'), err)

    def _extract_text_chunk(self, chunk: Any) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç–≤–µ—Ç –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –º–æ–¥—É–ª—è."""
        if chunk is None:
            return ""
        if isinstance(chunk, str):
            return chunk
        if isinstance(chunk, dict):
            for key in ("text", "text_response", "value", "chunk"):
                value = chunk.get(key)
                if isinstance(value, str):
                    return value
        return ""

    def _extract_audio_chunk(self, chunk: Any) -> bytes:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∞—É–¥–∏–æ –±–∞–π—Ç—ã –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –º–æ–¥—É–ª—è."""
        if chunk is None:
            return b""
        if isinstance(chunk, (bytes, bytearray)):
            return bytes(chunk)
        if isinstance(chunk, dict):
            for key in ("audio", "audio_chunk", "audio_data", "data", "value"):
                value = chunk.get(key)
                if isinstance(value, (bytes, bytearray)):
                    return bytes(value)
        return b""

    def _enrich_with_memory(self, text: str, memory_context: Optional[Dict[str, Any]]) -> str:
        """
        –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –ø–∞–º—è—Ç–∏

        Args:
            text: –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç
            memory_context: –ö–æ–Ω—Ç–µ–∫—Å—Ç –ø–∞–º—è—Ç–∏ (–¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å–ª–æ–≤–∞—Ä–µ–º)
        """
        if not memory_context:
            return text

        # ‚ö†Ô∏è CRITICAL: –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ memory_context - —ç—Ç–æ —Å–ª–æ–≤–∞—Ä—å
        if not isinstance(memory_context, dict):
            logger.warning(
                f"‚ö†Ô∏è Memory context is not a dict (type={type(memory_context).__name__}), skipping enrichment"
            )
            return text

        try:
            memory_info = memory_context.get('recent_context', '') if memory_context else ''
            if memory_info:
                enriched_text = f"–ö–æ–Ω—Ç–µ–∫—Å—Ç: {memory_info}\n\n{text}"
                logger.debug("–¢–µ–∫—Å—Ç –æ–±–æ–≥–∞—â–µ–Ω –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –ø–∞–º—è—Ç–∏")
                return enriched_text
            return text
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–±–æ–≥–∞—â–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –ø–∞–º—è—Ç—å—é: {e}")
            return text

    async def _stream_audio_for_sentence(self, sentence: str, sentence_index: int) -> AsyncGenerator[bytes, None]:
        """–°—Ç—Ä–∏–º–∏—Ç –∞—É–¥–∏–æ —á–∞–Ω–∫–∏ –¥–ª—è –æ–¥–Ω–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è."""
        if not sentence.strip():
            return
        if not self.audio_module:
            logger.warning("‚ö†Ô∏è AudioProcessor –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –∞—É–¥–∏–æ")
            return
        if hasattr(self.audio_module, 'process'):
            try:
                logger.info(f"üîä –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∞—É–¥–∏–æ –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è #{sentence_index}: '{sentence[:80]}...'")
                chunk_count = 0
                async for chunk in self._stream_audio_module(sentence):
                    audio_chunk = self._extract_audio_chunk(chunk)
                    if audio_chunk:
                        chunk_count += 1
                        logger.info(f"üîä Audio chunk #{chunk_count} –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è #{sentence_index}: {len(audio_chunk)} bytes")
                        yield audio_chunk
                logger.info(f"‚úÖ –ê—É–¥–∏–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è #{sentence_index}: {chunk_count} —á–∞–Ω–∫–æ–≤")
            except Exception as audio_error:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∞—É–¥–∏–æ –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è #{sentence_index}: {audio_error}")
        elif hasattr(self.audio_module, 'generate_speech_streaming'):
            # Legacy fallback
            try:
                logger.info(f"üîä Legacy –∞—É–¥–∏–æ –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è #{sentence_index}: '{sentence[:80]}...'")
                chunk_count = 0
                async for audio_chunk in self.audio_module.generate_speech_streaming(sentence):
                    if audio_chunk:
                        chunk_count += 1
                        logger.info(f"üîä Audio chunk #{chunk_count} –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è #{sentence_index}: {len(audio_chunk)} bytes")
                        yield audio_chunk
                logger.info(f"‚úÖ Legacy –∞—É–¥–∏–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è #{sentence_index}: {chunk_count} —á–∞–Ω–∫–æ–≤")
            except Exception as audio_error:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ legacy –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∞—É–¥–∏–æ –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è #{sentence_index}: {audio_error}")
    
    async def _parse_assistant_response(self, response: Union[str, Dict[str, Any]], session_id: str):
        """
        –ü–∞—Ä—Å–∏–Ω–≥ –æ—Ç–≤–µ—Ç–∞ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è text –∏ command_payload (–§–∞–∑–∞ 2)
        
        Args:
            response: –û—Ç–≤–µ—Ç –æ—Ç —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –º–æ–¥—É–ª—è (—Å—Ç—Ä–æ–∫–∞ –∏–ª–∏ —Å–ª–æ–≤–∞—Ä—å)
            session_id: ID —Å–µ—Å—Å–∏–∏ –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
            
        Returns:
            ParsedResponse —Å text_response –∏ –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–º command_payload
        """
        try:
            config = get_config()
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–∏—á–∞-—Ñ–ª–∞–≥ –∏ kill-switch
            if (not config.features.forward_assistant_actions or 
                config.kill_switches.disable_forward_assistant_actions):
                # –§–∏—á–∞ –≤—ã–∫–ª—é—á–µ–Ω–∞ - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç
                if isinstance(response, dict):
                    return self._assistant_parser.parse(response.get('text', str(response)))
                return self._assistant_parser.parse(response)
            
            # –ü–∞—Ä—Å–∏–º –æ—Ç–≤–µ—Ç, –ø–µ—Ä–µ–¥–∞–≤–∞—è session_id –¥–ª—è –ø–æ–¥—Å—Ç–∞–Ω–æ–≤–∫–∏ –≤ action-–æ—Ç–≤–µ—Ç—ã
            return self._assistant_parser.parse(response, session_id=session_id)
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ—Ç–≤–µ—Ç–∞ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞: {e}, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç")
            # Fallback –Ω–∞ –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç
            if isinstance(response, dict):
                text = response.get('text', str(response))
            else:
                text = str(response)
            return self._assistant_parser.parse(text)
    
    def _log_command_detected(self, parsed, session_id: str):
        """
        –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –∫–æ–º–∞–Ω–¥—ã (–§–∞–∑–∞ 2)
        
        Args:
            parsed: ParsedResponse —Å command_payload
            session_id: ID —Å–µ—Å—Å–∏–∏
        """
        if not parsed.command_payload:
            return
        
        payload = parsed.command_payload.get('payload', {})
        command = payload.get('command', 'unknown')
        args = payload.get('args', {})
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º feature_id –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∫–æ–º–∞–Ω–¥—ã
        if command == 'open_app':
            feature_id = 'F-2025-013-open-app'
        elif command == 'close_app':
            feature_id = 'F-2025-014-close-app'
        elif command in ('create_subscription', 'cancel_subscription'):
            feature_id = 'F-2025-017-stripe-payment'
        else:
            feature_id = 'F-2025-016-mcp-app-opening-integration'
        
        log_structured(
            logger,
            logging.INFO,
            f"[{feature_id}] Command detected: {command}",
            scope="command",
            method="parse_assistant_response",
            decision="start",
            ctx={
                "session_id": session_id,
                "command": command,
                "args": args,
                "feature_id": feature_id
            }
        )
    
    def _log_command_complete(self, session_id: str):
        """
        –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ–≥–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∫–æ–º–∞–Ω–¥—ã (–§–∞–∑–∞ 2)
        
        Args:
            session_id: ID —Å–µ—Å—Å–∏–∏
        """
        if not self._pending_command_payload:
            return
        
        payload = self._pending_command_payload.get('payload', {})
        command = payload.get('command', 'unknown')
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º feature_id –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∫–æ–º–∞–Ω–¥—ã
        if command == 'open_app':
            feature_id = 'F-2025-013-open-app'
        elif command == 'close_app':
            feature_id = 'F-2025-014-close-app'
        elif command in ('create_subscription', 'cancel_subscription'):
            feature_id = 'F-2025-017-stripe-payment'
        else:
            feature_id = 'F-2025-016-mcp-app-opening-integration'
        
        log_structured(
            logger,
            logging.INFO,
            f"[{feature_id}] Command forwarded: {command}",
            scope="command",
            method="process_request_streaming",
            decision="complete",
            ctx={
                "session_id": session_id,
                "command": command,
                "feature_id": feature_id
            }
        )
    
    def _extract_json_from_markdown(self, text: str) -> str:
        """
        –£–¥–∞–ª—è–µ—Ç Markdown-–æ–±—ë—Ä—Ç–∫–∏ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —á–∏—Å—Ç—ã–π JSON —Ç–µ–∫—Å—Ç.
        –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ä–∞–∑–ª–∏—á–Ω—ã–µ –≤–∞—Ä–∏–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–æ–≤ LLM:
        - ```json {...}```
        - ``` {...}```
        - json {...}
        - –¢–µ–∫—Å—Ç –¥–æ/–ø–æ—Å–ª–µ JSON
        - –ß–∞—Å—Ç–∏—á–Ω—ã–π JSON (–¥–ª—è –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è)
        - JSON —Å –ª–∏—à–Ω–∏–º–∏ –ø—Ä–æ–±–µ–ª–∞–º–∏/–ø–µ—Ä–µ–Ω–æ—Å–∞–º–∏
        - JSON —Å trailing commas (—É–¥–∞–ª—è—é—Ç—Å—è)
        - JSON —Å –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è–º–∏ (—É–¥–∞–ª—è—é—Ç—Å—è)
        
        Args:
            text: –¢–µ–∫—Å—Ç, –∫–æ—Ç–æ—Ä—ã–π –º–æ–∂–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å JSON –≤ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–∞—Ö
            
        Returns:
            –ß–∏—Å—Ç—ã–π JSON —Ç–µ–∫—Å—Ç –±–µ–∑ markdown-—Ä–∞–∑–º–µ—Ç–∫–∏ –∏ –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤
        """
        if not text:
            return ""

        import re
        
        text = str(text).strip()

        # –í–∞—Ä–∏–∞–Ω—Ç 1: Markdown code fence ```json ... ``` –∏–ª–∏ ``` ... ```
        if text.startswith("```"):
            # –£–¥–∞–ª—è–µ–º –æ—Ç–∫—Ä—ã–≤–∞—é—â–∏–π fence
            text = text[3:]
            text = text.lstrip()
            
            # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π —è–∑—ã–∫ (json/JSON/JSONC –∏ —Ç.–¥.)
            lowered = text.lower()
            if lowered.startswith("json"):
                text = text[4:]
            text = text.lstrip()
            
            # –£–¥–∞–ª—è–µ–º –≤–µ–¥—É—â–∏–µ –ø–µ—Ä–µ–≤–æ–¥—ã —Å—Ç—Ä–æ–∫–∏
            while text.startswith(("\n", "\r")):
                text = text[1:]
            
            # –£–¥–∞–ª—è–µ–º –∑–∞–∫—Ä—ã–≤–∞—é—â–∏–π fence (–º–æ–∂–µ—Ç –±—ã—Ç—å –≤ –∫–æ–Ω—Ü–µ –∏–ª–∏ –≤ —Å–µ—Ä–µ–¥–∏–Ω–µ –¥–ª—è —á–∞—Å—Ç–∏—á–Ω–æ–≥–æ JSON)
            text = text.rstrip()
            if text.endswith("```"):
                text = text[:-3]
            text = text.strip()

        # –í–∞—Ä–∏–∞–Ω—Ç 2: –¢–µ–∫—Å—Ç –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å "json" (–±–µ–∑ markdown)
        # –£–¥–∞–ª—è–µ–º "json" –µ—Å–ª–∏ –æ–Ω —Å—Ç–æ–∏—Ç –ø–µ—Ä–µ–¥ JSON –æ–±—ä–µ–∫—Ç–æ–º
        text_lower = text.lower()
        if text_lower.startswith("json") and len(text) > 4:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –ø–æ—Å–ª–µ "json" –∏–¥—ë—Ç –ø—Ä–æ–±–µ–ª/–ø–µ—Ä–µ–Ω–æ—Å –∏ –∑–∞—Ç–µ–º {
            after_json = text[4:].lstrip()
            if after_json.startswith("{") or after_json.startswith("\n{") or after_json.startswith("\r{"):
                text = after_json

        # –í–∞—Ä–∏–∞–Ω—Ç 3: –¢–µ–∫—Å—Ç –¥–æ/–ø–æ—Å–ª–µ JSON - –∏–∑–≤–ª–µ–∫–∞–µ–º —Ç–æ–ª—å–∫–æ JSON –æ–±—ä–µ–∫—Ç
        # –ò—â–µ–º –ø–µ—Ä–≤—É—é –æ—Ç–∫—Ä—ã–≤–∞—é—â—É—é —Å–∫–æ–±–∫—É –∏ –ø–æ—Å–ª–µ–¥–Ω—é—é –∑–∞–∫—Ä—ã–≤–∞—é—â—É—é
        first_brace = text.find("{")
        last_brace = text.rfind("}")
        
        if first_brace != -1 and last_brace != -1 and first_brace < last_brace:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º JSON –æ–±—ä–µ–∫—Ç
            json_candidate = text[first_brace:last_brace + 1]
            
            # –û—á–∏—â–∞–µ–º –æ—Ç –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤ –≤–æ–∫—Ä—É–≥
            json_candidate = json_candidate.strip()
            
            # –£–¥–∞–ª—è–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã:
            # 1. –£–¥–∞–ª—è–µ–º –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ (// –∏ /* */) - —Ö–æ—Ç—è JSON –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç, LLM –º–æ–∂–µ—Ç –∏—Ö –¥–æ–±–∞–≤–∏—Ç—å
            json_candidate = re.sub(r'//.*?$', '', json_candidate, flags=re.MULTILINE)  # –û–¥–Ω–æ—Å—Ç—Ä–æ—á–Ω—ã–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏
            json_candidate = re.sub(r'/\*.*?\*/', '', json_candidate, flags=re.DOTALL)  # –ú–Ω–æ–≥–æ—Å—Ç—Ä–æ—á–Ω—ã–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏
            
            # 2. –£–¥–∞–ª—è–µ–º trailing commas –ø–µ—Ä–µ–¥ –∑–∞–∫—Ä—ã–≤–∞—é—â–∏–º–∏ —Å–∫–æ–±–∫–∞–º–∏/—Ñ–∏–≥—É—Ä–Ω—ã–º–∏ —Å–∫–æ–±–∫–∞–º–∏
            json_candidate = re.sub(r',\s*}', '}', json_candidate)  # Trailing comma –ø–µ—Ä–µ–¥ }
            json_candidate = re.sub(r',\s*]', ']', json_candidate)  # Trailing comma –ø–µ—Ä–µ–¥ ]
            
            # 3. –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø—Ä–æ–±–µ–ª—ã –∏ –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫
            json_candidate = re.sub(r'\n\s*\n', '\n', json_candidate)  # –£–¥–∞–ª—è–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
            json_candidate = re.sub(r'[ \t]+', ' ', json_candidate)  # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø—Ä–æ–±–µ–ª—ã
            
            # 4. –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –≤–æ–∫—Ä—É–≥ –¥–≤–æ–µ—Ç–æ—á–∏–π –∏ –∑–∞–ø—è—Ç—ã—Ö
            json_candidate = re.sub(r'\s*:\s*', ': ', json_candidate)  # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø—Ä–æ–±–µ–ª—ã –≤–æ–∫—Ä—É–≥ :
            json_candidate = re.sub(r'\s*,\s*', ', ', json_candidate)  # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø—Ä–æ–±–µ–ª—ã –≤–æ–∫—Ä—É–≥ ,
            
            return json_candidate

        # –ï—Å–ª–∏ JSON –æ–±—ä–µ–∫—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—á–∏—â–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
        # (–º–æ–∂–µ—Ç –±—ã—Ç—å —á–∞—Å—Ç–∏—á–Ω—ã–π JSON –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è)
        return text.strip()

    def _split_into_sentences(self, text: str) -> list[str]:
        """
        –†–∞–∑–±–∏–≤–∫–∞ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
        
        Args:
            text: –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç
            
        Returns:
            –°–ø–∏—Å–æ–∫ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
        """
        try:
            # –ü—Ä–æ—Å—Ç–∞—è —Ä–∞–∑–±–∏–≤–∫–∞ –ø–æ —Ç–æ—á–∫–∞–º, –≤–æ—Å–∫–ª–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–º –∏ –≤–æ–ø—Ä–æ—Å–∏—Ç–µ–ª—å–Ω—ã–º –∑–Ω–∞–∫–∞–º
            import re
            sentences = re.split(r'[.!?]+', text)
            
            # –û—á–∏—â–∞–µ–º –æ—Ç –ø—É—Å—Ç—ã—Ö —Å—Ç—Ä–æ–∫ –∏ –ª–∏—à–Ω–∏—Ö –ø—Ä–æ–±–µ–ª–æ–≤
            clean_sentences = [s.strip() for s in sentences if s.strip()]
            
            logger.debug(f"–¢–µ–∫—Å—Ç —Ä–∞–∑–±–∏—Ç –Ω–∞ {len(clean_sentences)} –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π")
            return clean_sentences
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Ä–∞–∑–±–∏–≤–∫–∏ —Ç–µ–∫—Å—Ç–∞: {e}")
            return [text]  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –≤–µ—Å—å —Ç–µ–∫—Å—Ç –∫–∞–∫ –æ–¥–Ω–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ
    
    async def cleanup(self):
        """–û—á–∏—Å—Ç–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤"""
        try:
            logger.info("–û—á–∏—Å—Ç–∫–∞ StreamingWorkflowIntegration...")
            self.is_initialized = False
            logger.info("‚úÖ StreamingWorkflowIntegration –æ—á–∏—â–µ–Ω")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ StreamingWorkflowIntegration: {e}")

    async def _get_memory_context_parallel(self, hardware_id: str) -> Optional[Dict[str, Any]]:
        """
        –ù–µ–±–ª–æ–∫–∏—Ä—É—é—â–µ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø–∞–º—è—Ç–∏
        
        Args:
            hardware_id: –ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è
        """
        try:
            if not self.memory_workflow:
                logger.debug("MemoryWorkflow –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –ø–æ–ª—É—á–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏")
                return None
            
            logger.debug(f"–ü–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø–∞–º—è—Ç–∏ –¥–ª—è {hardware_id}")
            memory_context = await self.memory_workflow.get_memory_context_parallel(hardware_id)
            
            if memory_context:
                logger.debug(f"‚úÖ –ü–æ–ª—É—á–µ–Ω –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø–∞–º—è—Ç–∏: {len(memory_context)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤")
            else:
                logger.debug("‚ö†Ô∏è –ö–æ–Ω—Ç–µ–∫—Å—Ç –ø–∞–º—è—Ç–∏ –ø—É—Å—Ç")
            
            return memory_context
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø–∞–º—è—Ç–∏: {e}")
            return None

    async def _iter_processed_sentences(
        self,
        text: str,
        screenshot: Optional[str],
        memory_context: Optional[Dict[str, Any]],
        subscription_context: str = ""  # MVP 7: Subscription context (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)
    ) -> AsyncGenerator[str, None]:
        """–°—Ç—Ä–∏–º–∏–Ω–≥–æ–≤–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è —Å —É—á—ë—Ç–æ–º –ø–∞–º—è—Ç–∏, subscription context –∏ —Å–∫—Ä–∏–Ω—à–æ—Ç–∞."""
        # MVP 7: –û–±–æ–≥–∞—â–∞–µ–º —Ç–µ–∫—Å—Ç subscription context –∏ memory context
        if subscription_context:
            enriched_text = self._enrich_with_subscription_and_memory(text, subscription_context, memory_context)
        else:
            enriched_text = self._enrich_with_memory(text, memory_context)

        screenshot_data: Optional[bytes] = None
        if screenshot:
            import base64
            try:
                screenshot_data = base64.b64decode(screenshot)
                logger.info(f"üì∏ –°–∫—Ä–∏–Ω—à–æ—Ç –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω: {len(screenshot_data)} bytes")
            except Exception as decode_error:
                logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞—Ç—å —Å–∫—Ä–∏–Ω—à–æ—Ç: {decode_error}")
                screenshot_data = None

        yielded_any = False
        if self.text_module and hasattr(self.text_module, 'process'):
            logger.info(f"üîÑ –°—Ç—Ä–∏–º–∏–Ω–≥ —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ Text Module: '{enriched_text[:80]}...'")
            try:
                async for chunk in self._stream_text_module(enriched_text, screenshot_data):
                    sentence = (self._extract_text_chunk(chunk) or '').strip()
                    if sentence:
                        yielded_any = True
                        logger.debug(f"üì® TextModule sentence: '{sentence[:120]}...'")
                        yield sentence
            except Exception as processing_error:
                logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ Text Module: {processing_error}. –ò—Å–ø–æ–ª—å–∑—É–µ–º fallback")
        elif self.text_module and hasattr(self.text_module, 'process_text_streaming'):
            # Legacy fallback –Ω–∞ –ø—Ä—è–º–æ–π –¥–æ—Å—Ç—É–ø –∫ TextProcessor
            logger.info(f"üîÑ Legacy —Å—Ç—Ä–∏–º–∏–Ω–≥ —Ç–µ–∫—Å—Ç–∞: '{enriched_text[:80]}...'")
            try:
                async for processed_sentence in self.text_module.process_text_streaming(enriched_text, screenshot_data):
                    sentence = (processed_sentence or '').strip()
                    if sentence:
                        yielded_any = True
                        logger.debug(f"üì® Legacy TextProcessor sentence: '{sentence[:120]}...'")
                        yield sentence
            except Exception as processing_error:
                logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ legacy TextProcessor: {processing_error}. –ò—Å–ø–æ–ª—å–∑—É–µ–º fallback")

        if not yielded_any:
            logger.debug("‚ö†Ô∏è TextProcessor –Ω–µ –≤–µ—Ä–Ω—É–ª –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π, –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback —Ä–∞–∑–±–∏–≤–∫—É")
            for fallback_sentence in self._split_into_sentences(enriched_text):
                if fallback_sentence:
                    yield fallback_sentence

    async def _sanitize_for_tts(self, text: str) -> str:
        """
        –û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è —Å–∏–Ω—Ç–µ–∑–∞ —Ä–µ—á–∏ —á–µ—Ä–µ–∑ –º–æ–¥—É–ª—å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        """
        if not text:
            return ""

        if self.text_filter_module and hasattr(self.text_filter_module, 'process'):
            try:
                result = await self.text_filter_module.process({
                    "operation": "clean_text",
                    "text": text,
                    "options": {
                        "remove_special_chars": True,
                        "remove_extra_whitespace": True,
                        "normalize_unicode": True,
                        "remove_control_chars": True
                    }
                })
                if isinstance(result, dict) and result.get("success") and result.get("cleaned_text") is not None:
                    return result.get("cleaned_text", "").strip()
            except Exception as err:
                logger.warning("‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ TextFilterModule: %s", err)

        return text.strip()

    async def _split_complete_sentences(self, text: str) -> tuple[list[str], str]:
        """
        –†–∞–∑–±–∏–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è —á–µ—Ä–µ–∑ –º–æ–¥—É–ª—å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        """
        if not text:
            return [], ""

        if self.text_filter_module and hasattr(self.text_filter_module, 'process'):
            try:
                result = await self.text_filter_module.process({
                    "operation": "split_sentences",
                    "text": text
                })
                if isinstance(result, dict) and result.get("success"):
                    return result.get("sentences", []), result.get("remainder", "")
            except Exception as err:
                logger.warning("‚ö†Ô∏è –û—à–∏–±–∫–∞ —Ä–∞–∑–±–∏–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ TextFilterModule: %s", err)

        stripped = text.strip()
        return ([stripped] if stripped else [], "")

    async def _count_meaningful_words(self, text: str) -> int:
        """
        –ü–æ–¥—Å—á—ë—Ç –∑–Ω–∞—á–∏–º—ã—Ö —Å–ª–æ–≤ —á–µ—Ä–µ–∑ –º–æ–¥—É–ª—å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        """
        if not text:
            return 0

        if self.text_filter_module and hasattr(self.text_filter_module, 'process'):
            try:
                result = await self.text_filter_module.process({
                    "operation": "count_meaningful_words",
                    "text": text
                })
                if isinstance(result, dict) and result.get("success"):
                    return int(result.get("count", 0))
            except Exception as err:
                logger.warning("‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–¥—Å—á—ë—Ç–∞ —Å–ª–æ–≤ —á–µ—Ä–µ–∑ TextFilterModule: %s", err)

        return len([w for w in text.split() if w.strip()])

    async def _stream_text_module(self, text: str, screenshot_data: Optional[bytes]):
        """–°—Ç—Ä–∏–º–∏–Ω–≥ –æ—Ç–≤–µ—Ç–æ–≤ –∏–∑ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –º–æ–¥—É–ª—è."""
        payload = {"text": text}
        if screenshot_data:
            payload["image_data"] = screenshot_data

        async for chunk in self._stream_module_results(self.text_module, payload):
            yield chunk

    async def _stream_audio_module(self, text: str):
        """–°—Ç—Ä–∏–º–∏–Ω–≥ –∞—É–¥–∏–æ —á–∞–Ω–∫–æ–≤ –∏–∑ –∞—É–¥–∏–æ –º–æ–¥—É–ª—è."""
        async for chunk in self._stream_module_results(self.audio_module, {"text": text}):
            yield chunk

    async def _stream_module_results(self, module, payload: Dict[str, Any]):
        """–£–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≤—ã–∑–æ–≤ module.process —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π async generator."""
        if not module or not hasattr(module, 'process'):
            return
        try:
            result = await module.process(payload)
            if result is None:
                return
            if hasattr(result, "__aiter__"):
                async for item in result:
                    yield item
            else:
                yield result
        except Exception as err:
            logger.warning("‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ –º–æ–¥—É–ª—è %s: %s", getattr(module, 'name', 'unknown'), err)

    def _extract_text_chunk(self, chunk: Any) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç–≤–µ—Ç –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –º–æ–¥—É–ª—è."""
        if chunk is None:
            return ""
        if isinstance(chunk, str):
            return chunk
        if isinstance(chunk, dict):
            for key in ("text", "text_response", "value", "chunk"):
                value = chunk.get(key)
                if isinstance(value, str):
                    return value
        return ""

    def _extract_audio_chunk(self, chunk: Any) -> bytes:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∞—É–¥–∏–æ –±–∞–π—Ç—ã –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –º–æ–¥—É–ª—è."""
        if chunk is None:
            return b""
        if isinstance(chunk, (bytes, bytearray)):
            return bytes(chunk)
        if isinstance(chunk, dict):
            for key in ("audio", "audio_chunk", "audio_data", "data", "value"):
                value = chunk.get(key)
                if isinstance(value, (bytes, bytearray)):
                    return bytes(value)
        return b""

    def _enrich_with_memory(self, text: str, memory_context: Optional[Dict[str, Any]]) -> str:
        """
        –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –ø–∞–º—è—Ç–∏

        Args:
            text: –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç
            memory_context: –ö–æ–Ω—Ç–µ–∫—Å—Ç –ø–∞–º—è—Ç–∏ (–¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å–ª–æ–≤–∞—Ä–µ–º)
        """
        if not memory_context:
            return text

        # ‚ö†Ô∏è CRITICAL: –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ memory_context - —ç—Ç–æ —Å–ª–æ–≤–∞—Ä—å
        if not isinstance(memory_context, dict):
            logger.warning(
                f"‚ö†Ô∏è Memory context is not a dict (type={type(memory_context).__name__}), skipping enrichment"
            )
            return text

        try:
            memory_info = memory_context.get('recent_context', '') if memory_context else ''
            if memory_info:
                enriched_text = f"–ö–æ–Ω—Ç–µ–∫—Å—Ç: {memory_info}\n\n{text}"
                logger.debug("–¢–µ–∫—Å—Ç –æ–±–æ–≥–∞—â–µ–Ω –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –ø–∞–º—è—Ç–∏")
                return enriched_text
            return text
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–±–æ–≥–∞—â–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –ø–∞–º—è—Ç—å—é: {e}")
            return text

    async def _stream_audio_for_sentence(self, sentence: str, sentence_index: int) -> AsyncGenerator[bytes, None]:
        """–°—Ç—Ä–∏–º–∏—Ç –∞—É–¥–∏–æ —á–∞–Ω–∫–∏ –¥–ª—è –æ–¥–Ω–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è."""
        if not sentence.strip():
            return
        if not self.audio_module:
            logger.warning("‚ö†Ô∏è AudioProcessor –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –∞—É–¥–∏–æ")
            return
        if hasattr(self.audio_module, 'process'):
            try:
                logger.info(f"üîä –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∞—É–¥–∏–æ –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è #{sentence_index}: '{sentence[:80]}...'")
                chunk_count = 0
                async for chunk in self._stream_audio_module(sentence):
                    audio_chunk = self._extract_audio_chunk(chunk)
                    if audio_chunk:
                        chunk_count += 1
                        logger.info(f"üîä Audio chunk #{chunk_count} –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è #{sentence_index}: {len(audio_chunk)} bytes")
                        yield audio_chunk
                logger.info(f"‚úÖ –ê—É–¥–∏–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è #{sentence_index}: {chunk_count} —á–∞–Ω–∫–æ–≤")
            except Exception as audio_error:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∞—É–¥–∏–æ –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è #{sentence_index}: {audio_error}")
        elif hasattr(self.audio_module, 'generate_speech_streaming'):
            # Legacy fallback
            try:
                logger.info(f"üîä Legacy –∞—É–¥–∏–æ –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è #{sentence_index}: '{sentence[:80]}...'")
                chunk_count = 0
                async for audio_chunk in self.audio_module.generate_speech_streaming(sentence):
                    if audio_chunk:
                        chunk_count += 1
                        logger.info(f"üîä Audio chunk #{chunk_count} –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è #{sentence_index}: {len(audio_chunk)} bytes")
                        yield audio_chunk
                logger.info(f"‚úÖ Legacy –∞—É–¥–∏–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è #{sentence_index}: {chunk_count} —á–∞–Ω–∫–æ–≤")
            except Exception as audio_error:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ legacy –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∞—É–¥–∏–æ –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è #{sentence_index}: {audio_error}")
    
    async def _parse_assistant_response(self, response: Union[str, Dict[str, Any]], session_id: str):
        """
        –ü–∞—Ä—Å–∏–Ω–≥ –æ—Ç–≤–µ—Ç–∞ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è text –∏ command_payload (–§–∞–∑–∞ 2)
        
        Args:
            response: –û—Ç–≤–µ—Ç –æ—Ç —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –º–æ–¥—É–ª—è (—Å—Ç—Ä–æ–∫–∞ –∏–ª–∏ —Å–ª–æ–≤–∞—Ä—å)
            session_id: ID —Å–µ—Å—Å–∏–∏ –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
            
        Returns:
            ParsedResponse —Å text_response –∏ –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–º command_payload
        """
        try:
            config = get_config()
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–∏—á–∞-—Ñ–ª–∞–≥ –∏ kill-switch
            if (not config.features.forward_assistant_actions or 
                config.kill_switches.disable_forward_assistant_actions):
                # –§–∏—á–∞ –≤—ã–∫–ª—é—á–µ–Ω–∞ - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç
                if isinstance(response, dict):
                    return self._assistant_parser.parse(response.get('text', str(response)))
                return self._assistant_parser.parse(response)
            
            # –ü–∞—Ä—Å–∏–º –æ—Ç–≤–µ—Ç, –ø–µ—Ä–µ–¥–∞–≤–∞—è session_id –¥–ª—è –ø–æ–¥—Å—Ç–∞–Ω–æ–≤–∫–∏ –≤ action-–æ—Ç–≤–µ—Ç—ã
            return self._assistant_parser.parse(response, session_id=session_id)
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ—Ç–≤–µ—Ç–∞ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞: {e}, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç")
            # Fallback –Ω–∞ –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç
            if isinstance(response, dict):
                text = response.get('text', str(response))
            else:
                text = str(response)
            return self._assistant_parser.parse(text)
    
    def _log_command_detected(self, parsed, session_id: str):
        """
        –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –∫–æ–º–∞–Ω–¥—ã (–§–∞–∑–∞ 2)
        
        Args:
            parsed: ParsedResponse —Å command_payload
            session_id: ID —Å–µ—Å—Å–∏–∏
        """
        if not parsed.command_payload:
            return
        
        payload = parsed.command_payload.get('payload', {})
        command = payload.get('command', 'unknown')
        args = payload.get('args', {})
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º feature_id –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∫–æ–º–∞–Ω–¥—ã
        if command == 'open_app':
            feature_id = 'F-2025-013-open-app'
        elif command == 'close_app':
            feature_id = 'F-2025-014-close-app'
        elif command in ('create_subscription', 'cancel_subscription'):
            feature_id = 'F-2025-017-stripe-payment'
        else:
            feature_id = 'F-2025-016-mcp-app-opening-integration'
        
        log_structured(
            logger,
            logging.INFO,
            f"[{feature_id}] Command detected: {command}",
            scope="command",
            method="parse_assistant_response",
            decision="start",
            ctx={
                "session_id": session_id,
                "command": command,
                "args": args,
                "feature_id": feature_id
            }
        )
    
    def _log_command_complete(self, session_id: str):
        """
        –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ–≥–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∫–æ–º–∞–Ω–¥—ã (–§–∞–∑–∞ 2)
        
        Args:
            session_id: ID —Å–µ—Å—Å–∏–∏
        """
        if not self._pending_command_payload:
            return
        
        payload = self._pending_command_payload.get('payload', {})
        command = payload.get('command', 'unknown')
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º feature_id –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∫–æ–º–∞–Ω–¥—ã
        if command == 'open_app':
            feature_id = 'F-2025-013-open-app'
        elif command == 'close_app':
            feature_id = 'F-2025-014-close-app'
        elif command in ('create_subscription', 'cancel_subscription'):
            feature_id = 'F-2025-017-stripe-payment'
        else:
            feature_id = 'F-2025-016-mcp-app-opening-integration'
        
        log_structured(
            logger,
            logging.INFO,
            f"[{feature_id}] Command forwarded: {command}",
            scope="command",
            method="process_request_streaming",
            decision="complete",
            ctx={
                "session_id": session_id,
                "command": command,
                "feature_id": feature_id
            }
        )
    
    def _extract_json_from_markdown(self, text: str) -> str:
        """
        –£–¥–∞–ª—è–µ—Ç Markdown-–æ–±—ë—Ä—Ç–∫–∏ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —á–∏—Å—Ç—ã–π JSON —Ç–µ–∫—Å—Ç.
        –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ä–∞–∑–ª–∏—á–Ω—ã–µ –≤–∞—Ä–∏–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–æ–≤ LLM:
        - ```json {...}```
        - ``` {...}```
        - json {...}
        - –¢–µ–∫—Å—Ç –¥–æ/–ø–æ—Å–ª–µ JSON
        - –ß–∞—Å—Ç–∏—á–Ω—ã–π JSON (–¥–ª—è –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è)
        - JSON —Å –ª–∏—à–Ω–∏–º–∏ –ø—Ä–æ–±–µ–ª–∞–º–∏/–ø–µ—Ä–µ–Ω–æ—Å–∞–º–∏
        - JSON —Å trailing commas (—É–¥–∞–ª—è—é—Ç—Å—è)
        - JSON —Å –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è–º–∏ (—É–¥–∞–ª—è—é—Ç—Å—è)
        
        Args:
            text: –¢–µ–∫—Å—Ç, –∫–æ—Ç–æ—Ä—ã–π –º–æ–∂–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å JSON –≤ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–∞—Ö
            
        Returns:
            –ß–∏—Å—Ç—ã–π JSON —Ç–µ–∫—Å—Ç –±–µ–∑ markdown-—Ä–∞–∑–º–µ—Ç–∫–∏ –∏ –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤
        """
        if not text:
            return ""

        import re
        
        text = str(text).strip()

        # –í–∞—Ä–∏–∞–Ω—Ç 1: Markdown code fence ```json ... ``` –∏–ª–∏ ``` ... ```
        if text.startswith("```"):
            # –£–¥–∞–ª—è–µ–º –æ—Ç–∫—Ä—ã–≤–∞—é—â–∏–π fence
            text = text[3:]
            text = text.lstrip()
            
            # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π —è–∑—ã–∫ (json/JSON/JSONC –∏ —Ç.–¥.)
            lowered = text.lower()
            if lowered.startswith("json"):
                text = text[4:]
            text = text.lstrip()
            
            # –£–¥–∞–ª—è–µ–º –≤–µ–¥—É—â–∏–µ –ø–µ—Ä–µ–≤–æ–¥—ã —Å—Ç—Ä–æ–∫–∏
            while text.startswith(("\n", "\r")):
                text = text[1:]
            
            # –£–¥–∞–ª—è–µ–º –∑–∞–∫—Ä—ã–≤–∞—é—â–∏–π fence (–º–æ–∂–µ—Ç –±—ã—Ç—å –≤ –∫–æ–Ω—Ü–µ –∏–ª–∏ –≤ —Å–µ—Ä–µ–¥–∏–Ω–µ –¥–ª—è —á–∞—Å—Ç–∏—á–Ω–æ–≥–æ JSON)
            text = text.rstrip()
            if text.endswith("```"):
                text = text[:-3]
            text = text.strip()

        # –í–∞—Ä–∏–∞–Ω—Ç 2: –¢–µ–∫—Å—Ç –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å "json" (–±–µ–∑ markdown)
        # –£–¥–∞–ª—è–µ–º "json" –µ—Å–ª–∏ –æ–Ω —Å—Ç–æ–∏—Ç –ø–µ—Ä–µ–¥ JSON –æ–±—ä–µ–∫—Ç–æ–º
        text_lower = text.lower()
        if text_lower.startswith("json") and len(text) > 4:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –ø–æ—Å–ª–µ "json" –∏–¥—ë—Ç –ø—Ä–æ–±–µ–ª/–ø–µ—Ä–µ–Ω–æ—Å –∏ –∑–∞—Ç–µ–º {
            after_json = text[4:].lstrip()
            if after_json.startswith("{") or after_json.startswith("\n{") or after_json.startswith("\r{"):
                text = after_json

        # –í–∞—Ä–∏–∞–Ω—Ç 3: –¢–µ–∫—Å—Ç –¥–æ/–ø–æ—Å–ª–µ JSON - –∏–∑–≤–ª–µ–∫–∞–µ–º —Ç–æ–ª—å–∫–æ JSON –æ–±—ä–µ–∫—Ç
        # –ò—â–µ–º –ø–µ—Ä–≤—É—é –æ—Ç–∫—Ä—ã–≤–∞—é—â—É—é —Å–∫–æ–±–∫—É –∏ –ø–æ—Å–ª–µ–¥–Ω—é—é –∑–∞–∫—Ä—ã–≤–∞—é—â—É—é
        first_brace = text.find("{")
        last_brace = text.rfind("}")
        
        if first_brace != -1 and last_brace != -1 and first_brace < last_brace:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º JSON –æ–±—ä–µ–∫—Ç
            json_candidate = text[first_brace:last_brace + 1]
            
            # –û—á–∏—â–∞–µ–º –æ—Ç –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤ –≤–æ–∫—Ä—É–≥
            json_candidate = json_candidate.strip()
            
            # –£–¥–∞–ª—è–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã:
            # 1. –£–¥–∞–ª—è–µ–º –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ (// –∏ /* */) - —Ö–æ—Ç—è JSON –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç, LLM –º–æ–∂–µ—Ç –∏—Ö –¥–æ–±–∞–≤–∏—Ç—å
            json_candidate = re.sub(r'//.*?$', '', json_candidate, flags=re.MULTILINE)  # –û–¥–Ω–æ—Å—Ç—Ä–æ—á–Ω—ã–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏
            json_candidate = re.sub(r'/\*.*?\*/', '', json_candidate, flags=re.DOTALL)  # –ú–Ω–æ–≥–æ—Å—Ç—Ä–æ—á–Ω—ã–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏
            
            # 2. –£–¥–∞–ª—è–µ–º trailing commas –ø–µ—Ä–µ–¥ –∑–∞–∫—Ä—ã–≤–∞—é—â–∏–º–∏ —Å–∫–æ–±–∫–∞–º–∏/—Ñ–∏–≥—É—Ä–Ω—ã–º–∏ —Å–∫–æ–±–∫–∞–º–∏
            json_candidate = re.sub(r',\s*}', '}', json_candidate)  # Trailing comma –ø–µ—Ä–µ–¥ }
            json_candidate = re.sub(r',\s*]', ']', json_candidate)  # Trailing comma –ø–µ—Ä–µ–¥ ]
            
            # 3. –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø—Ä–æ–±–µ–ª—ã –∏ –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫
            json_candidate = re.sub(r'\n\s*\n', '\n', json_candidate)  # –£–¥–∞–ª—è–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
            json_candidate = re.sub(r'[ \t]+', ' ', json_candidate)  # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø—Ä–æ–±–µ–ª—ã
            
            # 4. –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –≤–æ–∫—Ä—É–≥ –¥–≤–æ–µ—Ç–æ—á–∏–π –∏ –∑–∞–ø—è—Ç—ã—Ö
            json_candidate = re.sub(r'\s*:\s*', ': ', json_candidate)  # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø—Ä–æ–±–µ–ª—ã –≤–æ–∫—Ä—É–≥ :
            json_candidate = re.sub(r'\s*,\s*', ', ', json_candidate)  # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø—Ä–æ–±–µ–ª—ã –≤–æ–∫—Ä—É–≥ ,
            
            return json_candidate

        # –ï—Å–ª–∏ JSON –æ–±—ä–µ–∫—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—á–∏—â–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
        # (–º–æ–∂–µ—Ç –±—ã—Ç—å —á–∞—Å—Ç–∏—á–Ω—ã–π JSON –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è)
        return text.strip()

    def _split_into_sentences(self, text: str) -> list[str]:
        """
        –†–∞–∑–±–∏–≤–∫–∞ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
        
        Args:
            text: –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç
            
        Returns:
            –°–ø–∏—Å–æ–∫ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
        """
        try:
            # –ü—Ä–æ—Å—Ç–∞—è —Ä–∞–∑–±–∏–≤–∫–∞ –ø–æ —Ç–æ—á–∫–∞–º, –≤–æ—Å–∫–ª–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–º –∏ –≤–æ–ø—Ä–æ—Å–∏—Ç–µ–ª—å–Ω—ã–º –∑–Ω–∞–∫–∞–º
            import re
            sentences = re.split(r'[.!?]+', text)
            
            # –û—á–∏—â–∞–µ–º –æ—Ç –ø—É—Å—Ç—ã—Ö —Å—Ç—Ä–æ–∫ –∏ –ª–∏—à–Ω–∏—Ö –ø—Ä–æ–±–µ–ª–æ–≤
            clean_sentences = [s.strip() for s in sentences if s.strip()]
            
            logger.debug(f"–¢–µ–∫—Å—Ç —Ä–∞–∑–±–∏—Ç –Ω–∞ {len(clean_sentences)} –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π")
            return clean_sentences
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Ä–∞–∑–±–∏–≤–∫–∏ —Ç–µ–∫—Å—Ç–∞: {e}")
            return [text]  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –≤–µ—Å—å —Ç–µ–∫—Å—Ç –∫–∞–∫ –æ–¥–Ω–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ
    
    async def cleanup(self):
        """–û—á–∏—Å—Ç–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤"""
        try:
            logger.info("–û—á–∏—Å—Ç–∫–∞ StreamingWorkflowIntegration...")
            self.is_initialized = False
            logger.info("‚úÖ StreamingWorkflowIntegration –æ—á–∏—â–µ–Ω")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ StreamingWorkflowIntegration: {e}")

    async def _get_memory_context_parallel(self, hardware_id: str) -> Optional[Dict[str, Any]]:
        """
        –ù–µ–±–ª–æ–∫–∏—Ä—É—é—â–µ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø–∞–º—è—Ç–∏
        
        Args:
            hardware_id: –ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è
        """
        try:
            if not self.memory_workflow:
                logger.debug("MemoryWorkflow –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –ø–æ–ª—É—á–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏")
                return None
            
            logger.debug(f"–ü–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø–∞–º—è—Ç–∏ –¥–ª—è {hardware_id}")
            memory_context = await self.memory_workflow.get_memory_context_parallel(hardware_id)
            
            if memory_context:
                logger.debug(f"‚úÖ –ü–æ–ª—É—á–µ–Ω –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø–∞–º—è—Ç–∏: {len(memory_context)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤")
            else:
                logger.debug("‚ö†Ô∏è –ö–æ–Ω—Ç–µ–∫—Å—Ç –ø–∞–º—è—Ç–∏ –ø—É—Å—Ç")
            
            return memory_context
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø–∞–º—è—Ç–∏: {e}")
            return None

    async def _iter_processed_sentences(
        self,
        text: str,
        screenshot: Optional[str],
        memory_context: Optional[Dict[str, Any]],
        subscription_context: str = ""  # MVP 7: Subscription context (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)
    ) -> AsyncGenerator[str, None]:
        """–°—Ç—Ä–∏–º–∏–Ω–≥–æ–≤–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è —Å —É—á—ë—Ç–æ–º –ø–∞–º—è—Ç–∏, subscription context –∏ —Å–∫—Ä–∏–Ω—à–æ—Ç–∞."""
        # MVP 7: –û–±–æ–≥–∞—â–∞–µ–º —Ç–µ–∫—Å—Ç subscription context –∏ memory context
        if subscription_context:
            enriched_text = self._enrich_with_subscription_and_memory(text, subscription_context, memory_context)
        else:
            enriched_text = self._enrich_with_memory(text, memory_context)

        screenshot_data: Optional[bytes] = None
        if screenshot:
            import base64
            try:
                screenshot_data = base64.b64decode(screenshot)
                logger.info(f"üì∏ –°–∫—Ä–∏–Ω—à–æ—Ç –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω: {len(screenshot_data)} bytes")
            except Exception as decode_error:
                logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞—Ç—å —Å–∫—Ä–∏–Ω—à–æ—Ç: {decode_error}")
                screenshot_data = None

        yielded_any = False
        if self.text_module and hasattr(self.text_module, 'process'):
            logger.info(f"üîÑ –°—Ç—Ä–∏–º–∏–Ω–≥ —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ Text Module: '{enriched_text[:80]}...'")
            try:
                async for chunk in self._stream_text_module(enriched_text, screenshot_data):
                    sentence = (self._extract_text_chunk(chunk) or '').strip()
                    if sentence:
                        yielded_any = True
                        logger.debug(f"üì® TextModule sentence: '{sentence[:120]}...'")
                        yield sentence
            except Exception as processing_error:
                logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ Text Module: {processing_error}. –ò—Å–ø–æ–ª—å–∑—É–µ–º fallback")
        elif self.text_module and hasattr(self.text_module, 'process_text_streaming'):
            # Legacy fallback –Ω–∞ –ø—Ä—è–º–æ–π –¥–æ—Å—Ç—É–ø –∫ TextProcessor
            logger.info(f"üîÑ Legacy —Å—Ç—Ä–∏–º–∏–Ω–≥ —Ç–µ–∫—Å—Ç–∞: '{enriched_text[:80]}...'")
            try:
                async for processed_sentence in self.text_module.process_text_streaming(enriched_text, screenshot_data):
                    sentence = (processed_sentence or '').strip()
                    if sentence:
                        yielded_any = True
                        logger.debug(f"üì® Legacy TextProcessor sentence: '{sentence[:120]}...'")
                        yield sentence
            except Exception as processing_error:
                logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ legacy TextProcessor: {processing_error}. –ò—Å–ø–æ–ª—å–∑—É–µ–º fallback")

        if not yielded_any:
            logger.debug("‚ö†Ô∏è TextProcessor –Ω–µ –≤–µ—Ä–Ω—É–ª –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π, –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback —Ä–∞–∑–±–∏–≤–∫—É")
            for fallback_sentence in self._split_into_sentences(enriched_text):
                if fallback_sentence:
                    yield fallback_sentence

    async def _sanitize_for_tts(self, text: str) -> str:
        """
        –û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è —Å–∏–Ω—Ç–µ–∑–∞ —Ä–µ—á–∏ —á–µ—Ä–µ–∑ –º–æ–¥—É–ª—å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        """
        if not text:
            return ""

        if self.text_filter_module and hasattr(self.text_filter_module, 'process'):
            try:
                result = await self.text_filter_module.process({
                    "operation": "clean_text",
                    "text": text,
                    "options": {
                        "remove_special_chars": True,
                        "remove_extra_whitespace": True,
                        "normalize_unicode": True,
                        "remove_control_chars": True
                    }
                })
                if isinstance(result, dict) and result.get("success") and result.get("cleaned_text") is not None:
                    return result.get("cleaned_text", "").strip()
            except Exception as err:
                logger.warning("‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ TextFilterModule: %s", err)

        return text.strip()

    async def _split_complete_sentences(self, text: str) -> tuple[list[str], str]:
        """
        –†–∞–∑–±–∏–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è —á–µ—Ä–µ–∑ –º–æ–¥—É–ª—å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        """
        if not text:
            return [], ""

        if self.text_filter_module and hasattr(self.text_filter_module, 'process'):
            try:
                result = await self.text_filter_module.process({
                    "operation": "split_sentences",
                    "text": text
                })
                if isinstance(result, dict) and result.get("success"):
                    return result.get("sentences", []), result.get("remainder", "")
            except Exception as err:
                logger.warning("‚ö†Ô∏è –û—à–∏–±–∫–∞ —Ä–∞–∑–±–∏–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ TextFilterModule: %s", err)

        stripped = text.strip()
        return ([stripped] if stripped else [], "")

    async def _count_meaningful_words(self, text: str) -> int:
        """
        –ü–æ–¥—Å—á—ë—Ç –∑–Ω–∞—á–∏–º—ã—Ö —Å–ª–æ–≤ —á–µ—Ä–µ–∑ –º–æ–¥—É–ª—å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        """
        if not text:
            return 0

        if self.text_filter_module and hasattr(self.text_filter_module, 'process'):
            try:
                result = await self.text_filter_module.process({
                    "operation": "count_meaningful_words",
                    "text": text
                })
                if isinstance(result, dict) and result.get("success"):
                    return int(result.get("count", 0))
            except Exception as err:
                logger.warning("‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–¥—Å—á—ë—Ç–∞ —Å–ª–æ–≤ —á–µ—Ä–µ–∑ TextFilterModule: %s", err)

        return len([w for w in text.split() if w.strip()])

    async def _stream_text_module(self, text: str, screenshot_data: Optional[bytes]):
        """–°—Ç—Ä–∏–º–∏–Ω–≥ –æ—Ç–≤–µ—Ç–æ–≤ –∏–∑ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –º–æ–¥—É–ª—è."""
        payload = {"text": text}
        if screenshot_data:
            payload["image_data"] = screenshot_data

        async for chunk in self._stream_module_results(self.text_module, payload):
            yield chunk

    async def _stream_audio_module(self, text: str):
        """–°—Ç—Ä–∏–º–∏–Ω–≥ –∞—É–¥–∏–æ —á–∞–Ω–∫–æ–≤ –∏–∑ –∞—É–¥–∏–æ –º–æ–¥—É–ª—è."""
        async for chunk in self._stream_module_results(self.audio_module, {"text": text}):
            yield chunk

    async def _stream_module_results(self, module, payload: Dict[str, Any]):
        """–£–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≤—ã–∑–æ–≤ module.process —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π async generator."""
        if not module or not hasattr(module, 'process'):
            return
        try:
            result = await module.process(payload)
            if result is None:
                return
            if hasattr(result, "__aiter__"):
                async for item in result:
                    yield item
            else:
                yield result
        except Exception as err:
            logger.warning("‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ –º–æ–¥—É–ª—è %s: %s", getattr(module, 'name', 'unknown'), err)

    def _extract_text_chunk(self, chunk: Any) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç–≤–µ—Ç –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –º–æ–¥—É–ª—è."""
        if chunk is None:
            return ""
        if isinstance(chunk, str):
            return chunk
        if isinstance(chunk, dict):
            for key in ("text", "text_response", "value", "chunk"):
                value = chunk.get(key)
                if isinstance(value, str):
                    return value
        return ""

    def _extract_audio_chunk(self, chunk: Any) -> bytes:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∞—É–¥–∏–æ –±–∞–π—Ç—ã –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –º–æ–¥—É–ª—è."""
        if chunk is None:
            return b""
        if isinstance(chunk, (bytes, bytearray)):
            return bytes(chunk)
        if isinstance(chunk, dict):
            for key in ("audio", "audio_chunk", "audio_data", "data", "value"):
                value = chunk.get(key)
                if isinstance(value, (bytes, bytearray)):
                    return bytes(value)
        return b""

    def _enrich_with_memory(self, text: str, memory_context: Optional[Dict[str, Any]]) -> str:
        """
        –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –ø–∞–º—è—Ç–∏

        Args:
            text: –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç
            memory_context: –ö–æ–Ω—Ç–µ–∫—Å—Ç –ø–∞–º—è—Ç–∏ (–¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å–ª–æ–≤–∞—Ä–µ–º)
        """
        if not memory_context:
            return text

        # ‚ö†Ô∏è CRITICAL: –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ memory_context - —ç—Ç–æ —Å–ª–æ–≤–∞—Ä—å
        if not isinstance(memory_context, dict):
            logger.warning(
                f"‚ö†Ô∏è Memory context is not a dict (type={type(memory_context).__name__}), skipping enrichment"
            )
            return text

        try:
            memory_info = memory_context.get('recent_context', '') if memory_context else ''
            if memory_info:
                enriched_text = f"–ö–æ–Ω—Ç–µ–∫—Å—Ç: {memory_info}\n\n{text}"
                logger.debug("–¢–µ–∫—Å—Ç –æ–±–æ–≥–∞—â–µ–Ω –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –ø–∞–º—è—Ç–∏")
                return enriched_text
            return text
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–±–æ–≥–∞—â–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –ø–∞–º—è—Ç—å—é: {e}")
            return text

    async def _stream_audio_for_sentence(self, sentence: str, sentence_index: int) -> AsyncGenerator[bytes, None]:
        """–°—Ç—Ä–∏–º–∏—Ç –∞—É–¥–∏–æ —á–∞–Ω–∫–∏ –¥–ª—è –æ–¥–Ω–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è."""
        if not sentence.strip():
            return
        if not self.audio_module:
            logger.warning("‚ö†Ô∏è AudioProcessor –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –∞—É–¥–∏–æ")
            return
        if hasattr(self.audio_module, 'process'):
            try:
                logger.info(f"üîä –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∞—É–¥–∏–æ –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è #{sentence_index}: '{sentence[:80]}...'")
                chunk_count = 0
                async for chunk in self._stream_audio_module(sentence):
                    audio_chunk = self._extract_audio_chunk(chunk)
                    if audio_chunk:
                        chunk_count += 1
                        logger.info(f"üîä Audio chunk #{chunk_count} –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è #{sentence_index}: {len(audio_chunk)} bytes")
                        yield audio_chunk
                logger.info(f"‚úÖ –ê—É–¥–∏–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è #{sentence_index}: {chunk_count} —á–∞–Ω–∫–æ–≤")
            except Exception as audio_error:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∞—É–¥–∏–æ –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è #{sentence_index}: {audio_error}")
        elif hasattr(self.audio_module, 'generate_speech_streaming'):
            # Legacy fallback
            try:
                logger.info(f"üîä Legacy –∞—É–¥–∏–æ –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è #{sentence_index}: '{sentence[:80]}...'")
                chunk_count = 0
                async for audio_chunk in self.audio_module.generate_speech_streaming(sentence):
                    if audio_chunk:
                        chunk_count += 1
                        logger.info(f"üîä Audio chunk #{chunk_count} –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è #{sentence_index}: {len(audio_chunk)} bytes")
                        yield audio_chunk
                logger.info(f"‚úÖ Legacy –∞—É–¥–∏–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è #{sentence_index}: {chunk_count} —á–∞–Ω–∫–æ–≤")
            except Exception as audio_error:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ legacy –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∞—É–¥–∏–æ –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è #{sentence_index}: {audio_error}")
    
    async def _parse_assistant_response(self, response: Union[str, Dict[str, Any]], session_id: str):
        """
        –ü–∞—Ä—Å–∏–Ω–≥ –æ—Ç–≤–µ—Ç–∞ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è text –∏ command_payload (–§–∞–∑–∞ 2)
        
        Args:
            response: –û—Ç–≤–µ—Ç –æ—Ç —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –º–æ–¥—É–ª—è (—Å—Ç—Ä–æ–∫–∞ –∏–ª–∏ —Å–ª–æ–≤–∞—Ä—å)
            session_id: ID —Å–µ—Å—Å–∏–∏ –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
            
        Returns:
            ParsedResponse —Å text_response –∏ –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–º command_payload
        """
        try:
            config = get_config()
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–∏—á–∞-—Ñ–ª–∞–≥ –∏ kill-switch
            if (not config.features.forward_assistant_actions or 
                config.kill_switches.disable_forward_assistant_actions):
                # –§–∏—á–∞ –≤—ã–∫–ª—é—á–µ–Ω–∞ - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç
                if isinstance(response, dict):
                    return self._assistant_parser.parse(response.get('text', str(response)))
                return self._assistant_parser.parse(response)
            
            # –ü–∞—Ä—Å–∏–º –æ—Ç–≤–µ—Ç, –ø–µ—Ä–µ–¥–∞–≤–∞—è session_id –¥–ª—è –ø–æ–¥—Å—Ç–∞–Ω–æ–≤–∫–∏ –≤ action-–æ—Ç–≤–µ—Ç—ã
            return self._assistant_parser.parse(response, session_id=session_id)
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ—Ç–≤–µ—Ç–∞ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞: {e}, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç")
            # Fallback –Ω–∞ –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç
            if isinstance(response, dict):
                text = response.get('text', str(response))
            else:
                text = str(response)
            return self._assistant_parser.parse(text)
    
    def _log_command_detected(self, parsed, session_id: str):
        """
        –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –∫–æ–º–∞–Ω–¥—ã (–§–∞–∑–∞ 2)
        
        Args:
            parsed: ParsedResponse —Å command_payload
            session_id: ID —Å–µ—Å—Å–∏–∏
        """
        if not parsed.command_payload:
            return
        
        payload = parsed.command_payload.get('payload', {})
        command = payload.get('command', 'unknown')
        args = payload.get('args', {})
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º feature_id –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∫–æ–º–∞–Ω–¥—ã
        if command == 'open_app':
            feature_id = 'F-2025-013-open-app'
        elif command == 'close_app':
            feature_id = 'F-2025-014-close-app'
        elif command in ('create_subscription', 'cancel_subscription'):
            feature_id = 'F-2025-017-stripe-payment'
        else:
            feature_id = 'F-2025-016-mcp-app-opening-integration'
        
        log_structured(
            logger,
            logging.INFO,
            f"[{feature_id}] Command detected: {command}",
            scope="command",
            method="parse_assistant_response",
            decision="start",
            ctx={
                "session_id": session_id,
                "command": command,
                "args": args,
                "feature_id": feature_id
            }
        )
    
    def _log_command_complete(self, session_id: str):
        """
        –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ–≥–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∫–æ–º–∞–Ω–¥—ã (–§–∞–∑–∞ 2)
        
        Args:
            session_id: ID —Å–µ—Å—Å–∏–∏
        """
        if not self._pending_command_payload:
            return
        
        payload = self._pending_command_payload.get('payload', {})
        command = payload.get('command', 'unknown')
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º feature_id –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∫–æ–º–∞–Ω–¥—ã
        if command == 'open_app':
            feature_id = 'F-2025-013-open-app'
        elif command == 'close_app':
            feature_id = 'F-2025-014-close-app'
        elif command in ('create_subscription', 'cancel_subscription'):
            feature_id = 'F-2025-017-stripe-payment'
        else:
            feature_id = 'F-2025-016-mcp-app-opening-integration'
        
        log_structured(
            logger,
            logging.INFO,
            f"[{feature_id}] Command forwarded: {command}",
            scope="command",
            method="process_request_streaming",
            decision="complete",
            ctx={
                "session_id": session_id,
                "command": command,
                "feature_id": feature_id
            }
        )
    
    def _extract_json_from_markdown(self, text: str) -> str:
        """
        –£–¥–∞–ª—è–µ—Ç Markdown-–æ–±—ë—Ä—Ç–∫–∏ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —á–∏—Å—Ç—ã–π JSON —Ç–µ–∫—Å—Ç.
        –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ä–∞–∑–ª–∏—á–Ω—ã–µ –≤–∞—Ä–∏–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–æ–≤ LLM:
        - ```json {...}```
        - ``` {...}```
        - json {...}
        - –¢–µ–∫—Å—Ç –¥–æ/–ø–æ—Å–ª–µ JSON
        - –ß–∞—Å—Ç–∏—á–Ω—ã–π JSON (–¥–ª—è –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è)
        - JSON —Å –ª–∏—à–Ω–∏–º–∏ –ø—Ä–æ–±–µ–ª–∞–º–∏/–ø–µ—Ä–µ–Ω–æ—Å–∞–º–∏
        - JSON —Å trailing commas (—É–¥–∞–ª—è—é—Ç—Å—è)
        - JSON —Å –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è–º–∏ (—É–¥–∞–ª—è—é—Ç—Å—è)
        
        Args:
            text: –¢–µ–∫—Å—Ç, –∫–æ—Ç–æ—Ä—ã–π –º–æ–∂–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å JSON –≤ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–∞—Ö
            
        Returns:
            –ß–∏—Å—Ç—ã–π JSON —Ç–µ–∫—Å—Ç –±–µ–∑ markdown-—Ä–∞–∑–º–µ—Ç–∫–∏ –∏ –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤
        """
        if not text:
            return ""

        import re
        
        text = str(text).strip()

        # –í–∞—Ä–∏–∞–Ω—Ç 1: Markdown code fence ```json ... ``` –∏–ª–∏ ``` ... ```
        if text.startswith("```"):
            # –£–¥–∞–ª—è–µ–º –æ—Ç–∫—Ä—ã–≤–∞—é—â–∏–π fence
            text = text[3:]
            text = text.lstrip()
            
            # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π —è–∑—ã–∫ (json/JSON/JSONC –∏ —Ç.–¥.)
            lowered = text.lower()
            if lowered.startswith("json"):
                text = text[4:]
            text = text.lstrip()
            
            # –£–¥–∞–ª—è–µ–º –≤–µ–¥—É—â–∏–µ –ø–µ—Ä–µ–≤–æ–¥—ã —Å—Ç—Ä–æ–∫–∏
            while text.startswith(("\n", "\r")):
                text = text[1:]
            
            # –£–¥–∞–ª—è–µ–º –∑–∞–∫—Ä—ã–≤–∞—é—â–∏–π fence (–º–æ–∂–µ—Ç –±—ã—Ç—å –≤ –∫–æ–Ω—Ü–µ –∏–ª–∏ –≤ —Å–µ—Ä–µ–¥–∏–Ω–µ –¥–ª—è —á–∞—Å—Ç–∏—á–Ω–æ–≥–æ JSON)
            text = text.rstrip()
            if text.endswith("```"):
                text = text[:-3]
            text = text.strip()

        # –í–∞—Ä–∏–∞–Ω—Ç 2: –¢–µ–∫—Å—Ç –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å "json" (–±–µ–∑ markdown)
        # –£–¥–∞–ª—è–µ–º "json" –µ—Å–ª–∏ –æ–Ω —Å—Ç–æ–∏—Ç –ø–µ—Ä–µ–¥ JSON –æ–±—ä–µ–∫—Ç–æ–º
        text_lower = text.lower()
        if text_lower.startswith("json") and len(text) > 4:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –ø–æ—Å–ª–µ "json" –∏–¥—ë—Ç –ø—Ä–æ–±–µ–ª/–ø–µ—Ä–µ–Ω–æ—Å –∏ –∑–∞—Ç–µ–º {
            after_json = text[4:].lstrip()
            if after_json.startswith("{") or after_json.startswith("\n{") or after_json.startswith("\r{"):
                text = after_json

        # –í–∞—Ä–∏–∞–Ω—Ç 3: –¢–µ–∫—Å—Ç –¥–æ/–ø–æ—Å–ª–µ JSON - –∏–∑–≤–ª–µ–∫–∞–µ–º —Ç–æ–ª—å–∫–æ JSON –æ–±—ä–µ–∫—Ç
        # –ò—â–µ–º –ø–µ—Ä–≤—É—é –æ—Ç–∫—Ä—ã–≤–∞—é—â—É—é —Å–∫–æ–±–∫—É –∏ –ø–æ—Å–ª–µ–¥–Ω—é—é –∑–∞–∫—Ä—ã–≤–∞—é—â—É—é
        first_brace = text.find("{")
        last_brace = text.rfind("}")
        
        if first_brace != -1 and last_brace != -1 and first_brace < last_brace:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º JSON –æ–±—ä–µ–∫—Ç
            json_candidate = text[first_brace:last_brace + 1]
            
            # –û—á–∏—â–∞–µ–º –æ—Ç –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤ –≤–æ–∫—Ä—É–≥
            json_candidate = json_candidate.strip()
            
            # –£–¥–∞–ª—è–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã:
            # 1. –£–¥–∞–ª—è–µ–º –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ (// –∏ /* */) - —Ö–æ—Ç—è JSON –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç, LLM –º–æ–∂–µ—Ç –∏—Ö –¥–æ–±–∞–≤–∏—Ç—å
            json_candidate = re.sub(r'//.*?$', '', json_candidate, flags=re.MULTILINE)  # –û–¥–Ω–æ—Å—Ç—Ä–æ—á–Ω—ã–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏
            json_candidate = re.sub(r'/\*.*?\*/', '', json_candidate, flags=re.DOTALL)  # –ú–Ω–æ–≥–æ—Å—Ç—Ä–æ—á–Ω—ã–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏
            
            # 2. –£–¥–∞–ª—è–µ–º trailing commas –ø–µ—Ä–µ–¥ –∑–∞–∫—Ä—ã–≤–∞—é—â–∏–º–∏ —Å–∫–æ–±–∫–∞–º–∏/—Ñ–∏–≥—É—Ä–Ω—ã–º–∏ —Å–∫–æ–±–∫–∞–º–∏
            json_candidate = re.sub(r',\s*}', '}', json_candidate)  # Trailing comma –ø–µ—Ä–µ–¥ }
            json_candidate = re.sub(r',\s*]', ']', json_candidate)  # Trailing comma –ø–µ—Ä–µ–¥ ]
            
            # 3. –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø—Ä–æ–±–µ–ª—ã –∏ –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫
            json_candidate = re.sub(r'\n\s*\n', '\n', json_candidate)  # –£–¥–∞–ª—è–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
            json_candidate = re.sub(r'[ \t]+', ' ', json_candidate)  # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø—Ä–æ–±–µ–ª—ã
            
            # 4. –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –≤–æ–∫—Ä—É–≥ –¥–≤–æ–µ—Ç–æ—á–∏–π –∏ –∑–∞–ø—è—Ç—ã—Ö
            json_candidate = re.sub(r'\s*:\s*', ': ', json_candidate)  # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø—Ä–æ–±–µ–ª—ã –≤–æ–∫—Ä—É–≥ :
            json_candidate = re.sub(r'\s*,\s*', ', ', json_candidate)  # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø—Ä–æ–±–µ–ª—ã –≤–æ–∫—Ä—É–≥ ,
            
            return json_candidate

        # –ï—Å–ª–∏ JSON –æ–±—ä–µ–∫—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—á–∏—â–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
        # (–º–æ–∂–µ—Ç –±—ã—Ç—å —á–∞—Å—Ç–∏—á–Ω—ã–π JSON –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è)
        return text.strip()

    def _split_into_sentences(self, text: str) -> list[str]:
        """
        –†–∞–∑–±–∏–≤–∫–∞ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
        
        Args:
            text: –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç
            
        Returns:
            –°–ø–∏—Å–æ–∫ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
        """
        try:
            # –ü—Ä–æ—Å—Ç–∞—è —Ä–∞–∑–±–∏–≤–∫–∞ –ø–æ —Ç–æ—á–∫–∞–º, –≤–æ—Å–∫–ª–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–º –∏ –≤–æ–ø—Ä–æ—Å–∏—Ç–µ–ª—å–Ω—ã–º –∑–Ω–∞–∫–∞–º
            import re
            sentences = re.split(r'[.!?]+', text)
            
            # –û—á–∏—â–∞–µ–º –æ—Ç –ø—É—Å—Ç—ã—Ö —Å—Ç—Ä–æ–∫ –∏ –ª–∏—à–Ω–∏—Ö –ø—Ä–æ–±–µ–ª–æ–≤
            clean_sentences = [s.strip() for s in sentences if s.strip()]
            
            logger.debug(f"–¢–µ–∫—Å—Ç —Ä–∞–∑–±–∏—Ç –Ω–∞ {len(clean_sentences)} –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π")
            return clean_sentences
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Ä–∞–∑–±–∏–≤–∫–∏ —Ç–µ–∫—Å—Ç–∞: {e}")
            return [text]  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –≤–µ—Å—å —Ç–µ–∫—Å—Ç –∫–∞–∫ –æ–¥–Ω–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ
    
    async def cleanup(self):
        """–û—á–∏—Å—Ç–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤"""
        try:
            logger.info("–û—á–∏—Å—Ç–∫–∞ StreamingWorkflowIntegration...")
            self.is_initialized = False
            logger.info("‚úÖ StreamingWorkflowIntegration –æ—á–∏—â–µ–Ω")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ StreamingWorkflowIntegration: {e}")

    async def _get_memory_context_parallel(self, hardware_id: str) -> Optional[Dict[str, Any]]:
        """
        –ù–µ–±–ª–æ–∫–∏—Ä—É—é—â–µ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø–∞–º—è—Ç–∏
        
        Args:
            hardware_id: –ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è
        """
        try:
            if not self.memory_workflow:
                logger.debug("MemoryWorkflow –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –ø–æ–ª—É—á–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏")
                return None
            
            logger.debug(f"–ü–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø–∞–º—è—Ç–∏ –¥–ª—è {hardware_id}")
            memory_context = await self.memory_workflow.get_memory_context_parallel(hardware_id)
            
            if memory_context:
                logger.debug(f"‚úÖ –ü–æ–ª—É—á–µ–Ω –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø–∞–º—è—Ç–∏: {len(memory_context)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤")
            else:
                logger.debug("‚ö†Ô∏è –ö–æ–Ω—Ç–µ–∫—Å—Ç –ø–∞–º—è—Ç–∏ –ø—É—Å—Ç")
            
            return memory_context
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø–∞–º—è—Ç–∏: {e}")
            return None

    async def _iter_processed_sentences(
        self,
        text: str,
        screenshot: Optional[str],
        memory_context: Optional[Dict[str, Any]],
        subscription_context: str = ""  # MVP 7: Subscription context (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)
    ) -> AsyncGenerator[str, None]:
        """–°—Ç—Ä–∏–º–∏–Ω–≥–æ–≤–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è —Å —É—á—ë—Ç–æ–º –ø–∞–º—è—Ç–∏, subscription context –∏ —Å–∫—Ä–∏–Ω—à–æ—Ç–∞."""
        # MVP 7: –û–±–æ–≥–∞—â–∞–µ–º —Ç–µ–∫—Å—Ç subscription context –∏ memory context
        if subscription_context:
            enriched_text = self._enrich_with_subscription_and_memory(text, subscription_context, memory_context)
        else:
            enriched_text = self._enrich_with_memory(text, memory_context)

        screenshot_data: Optional[bytes] = None
        if screenshot:
            import base64
            try:
                screenshot_data = base64.b64decode(screenshot)
                logger.info(f"üì∏ –°–∫—Ä–∏–Ω—à–æ—Ç –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω: {len(screenshot_data)} bytes")
            except Exception as decode_error:
                logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞—Ç—å —Å–∫—Ä–∏–Ω—à–æ—Ç: {decode_error}")
                screenshot_data = None

        yielded_any = False
        if self.text_module and hasattr(self.text_module, 'process'):
            logger.info(f"üîÑ –°—Ç—Ä–∏–º–∏–Ω–≥ —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ Text Module: '{enriched_text[:80]}...'")
            try:
                async for chunk in self._stream_text_module(enriched_text, screenshot_data):
                    sentence = (self._extract_text_chunk(chunk) or '').strip()
                    if sentence:
                        yielded_any = True
                        logger.debug(f"üì® TextModule sentence: '{sentence[:120]}...'")
                        yield sentence
            except Exception as processing_error:
                logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ Text Module: {processing_error}. –ò—Å–ø–æ–ª—å–∑—É–µ–º fallback")
        elif self.text_module and hasattr(self.text_module, 'process_text_streaming'):
            # Legacy fallback –Ω–∞ –ø—Ä—è–º–æ–π –¥–æ—Å—Ç—É–ø –∫ TextProcessor
            logger.info(f"üîÑ Legacy —Å—Ç—Ä–∏–º–∏–Ω–≥ —Ç–µ–∫—Å—Ç–∞: '{enriched_text[:80]}...'")
            try:
                async for processed_sentence in self.text_module.process_text_streaming(enriched_text, screenshot_data):
                    sentence = (processed_sentence or '').strip()
                    if sentence:
                        yielded_any = True
                        logger.debug(f"üì® Legacy TextProcessor sentence: '{sentence[:120]}...'")
                        yield sentence
            except Exception as processing_error:
                logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ legacy TextProcessor: {processing_error}. –ò—Å–ø–æ–ª—å–∑—É–µ–º fallback")

        if not yielded_any:
            logger.debug("‚ö†Ô∏è TextProcessor –Ω–µ –≤–µ—Ä–Ω—É–ª –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π, –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback —Ä–∞–∑–±–∏–≤–∫—É")
            for fallback_sentence in self._split_into_sentences(enriched_text):
                if fallback_sentence:
                    yield fallback_sentence

    async def _sanitize_for_tts(self, text: str) -> str:
        """
        –û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è —Å–∏–Ω—Ç–µ–∑–∞ —Ä–µ—á–∏ —á–µ—Ä–µ–∑ –º–æ–¥—É–ª—å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        """
        if not text:
            return ""

        if self.text_filter_module and hasattr(self.text_filter_module, 'process'):
            try:
                result = await self.text_filter_module.process({
                    "operation": "clean_text",
                    "text": text,
                    "options": {
                        "remove_special_chars": True,
                        "remove_extra_whitespace": True,
                        "normalize_unicode": True,
                        "remove_control_chars": True
                    }
                })
                if isinstance(result, dict) and result.get("success") and result.get("cleaned_text") is not None:
                    return result.get("cleaned_text", "").strip()
            except Exception as err:
                logger.warning("‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ TextFilterModule: %s", err)

        return text.strip()

    async def _split_complete_sentences(self, text: str) -> tuple[list[str], str]:
        """
        –†–∞–∑–±–∏–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è —á–µ—Ä–µ–∑ –º–æ–¥—É–ª—å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        """
        if not text:
            return [], ""

        if self.text_filter_module and hasattr(self.text_filter_module, 'process'):
            try:
                result = await self.text_filter_module.process({
                    "operation": "split_sentences",
                    "text": text
                })
                if isinstance(result, dict) and result.get("success"):
                    return result.get("sentences", []), result.get("remainder", "")
            except Exception as err:
                logger.warning("‚ö†Ô∏è –û—à–∏–±–∫–∞ —Ä–∞–∑–±–∏–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ TextFilterModule: %s", err)

        stripped = text.strip()
        return ([stripped] if stripped else [], "")

    async def _count_meaningful_words(self, text: str) -> int:
        """
        –ü–æ–¥—Å—á—ë—Ç –∑–Ω–∞—á–∏–º—ã—Ö —Å–ª–æ–≤ —á–µ—Ä–µ–∑ –º–æ–¥—É–ª—å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        """
        if not text:
            return 0

        if self.text_filter_module and hasattr(self.text_filter_module, 'process'):
            try:
                result = await self.text_filter_module.process({
                    "operation": "count_meaningful_words",
                    "text": text
                })
                if isinstance(result, dict) and result.get("success"):
                    return int(result.get("count", 0))
            except Exception as err:
                logger.warning("‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–¥—Å—á—ë—Ç–∞ —Å–ª–æ–≤ —á–µ—Ä–µ–∑ TextFilterModule: %s", err)

        return len([w for w in text.split() if w.strip()])

    async def _stream_text_module(self, text: str, screenshot_data: Optional[bytes]):
        """–°—Ç—Ä–∏–º–∏–Ω–≥ –æ—Ç–≤–µ—Ç–æ–≤ –∏–∑ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –º–æ–¥—É–ª—è."""
        payload = {"text": text}
        if screenshot_data:
            payload["image_data"] = screenshot_data

        async for chunk in self._stream_module_results(self.text_module, payload):
            yield chunk

    async def _stream_audio_module(self, text: str):
        """–°—Ç—Ä–∏–º–∏–Ω–≥ –∞—É–¥–∏–æ —á–∞–Ω–∫–æ–≤ –∏–∑ –∞—É–¥–∏–æ –º–æ–¥—É–ª—è."""
        async for chunk in self._stream_module_results(self.audio_module, {"text": text}):
            yield chunk

    async def _stream_module_results(self, module, payload: Dict[str, Any]):
        """–£–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≤—ã–∑–æ–≤ module.process —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π async generator."""
        if not module or not hasattr(module, 'process'):
            return
        try:
            result = await module.process(payload)
            if result is None:
                return
            if hasattr(result, "__aiter__"):
                async for item in result:
                    yield item
            else:
                yield result
        except Exception as err:
            logger.warning("‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ –º–æ–¥—É–ª—è %s: %s", getattr(module, 'name', 'unknown'), err)

    def _extract_text_chunk(self, chunk: Any) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç–≤–µ—Ç –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –º–æ–¥—É–ª—è."""
        if chunk is None:
            return ""
        if isinstance(chunk, str):
            return chunk
        if isinstance(chunk, dict):
            for key in ("text", "text_response", "value", "chunk"):
                value = chunk.get(key)
                if isinstance(value, str):
                    return value
        return ""

    def _extract_audio_chunk(self, chunk: Any) -> bytes:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∞—É–¥–∏–æ –±–∞–π—Ç—ã –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –º–æ–¥—É–ª—è."""
        if chunk is None:
            return b""
        if isinstance(chunk, (bytes, bytearray)):
            return bytes(chunk)
        if isinstance(chunk, dict):
            for key in ("audio", "audio_chunk", "audio_data", "data", "value"):
                value = chunk.get(key)
                if isinstance(value, (bytes, bytearray)):
                    return bytes(value)
        return b""

    def _enrich_with_memory(self, text: str, memory_context: Optional[Dict[str, Any]]) -> str:
        """
        –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –ø–∞–º—è—Ç–∏

        Args:
            text: –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç
            memory_context: –ö–æ–Ω—Ç–µ–∫—Å—Ç –ø–∞–º—è—Ç–∏ (–¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å–ª–æ–≤–∞—Ä–µ–º)
        """
        if not memory_context:
            return text

        # ‚ö†Ô∏è CRITICAL: –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ memory_context - —ç—Ç–æ —Å–ª–æ–≤–∞—Ä—å
        if not isinstance(memory_context, dict):
            logger.warning(
                f"‚ö†Ô∏è Memory context is not a dict (type={type(memory_context).__name__}), skipping enrichment"
            )
            return text

        try:
            memory_info = memory_context.get('recent_context', '') if memory_context else ''
            if memory_info:
                enriched_text = f"–ö–æ–Ω—Ç–µ–∫—Å—Ç: {memory_info}\n\n{text}"
                logger.debug("–¢–µ–∫—Å—Ç –æ–±–æ–≥–∞—â–µ–Ω –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –ø–∞–º—è—Ç–∏")
                return enriched_text
            return text
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–±–æ–≥–∞—â–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –ø–∞–º—è—Ç—å—é: {e}")
            return text

    async def _stream_audio_for_sentence(self, sentence: str, sentence_index: int) -> AsyncGenerator[bytes, None]:
        """–°—Ç—Ä–∏–º–∏—Ç –∞—É–¥–∏–æ —á–∞–Ω–∫–∏ –¥–ª—è –æ–¥–Ω–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è."""
        if not sentence.strip():
            return
        if not self.audio_module:
            logger.warning("‚ö†Ô∏è AudioProcessor –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –∞—É–¥–∏–æ")
            return
        if hasattr(self.audio_module, 'process'):
            try:
                logger.info(f"üîä –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∞—É–¥–∏–æ –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è #{sentence_index}: '{sentence[:80]}...'")
                chunk_count = 0
                async for chunk in self._stream_audio_module(sentence):
                    audio_chunk = self._extract_audio_chunk(chunk)
                    if audio_chunk:
                        chunk_count += 1
                        logger.info(f"üîä Audio chunk #{chunk_count} –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è #{sentence_index}: {len(audio_chunk)} bytes")
                        yield audio_chunk
                logger.info(f"‚úÖ –ê—É–¥–∏–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è #{sentence_index}: {chunk_count} —á–∞–Ω–∫–æ–≤")
            except Exception as audio_error:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∞—É–¥–∏–æ –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è #{sentence_index}: {audio_error}")
        elif hasattr(self.audio_module, 'generate_speech_streaming'):
            # Legacy fallback
            try:
                logger.info(f"üîä Legacy –∞—É–¥–∏–æ –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è #{sentence_index}: '{sentence[:80]}...'")
                chunk_count = 0
                async for audio_chunk in self.audio_module.generate_speech_streaming(sentence):
                    if audio_chunk:
                        chunk_count += 1
                        logger.info(f"üîä Audio chunk #{chunk_count} –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è #{sentence_index}: {len(audio_chunk)} bytes")
                        yield audio_chunk
                logger.info(f"‚úÖ Legacy –∞—É–¥–∏–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è #{sentence_index}: {chunk_count} —á–∞–Ω–∫–æ–≤")
            except Exception as audio_error:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ legacy –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∞—É–¥–∏–æ –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è #{sentence_index}: {audio_error}")
    
    async def _parse_assistant_response(self, response: Union[str, Dict[str, Any]], session_id: str):
        """
        –ü–∞—Ä—Å–∏–Ω–≥ –æ—Ç–≤–µ—Ç–∞ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è text –∏ command_payload (–§–∞–∑–∞ 2)
        
        Args:
            response: –û—Ç–≤–µ—Ç –æ—Ç —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –º–æ–¥—É–ª—è (—Å—Ç—Ä–æ–∫–∞ –∏–ª–∏ —Å–ª–æ–≤–∞—Ä—å)
            session_id: ID —Å–µ—Å—Å–∏–∏ –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
            
        Returns:
            ParsedResponse —Å text_response –∏ –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–º command_payload
        """
        try:
            config = get_config()
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–∏—á–∞-—Ñ–ª–∞–≥ –∏ kill-switch
            if (not config.features.forward_assistant_actions or 
                config.kill_switches.disable_forward_assistant_actions):
                # –§–∏—á–∞ –≤—ã–∫–ª—é—á–µ–Ω–∞ - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç
                if isinstance(response, dict):
                    return self._assistant_parser.parse(response.get('text', str(response)))
                return self._assistant_parser.parse(response)
            
            # –ü–∞—Ä—Å–∏–º –æ—Ç–≤–µ—Ç, –ø–µ—Ä–µ–¥–∞–≤–∞—è session_id –¥–ª—è –ø–æ–¥—Å—Ç–∞–Ω–æ–≤–∫–∏ –≤ action-–æ—Ç–≤–µ—Ç—ã
            return self._assistant_parser.parse(response, session_id=session_id)
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ—Ç–≤–µ—Ç–∞ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞: {e}, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç")
            # Fallback –Ω–∞ –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç
            if isinstance(response, dict):
                text = response.get('text', str(response))
            else:
                text = str(response)
            return self._assistant_parser.parse(text)
    
    def _log_command_detected(self, parsed, session_id: str):
        """
        –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –∫–æ–º–∞–Ω–¥—ã (–§–∞–∑–∞ 2)
        
        Args:
            parsed: ParsedResponse —Å command_payload
            session_id: ID —Å–µ—Å—Å–∏–∏
        """
        if not parsed.command_payload:
            return
        
        payload = parsed.command_payload.get('payload', {})
        command = payload.get('command', 'unknown')
        args = payload.get('args', {})
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º feature_id –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∫–æ–º–∞–Ω–¥—ã
        if command == 'open_app':
            feature_id = 'F-2025-013-open-app'
        elif command == 'close_app':
            feature_id = 'F-2025-014-close-app'
        elif command in ('create_subscription', 'cancel_subscription'):
            feature_id = 'F-2025-017-stripe-payment'
        else:
            feature_id = 'F-2025-016-mcp-app-opening-integration'
        
        log_structured(
            logger,
            logging.INFO,
            f"[{feature_id}] Command detected: {command}",
            scope="command",
            method="parse_assistant_response",
            decision="start",
            ctx={
                "session_id": session_id,
                "command": command,
                "args": args,
                "feature_id": feature_id
            }
        )
    
    def _log_command_complete(self, session_id: str):
        """
        –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ–≥–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∫–æ–º–∞–Ω–¥—ã (–§–∞–∑–∞ 2)
        
        Args:
            session_id: ID —Å–µ—Å—Å–∏–∏
        """
        if not self._pending_command_payload:
            return
        
        payload = self._pending_command_payload.get('payload', {})
        command = payload.get('command', 'unknown')
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º feature_id –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∫–æ–º–∞–Ω–¥—ã
        if command == 'open_app':
            feature_id = 'F-2025-013-open-app'
        elif command == 'close_app':
            feature_id = 'F-2025-014-close-app'
        elif command in ('create_subscription', 'cancel_subscription'):
            feature_id = 'F-2025-017-stripe-payment'
        else:
            feature_id = 'F-2025-016-mcp-app-opening-integration'
        
        log_structured(
            logger,
            logging.INFO,
            f"[{feature_id}] Command forwarded: {command}",
            scope="command",
            method="process_request_streaming",
            decision="complete",
            ctx={
                "session_id": session_id,
                "command": command,
                "feature_id": feature_id
            }
        )
    
    def _extract_json_from_markdown(self, text: str) -> str:
        """
        –£–¥–∞–ª—è–µ—Ç Markdown-–æ–±—ë—Ä—Ç–∫–∏ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —á–∏—Å—Ç—ã–π JSON —Ç–µ–∫—Å—Ç.
        –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ä–∞–∑–ª–∏—á–Ω—ã–µ –≤–∞—Ä–∏–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–æ–≤ LLM:
        - ```json {...}```
        - ``` {...}```
        - json {...}
        - –¢–µ–∫—Å—Ç –¥–æ/–ø–æ—Å–ª–µ JSON
        - –ß–∞—Å—Ç–∏—á–Ω—ã–π JSON (–¥–ª—è –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è)
        - JSON —Å –ª–∏—à–Ω–∏–º–∏ –ø—Ä–æ–±–µ–ª–∞–º–∏/–ø–µ—Ä–µ–Ω–æ—Å–∞–º–∏
        - JSON —Å trailing commas (—É–¥–∞–ª—è—é—Ç—Å—è)
        - JSON —Å –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è–º–∏ (—É–¥–∞–ª—è—é—Ç—Å—è)
        
        Args:
            text: –¢–µ–∫—Å—Ç, –∫–æ—Ç–æ—Ä—ã–π –º–æ–∂–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å JSON –≤ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–∞—Ö
            
        Returns:
            –ß–∏—Å—Ç—ã–π JSON —Ç–µ–∫—Å—Ç –±–µ–∑ markdown-—Ä–∞–∑–º–µ—Ç–∫–∏ –∏ –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤
        """
        if not text:
            return ""

        import re
        
        text = str(text).strip()

        # –í–∞—Ä–∏–∞–Ω—Ç 1: Markdown code fence ```json ... ``` –∏–ª–∏ ``` ... ```
        if text.startswith("```"):
            # –£–¥–∞–ª—è–µ–º –æ—Ç–∫—Ä—ã–≤–∞—é—â–∏–π fence
            text = text[3:]
            text = text.lstrip()
            
            # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π —è–∑—ã–∫ (json/JSON/JSONC –∏ —Ç.–¥.)
            lowered = text.lower()
            if lowered.startswith("json"):
                text = text[4:]
            text = text.lstrip()
            
            # –£–¥–∞–ª—è–µ–º –≤–µ–¥—É—â–∏–µ –ø–µ—Ä–µ–≤–æ–¥—ã —Å—Ç—Ä–æ–∫–∏
            while text.startswith(("\n", "\r")):
                text = text[1:]
            
            # –£–¥–∞–ª—è–µ–º –∑–∞–∫—Ä—ã–≤–∞—é—â–∏–π fence (–º–æ–∂–µ—Ç –±—ã—Ç—å –≤ –∫–æ–Ω—Ü–µ –∏–ª–∏ –≤ —Å–µ—Ä–µ–¥–∏–Ω–µ –¥–ª—è —á–∞—Å—Ç–∏—á–Ω–æ–≥–æ JSON)
            text = text.rstrip()
            if text.endswith("```"):
                text = text[:-3]
            text = text.strip()

        # –í–∞—Ä–∏–∞–Ω—Ç 2: –¢–µ–∫—Å—Ç –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å "json" (–±–µ–∑ markdown)
        # –£–¥–∞–ª—è–µ–º "json" –µ—Å–ª–∏ –æ–Ω —Å—Ç–æ–∏—Ç –ø–µ—Ä–µ–¥ JSON –æ–±—ä–µ–∫—Ç–æ–º
        text_lower = text.lower()
        if text_lower.startswith("json") and len(text) > 4:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –ø–æ—Å–ª–µ "json" –∏–¥—ë—Ç –ø—Ä–æ–±–µ–ª/–ø–µ—Ä–µ–Ω–æ—Å –∏ –∑–∞—Ç–µ–º {
            after_json = text[4:].lstrip()
            if after_json.startswith("{") or after_json.startswith("\n{") or after_json.startswith("\r{"):
                text = after_json

        # –í–∞—Ä–∏–∞–Ω—Ç 3: –¢–µ–∫—Å—Ç –¥–æ/–ø–æ—Å–ª–µ JSON - –∏–∑–≤–ª–µ–∫–∞–µ–º —Ç–æ–ª—å–∫–æ JSON –æ–±—ä–µ–∫—Ç
        # –ò—â–µ–º –ø–µ—Ä–≤—É—é –æ—Ç–∫—Ä—ã–≤–∞—é—â—É—é —Å–∫–æ–±–∫—É –∏ –ø–æ—Å–ª–µ–¥–Ω—é—é –∑–∞–∫—Ä—ã–≤–∞—é—â—É—é
        first_brace = text.find("{")
        last_brace = text.rfind("}")
        
        if first_brace != -1 and last_brace != -1 and first_brace < last_brace:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º JSON –æ–±—ä–µ–∫—Ç
            json_candidate = text[first_brace:last_brace + 1]
            
            # –û—á–∏—â–∞–µ–º –æ—Ç –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤ –≤–æ–∫—Ä—É–≥
            json_candidate = json_candidate.strip()
            
            # –£–¥–∞–ª—è–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã:
            # 1. –£–¥–∞–ª—è–µ–º –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ (// –∏ /* */) - —Ö–æ—Ç—è JSON –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç, LLM –º–æ–∂–µ—Ç –∏—Ö –¥–æ–±–∞–≤–∏—Ç—å
            json_candidate = re.sub(r'//.*?$', '', json_candidate, flags=re.MULTILINE)  # –û–¥–Ω–æ—Å—Ç—Ä–æ—á–Ω—ã–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏
            json_candidate = re.sub(r'/\*.*?\*/', '', json_candidate, flags=re.DOTALL)  # –ú–Ω–æ–≥–æ—Å—Ç—Ä–æ—á–Ω—ã–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏
            
            # 2. –£–¥–∞–ª—è–µ–º trailing commas –ø–µ—Ä–µ–¥ –∑–∞–∫—Ä—ã–≤–∞—é—â–∏–º–∏ —Å–∫–æ–±–∫–∞–º–∏/—Ñ–∏–≥—É—Ä–Ω—ã–º–∏ —Å–∫–æ–±–∫–∞–º–∏
            json_candidate = re.sub(r',\s*}', '}', json_candidate)  # Trailing comma –ø–µ—Ä–µ–¥ }
            json_candidate = re.sub(r',\s*]', ']', json_candidate)  # Trailing comma –ø–µ—Ä–µ–¥ ]
            
            # 3. –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø—Ä–æ–±–µ–ª—ã –∏ –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫
            json_candidate = re.sub(r'\n\s*\n', '\n', json_candidate)  # –£–¥–∞–ª—è–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
            json_candidate = re.sub(r'[ \t]+', ' ', json_candidate)  # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø—Ä–æ–±–µ–ª—ã
            
            # 4. –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –≤–æ–∫—Ä—É–≥ –¥–≤–æ–µ—Ç–æ—á–∏–π –∏ –∑–∞–ø—è—Ç—ã—Ö
            json_candidate = re.sub(r'\s*:\s*', ': ', json_candidate)  # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø—Ä–æ–±–µ–ª—ã –≤–æ–∫—Ä—É–≥ :
            json_candidate = re.sub(r'\s*,\s*', ', ', json_candidate)  # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø—Ä–æ–±–µ–ª—ã –≤–æ–∫—Ä—É–≥ ,
            
            return json_candidate

        # –ï—Å–ª–∏ JSON –æ–±—ä–µ–∫—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—á–∏—â–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
        # (–º–æ–∂–µ—Ç –±—ã—Ç—å —á–∞—Å—Ç–∏—á–Ω—ã–π JSON –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è)
        return text.strip()

    def _split_into_sentences(self, text: str) -> list[str]:
        """
        –†–∞–∑–±–∏–≤–∫–∞ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
        
        Args:
            text: –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç
            
        Returns:
            –°–ø–∏—Å–æ–∫ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
        """
        try:
            # –ü—Ä–æ—Å—Ç–∞—è —Ä–∞–∑–±–∏–≤–∫–∞ –ø–æ —Ç–æ—á–∫–∞–º, –≤–æ—Å–∫–ª–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–º –∏ –≤–æ–ø—Ä–æ—Å–∏—Ç–µ–ª—å–Ω—ã–º –∑–Ω–∞–∫–∞–º
            import re
            sentences = re.split(r'[.!?]+', text)
            
            # –û—á–∏—â–∞–µ–º –æ—Ç –ø—É—Å—Ç—ã—Ö —Å—Ç—Ä–æ–∫ –∏ –ª–∏—à–Ω–∏—Ö –ø—Ä–æ–±–µ–ª–æ–≤
            clean_sentences = [s.strip() for s in sentences if s.strip()]
            
            logger.debug(f"–¢–µ–∫—Å—Ç —Ä–∞–∑–±–∏—Ç –Ω–∞ {len(clean_sentences)} –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π")
            return clean_sentences
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Ä–∞–∑–±–∏–≤–∫–∏ —Ç–µ–∫—Å—Ç–∞: {e}")
            return [text]  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –≤–µ—Å—å —Ç–µ–∫—Å—Ç –∫–∞–∫ –æ–¥–Ω–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ
    
    async def cleanup(self):
        """–û—á–∏—Å—Ç–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤"""
        try:
            logger.info("–û—á–∏—Å—Ç–∫–∞ StreamingWorkflowIntegration...")
            self.is_initialized = False
            logger.info("‚úÖ StreamingWorkflowIntegration –æ—á–∏—â–µ–Ω")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ StreamingWorkflowIntegration: {e}")

    async def _get_memory_context_parallel(self, hardware_id: str) -> Optional[Dict[str, Any]]:
        """
        –ù–µ–±–ª–æ–∫–∏—Ä—É—é—â–µ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø–∞–º—è—Ç–∏
        
        Args:
            hardware_id: –ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è
        """
        try:
            if not self.memory_workflow:
                logger.debug("MemoryWorkflow –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –ø–æ–ª—É—á–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏")
                return None
            
            logger.debug(f"–ü–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø–∞–º—è—Ç–∏ –¥–ª—è {hardware_id}")
            memory_context = await self.memory_workflow.get_memory_context_parallel(hardware_id)
            
            if memory_context:
                logger.debug(f"‚úÖ –ü–æ–ª—É—á–µ–Ω –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø–∞–º—è—Ç–∏: {len(memory_context)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤")
            else:
                logger.debug("‚ö†Ô∏è –ö–æ–Ω—Ç–µ–∫—Å—Ç –ø–∞–º—è—Ç–∏ –ø—É—Å—Ç")
            
            return memory_context
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø–∞–º—è—Ç–∏: {e}")
            return None

    async def _iter_processed_sentences(
        self,
        text: str,
        screenshot: Optional[str],
        memory_context: Optional[Dict[str, Any]],
        subscription_context: str = ""  # MVP 7: Subscription context (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)
    ) -> AsyncGenerator[str, None]:
        """–°—Ç—Ä–∏–º–∏–Ω–≥–æ–≤–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è —Å —É—á—ë—Ç–æ–º –ø–∞–º—è—Ç–∏, subscription context –∏ —Å–∫—Ä–∏–Ω—à–æ—Ç–∞."""
        # MVP 7: –û–±–æ–≥–∞—â–∞–µ–º —Ç–µ–∫—Å—Ç subscription context –∏ memory context
        if subscription_context:
            enriched_text = self._enrich_with_subscription_and_memory(text, subscription_context, memory_context)
        else:
            enriched_text = self._enrich_with_memory(text, memory_context)

        screenshot_data: Optional[bytes] = None
        if screenshot:
            import base64
            try:
                screenshot_data = base64.b64decode(screenshot)
                logger.info(f"üì∏ –°–∫—Ä–∏–Ω—à–æ—Ç –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω: {len(screenshot_data)} bytes")
            except Exception as decode_error:
                logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞—Ç—å —Å–∫—Ä–∏–Ω—à–æ—Ç: {decode_error}")
                screenshot_data = None

        yielded_any = False
        if self.text_module and hasattr(self.text_module, 'process'):
            logger.info(f"üîÑ –°—Ç—Ä–∏–º–∏–Ω–≥ —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ Text Module: '{enriched_text[:80]}...'")
            try:
                async for chunk in self._stream_text_module(enriched_text, screenshot_data):
                    sentence = (self._extract_text_chunk(chunk) or '').strip()
                    if sentence:
                        yielded_any = True
                        logger.debug(f"üì® TextModule sentence: '{sentence[:120]}...'")
                        yield sentence
            except Exception as processing_error:
                logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ Text Module: {processing_error}. –ò—Å–ø–æ–ª—å–∑—É–µ–º fallback")
        elif self.text_module and hasattr(self.text_module, 'process_text_streaming'):
            # Legacy fallback –Ω–∞ –ø—Ä—è–º–æ–π –¥–æ—Å—Ç—É–ø –∫ TextProcessor
            logger.info(f"üîÑ Legacy —Å—Ç—Ä–∏–º–∏–Ω–≥ —Ç–µ–∫—Å—Ç–∞: '{enriched_text[:80]}...'")
            try:
                async for processed_sentence in self.text_module.process_text_streaming(enriched_text, screenshot_data):
                    sentence = (processed_sentence or '').strip()
                    if sentence:
                        yielded_any = True
                        logger.debug(f"üì® Legacy TextProcessor sentence: '{sentence[:120]}...'")
                        yield sentence
            except Exception as processing_error:
                logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ legacy TextProcessor: {processing_error}. –ò—Å–ø–æ–ª—å–∑—É–µ–º fallback")

        if not yielded_any:
            logger.debug("‚ö†Ô∏è TextProcessor –Ω–µ –≤–µ—Ä–Ω—É–ª –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π, –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback —Ä–∞–∑–±–∏–≤–∫—É")
            for fallback_sentence in self._split_into_sentences(enriched_text):
                if fallback_sentence:
                    yield fallback_sentence

    async def _sanitize_for_tts(self, text: str) -> str:
        """
        –û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è —Å–∏–Ω—Ç–µ–∑–∞ —Ä–µ—á–∏ —á–µ—Ä–µ–∑ –º–æ–¥—É–ª—å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        """
        if not text:
            return ""

        if self.text_filter_module and hasattr(self.text_filter_module, 'process'):
            try:
                result = await self.text_filter_module.process({
                    "operation": "clean_text",
                    "text": text,
                    "options": {
                        "remove_special_chars": True,
                        "remove_extra_whitespace": True,
                        "normalize_unicode": True,
                        "remove_control_chars": True
                    }
                })
                if isinstance(result, dict) and result.get("success") and result.get("cleaned_text") is not None:
                    return result.get("cleaned_text", "").strip()
            except Exception as err:
                logger.warning("‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ TextFilterModule: %s", err)

        return text.strip()

    async def _split_complete_sentences(self, text: str) -> tuple[list[str], str]:
        """
        –†–∞–∑–±–∏–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è —á–µ—Ä–µ–∑ –º–æ–¥—É–ª—å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        """
        if not text:
            return [], ""

        if self.text_filter_module and hasattr(self.text_filter_module, 'process'):
            try:
                result = await self.text_filter_module.process({
                    "operation": "split_sentences",
                    "text": text
                })
                if isinstance(result, dict) and result.get("success"):
                    return result.get("sentences", []), result.get("remainder", "")
            except Exception as err:
                logger.warning("‚ö†Ô∏è –û—à–∏–±–∫–∞ —Ä–∞–∑–±–∏–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ TextFilterModule: %s", err)

        stripped = text.strip()
        return ([stripped] if stripped else [], "")

    async def _count_meaningful_words(self, text: str) -> int:
        """
        –ü–æ–¥—Å—á—ë—Ç –∑–Ω–∞—á–∏–º—ã—Ö —Å–ª–æ–≤ —á–µ—Ä–µ–∑ –º–æ–¥—É–ª—å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        """
        if not text:
            return 0

        if self.text_filter_module and hasattr(self.text_filter_module, 'process'):
            try:
                result = await self.text_filter_module.process({
                    "operation": "count_meaningful_words",
                    "text": text
                })
                if isinstance(result, dict) and result.get("success"):
                    return int(result.get("count", 0))
            except Exception as err:
                logger.warning("‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–¥—Å—á—ë—Ç–∞ —Å–ª–æ–≤ —á–µ—Ä–µ–∑ TextFilterModule: %s", err)

        return len([w for w in text.split() if w.strip()])

    async def _stream_text_module(self, text: str, screenshot_data: Optional[bytes]):
        """–°—Ç—Ä–∏–º–∏–Ω–≥ –æ—Ç–≤–µ—Ç–æ–≤ –∏–∑ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –º–æ–¥—É–ª—è."""
        payload = {"text": text}
        if screenshot_data:
            payload["image_data"] = screenshot_data

        async for chunk in self._stream_module_results(self.text_module, payload):
            yield chunk

    async def _stream_audio_module(self, text: str):
        """–°—Ç—Ä–∏–º–∏–Ω–≥ –∞—É–¥–∏–æ —á–∞–Ω–∫–æ–≤ –∏–∑ –∞—É–¥–∏–æ –º–æ–¥—É–ª—è."""
        async for chunk in self._stream_module_results(self.audio_module, {"text": text}):
            yield chunk

    async def _stream_module_results(self, module, payload: Dict[str, Any]):
        """–£–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≤—ã–∑–æ–≤ module.process —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π async generator."""
        if not module or not hasattr(module, 'process'):
            return
        try:
            result = await module.process(payload)
            if result is None:
                return
            if hasattr(result, "__aiter__"):
                async for item in result:
                    yield item
            else:
                yield result
        except Exception as err:
            logger.warning("‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ –º–æ–¥—É–ª—è %s: %s", getattr(module, 'name', 'unknown'), err)

    def _extract_text_chunk(self, chunk: Any) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç–≤–µ—Ç –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –º–æ–¥—É–ª—è."""
        if chunk is None:
            return ""
        if isinstance(chunk, str):
            return chunk
        if isinstance(chunk, dict):
            for key in ("text", "text_response", "value", "chunk"):
                value = chunk.get(key)
                if isinstance(value, str):
                    return value
        return ""

    def _extract_audio_chunk(self, chunk: Any) -> bytes:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∞—É–¥–∏–æ –±–∞–π—Ç—ã –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –º–æ–¥—É–ª—è."""
        if chunk is None:
            return b""
        if isinstance(chunk, (bytes, bytearray)):
            return bytes(chunk)
        if isinstance(chunk, dict):
            for key in ("audio", "audio_chunk", "audio_data", "data", "value"):
                value = chunk.get(key)
                if isinstance(value, (bytes, bytearray)):
                    return bytes(value)
        return b""

    def _enrich_with_memory(self, text: str, memory_context: Optional[Dict[str, Any]]) -> str:
        """
        –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –ø–∞–º—è—Ç–∏

        Args:
            text: –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç
            memory_context: –ö–æ–Ω—Ç–µ–∫—Å—Ç –ø–∞–º—è—Ç–∏ (–¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å–ª–æ–≤–∞—Ä–µ–º)
        """
        if not memory_context:
            return text

        # ‚ö†Ô∏è CRITICAL: –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ memory_context - —ç—Ç–æ —Å–ª–æ–≤–∞—Ä—å
        if not isinstance(memory_context, dict):
            logger.warning(
                f"‚ö†Ô∏è Memory context is not a dict (type={type(memory_context).__name__}), skipping enrichment"
            )
            return text

        try:
            memory_info = memory_context.get('recent_context', '') if memory_context else ''
            if memory_info:
                enriched_text = f"–ö–æ–Ω—Ç–µ–∫—Å—Ç: {memory_info}\n\n{text}"
                logger.debug("–¢–µ–∫—Å—Ç –æ–±–æ–≥–∞—â–µ–Ω –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –ø–∞–º—è—Ç–∏")
                return enriched_text
            return text
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–±–æ–≥–∞—â–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –ø–∞–º—è—Ç—å—é: {e}")
            return text

    async def _stream_audio_for_sentence(self, sentence: str, sentence_index: int) -> AsyncGenerator[bytes, None]:
        """–°—Ç—Ä–∏–º–∏—Ç –∞—É–¥–∏–æ —á–∞–Ω–∫–∏ –¥–ª—è –æ–¥–Ω–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è."""
        if not sentence.strip():
            return
        if not self.audio_module:
            logger.warning("‚ö†Ô∏è AudioProcessor –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –∞—É–¥–∏–æ")
            return
        if hasattr(self.audio_module, 'process'):
            try:
                logger.info(f"üîä –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∞—É–¥–∏–æ –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è #{sentence_index}: '{sentence[:80]}...'")
                chunk_count = 0
                async for chunk in self._stream_audio_module(sentence):
                    audio_chunk = self._extract_audio_chunk(chunk)
                    if audio_chunk:
                        chunk_count += 1
                        logger.info(f"üîä Audio chunk #{chunk_count} –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è #{sentence_index}: {len(audio_chunk)} bytes")
                        yield audio_chunk
                logger.info(f"‚úÖ –ê—É–¥–∏–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è #{sentence_index}: {chunk_count} —á–∞–Ω–∫–æ–≤")
            except Exception as audio_error:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∞—É–¥–∏–æ –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è #{sentence_index}: {audio_error}")
        elif hasattr(self.audio_module, 'generate_speech_streaming'):
            # Legacy fallback
            try:
                logger.info(f"üîä Legacy –∞—É–¥–∏–æ –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è #{sentence_index}: '{sentence[:80]}...'")
                chunk_count = 0
                async for audio_chunk in self.audio_module.generate_speech_streaming(sentence):
                    if audio_chunk:
                        chunk_count += 1
                        logger.info(f"üîä Audio chunk #{chunk_count} –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è #{sentence_index}: {len(audio_chunk)} bytes")
                        yield audio_chunk
                logger.info(f"‚úÖ Legacy –∞—É–¥–∏–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è #{sentence_index}: {chunk_count} —á–∞–Ω–∫–æ–≤")
            except Exception as audio_error:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ legacy –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∞—É–¥–∏–æ –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è #{sentence_index}: {audio_error}")
    
    async def _parse_assistant_response(self, response: Union[str, Dict[str, Any]], session_id: str):
        """
        –ü–∞—Ä—Å–∏–Ω–≥ –æ—Ç–≤–µ—Ç–∞ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è text –∏ command_payload (–§–∞–∑–∞ 2)
        
        Args:
            response: –û—Ç–≤–µ—Ç –æ—Ç —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –º–æ–¥—É–ª—è (—Å—Ç—Ä–æ–∫–∞ –∏–ª–∏ —Å–ª–æ–≤–∞—Ä—å)
            session_id: ID —Å–µ—Å—Å–∏–∏ –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
            
        Returns:
            ParsedResponse —Å text_response –∏ –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–º command_payload
        """
        try:
            config = get_config()
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–∏—á–∞-—Ñ–ª–∞–≥ –∏ kill-switch
            if (not config.features.forward_assistant_actions or 
                config.kill_switches.disable_forward_assistant_actions):
                # –§–∏—á–∞ –≤—ã–∫–ª—é—á–µ–Ω–∞ - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç
                if isinstance(response, dict):
                    return self._assistant_parser.parse(response.get('text', str(response)))
                return self._assistant_parser.parse(response)
            
            # –ü–∞—Ä—Å–∏–º –æ—Ç–≤–µ—Ç, –ø–µ—Ä–µ–¥–∞–≤–∞—è session_id –¥–ª—è –ø–æ–¥—Å—Ç–∞–Ω–æ–≤–∫–∏ –≤ action-–æ—Ç–≤–µ—Ç—ã
            return self._assistant_parser.parse(response, session_id=session_id)
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ—Ç–≤–µ—Ç–∞ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞: {e}, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç")
            # Fallback –Ω–∞ –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç
            if isinstance(response, dict):
                text = response.get('text', str(response))
            else:
                text = str(response)
            return self._assistant_parser.parse(text)
    
    def _log_command_detected(self, parsed, session_id: str):
        """
        –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –∫–æ–º–∞–Ω–¥—ã (–§–∞–∑–∞ 2)
        
        Args:
            parsed: ParsedResponse —Å command_payload
            session_id: ID —Å–µ—Å—Å–∏–∏
        """
        if not parsed.command_payload:
            return
        
        payload = parsed.command_payload.get('payload', {})
        command = payload.get('command', 'unknown')
        args = payload.get('args', {})
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º feature_id –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∫–æ–º–∞–Ω–¥—ã
        if command == 'open_app':
            feature_id = 'F-2025-013-open-app'
        elif command == 'close_app':
            feature_id = 'F-2025-014-close-app'
        elif command in ('create_subscription', 'cancel_subscription'):
            feature_id = 'F-2025-017-stripe-payment'
        else:
            feature_id = 'F-2025-016-mcp-app-opening-integration'
        
        log_structured(
            logger,
            logging.INFO,
            f"[{feature_id}] Command detected: {command}",
            scope="command",
            method="parse_assistant_response",
            decision="start",
            ctx={
                "session_id": session_id,
                "command": command,
                "args": args,
                "feature_id": feature_id
            }
        )
    
    def _log_command_complete(self, session_id: str):
        """
        –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ–≥–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∫–æ–º–∞–Ω–¥—ã (–§–∞–∑–∞ 2)
        
        Args:
            session_id: ID —Å–µ—Å—Å–∏–∏
        """
        if not self._pending_command_payload:
            return
        
        payload = self._pending_command_payload.get('payload', {})
        command = payload.get('command', 'unknown')
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º feature_id –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∫–æ–º–∞–Ω–¥—ã
        if command == 'open_app':
            feature_id = 'F-2025-013-open-app'
        elif command == 'close_app':
            feature_id = 'F-2025-014-close-app'
        elif command in ('create_subscription', 'cancel_subscription'):
            feature_id = 'F-2025-017-stripe-payment'
        else:
            feature_id = 'F-2025-016-mcp-app-opening-integration'
        
        log_structured(
            logger,
            logging.INFO,
            f"[{feature_id}] Command forwarded: {command}",
            scope="command",
            method="process_request_streaming",
            decision="complete",
            ctx={
                "session_id": session_id,
                "command": command,
                "feature_id": feature_id
            }
        )
    
    def _extract_json_from_markdown(self, text: str) -> str:
        """
        –£–¥–∞–ª—è–µ—Ç Markdown-–æ–±—ë—Ä—Ç–∫–∏ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —á–∏—Å—Ç—ã–π JSON —Ç–µ–∫—Å—Ç.
        –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ä–∞–∑–ª–∏—á–Ω—ã–µ –≤–∞—Ä–∏–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–æ–≤ LLM:
        - ```json {...}```
        - ``` {...}```
        - json {...}
        - –¢–µ–∫—Å—Ç –¥–æ/–ø–æ—Å–ª–µ JSON
        - –ß–∞—Å—Ç–∏—á–Ω—ã–π JSON (–¥–ª—è –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è)
        - JSON —Å –ª–∏—à–Ω–∏–º–∏ –ø—Ä–æ–±–µ–ª–∞–º–∏/–ø–µ—Ä–µ–Ω–æ—Å–∞–º–∏
        - JSON —Å trailing commas (—É–¥–∞–ª—è—é—Ç—Å—è)
        - JSON —Å –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è–º–∏ (—É–¥–∞–ª—è—é—Ç—Å—è)
        
        Args:
            text: –¢–µ–∫—Å—Ç, –∫–æ—Ç–æ—Ä—ã–π –º–æ–∂–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å JSON –≤ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–∞—Ö
            
        Returns:
            –ß–∏—Å—Ç—ã–π JSON —Ç–µ–∫—Å—Ç –±–µ–∑ markdown-—Ä–∞–∑–º–µ—Ç–∫–∏ –∏ –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤
        """
        if not text:
            return ""

        import re
        
        text = str(text).strip()

        # –í–∞—Ä–∏–∞–Ω—Ç 1: Markdown code fence ```json ... ``` –∏–ª–∏ ``` ... ```
        if text.startswith("```"):
            # –£–¥–∞–ª—è–µ–º –æ—Ç–∫—Ä—ã–≤–∞—é—â–∏–π fence
            text = text[3:]
            text = text.lstrip()
            
            # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π —è–∑—ã–∫ (json/JSON/JSONC –∏ —Ç.–¥.)
            lowered = text.lower()
            if lowered.startswith("json"):
                text = text[4:]
            text = text.lstrip()
            
            # –£–¥–∞–ª—è–µ–º –≤–µ–¥—É—â–∏–µ –ø–µ—Ä–µ–≤–æ–¥—ã —Å—Ç—Ä–æ–∫–∏
            while text.startswith(("\n", "\r")):
                text = text[1:]
            
            # –£–¥–∞–ª—è–µ–º –∑–∞–∫—Ä—ã–≤–∞—é—â–∏–π fence (–º–æ–∂–µ—Ç –±—ã—Ç—å –≤ –∫–æ–Ω—Ü–µ –∏–ª–∏ –≤ —Å–µ—Ä–µ–¥–∏–Ω–µ –¥–ª—è —á–∞—Å—Ç–∏—á–Ω–æ–≥–æ JSON)
            text = text.rstrip()
            if text.endswith("```"):
                text = text[:-3]
            text = text.strip()

        # –í–∞—Ä–∏–∞–Ω—Ç 2: –¢–µ–∫—Å—Ç –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å "json" (–±–µ–∑ markdown)
        # –£–¥–∞–ª—è–µ–º "json" –µ—Å–ª–∏ –æ–Ω —Å—Ç–æ–∏—Ç –ø–µ—Ä–µ–¥ JSON –æ–±—ä–µ–∫—Ç–æ–º
        text_lower = text.lower()
        if text_lower.startswith("json") and len(text) > 4:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –ø–æ—Å–ª–µ "json" –∏–¥—ë—Ç –ø—Ä–æ–±–µ–ª/–ø–µ—Ä–µ–Ω–æ—Å –∏ –∑–∞—Ç–µ–º {
            after_json = text[4:].lstrip()
            if after_json.startswith("{") or after_json.startswith("\n{") or after_json.startswith("\r{"):
                text = after_json

        # –í–∞—Ä–∏–∞–Ω—Ç 3: –¢–µ–∫—Å—Ç –¥–æ/–ø–æ—Å–ª–µ JSON - –∏–∑–≤–ª–µ–∫–∞–µ–º —Ç–æ–ª—å–∫–æ JSON –æ–±—ä–µ–∫—Ç
        # –ò—â–µ–º –ø–µ—Ä–≤—É—é –æ—Ç–∫—Ä—ã–≤–∞—é—â—É—é —Å–∫–æ–±–∫—É –∏ –ø–æ—Å–ª–µ–¥–Ω—é—é –∑–∞–∫—Ä—ã–≤–∞—é—â—É—é
        first_brace = text.find("{")
        last_brace = text.rfind("}")
        
        if first_brace != -1 and last_brace != -1 and first_brace < last_brace:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º JSON –æ–±—ä–µ–∫—Ç
            json_candidate = text[first_brace:last_brace + 1]
            
            # –û—á–∏—â–∞–µ–º –æ—Ç –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤ –≤–æ–∫—Ä—É–≥
            json_candidate = json_candidate.strip()
            
            # –£–¥–∞–ª—è–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã:
            # 1. –£–¥–∞–ª—è–µ–º –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ (// –∏ /* */) - —Ö–æ—Ç—è JSON –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç, LLM –º–æ–∂–µ—Ç –∏—Ö –¥–æ–±–∞–≤–∏—Ç—å
            json_candidate = re.sub(r'//.*?$', '', json_candidate, flags=re.MULTILINE)  # –û–¥–Ω–æ—Å—Ç—Ä–æ—á–Ω—ã–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏
            json_candidate = re.sub(r'/\*.*?\*/', '', json_candidate, flags=re.DOTALL)  # –ú–Ω–æ–≥–æ—Å—Ç—Ä–æ—á–Ω—ã–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏
            
            # 2. –£–¥–∞–ª—è–µ–º trailing commas –ø–µ—Ä–µ–¥ –∑–∞–∫—Ä—ã–≤–∞—é—â–∏–º–∏ —Å–∫–æ–±–∫–∞–º–∏/—Ñ–∏–≥—É—Ä–Ω—ã–º–∏ —Å–∫–æ–±–∫–∞–º–∏
            json_candidate = re.sub(r',\s*}', '}', json_candidate)  # Trailing comma –ø–µ—Ä–µ–¥ }
            json_candidate = re.sub(r',\s*]', ']', json_candidate)  # Trailing comma –ø–µ—Ä–µ–¥ ]
            
            # 3. –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø—Ä–æ–±–µ–ª—ã –∏ –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫
            json_candidate = re.sub(r'\n\s*\n', '\n', json_candidate)  # –£–¥–∞–ª—è–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
            json_candidate = re.sub(r'[ \t]+', ' ', json_candidate)  # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø—Ä–æ–±–µ–ª—ã
            
            # 4. –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –≤–æ–∫—Ä—É–≥ –¥–≤–æ–µ—Ç–æ—á–∏–π –∏ –∑–∞–ø—è—Ç—ã—Ö
            json_candidate = re.sub(r'\s*:\s*', ': ', json_candidate)  # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø—Ä–æ–±–µ–ª—ã –≤–æ–∫—Ä—É–≥ :
            json_candidate = re.sub(r'\s*,\s*', ', ', json_candidate)  # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø—Ä–æ–±–µ–ª—ã –≤–æ–∫—Ä—É–≥ ,
            
            return json_candidate

        # –ï—Å–ª–∏ JSON –æ–±—ä–µ–∫—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—á–∏—â–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
        # (–º–æ–∂–µ—Ç –±—ã—Ç—å —á–∞—Å—Ç–∏—á–Ω—ã–π JSON –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è)
        return text.strip()

    def _split_into_sentences(self, text: str) -> list[str]:
        """
        –†–∞–∑–±–∏–≤–∫–∞ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
        
        Args:
            text: –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç
            
        Returns:
            –°–ø–∏—Å–æ–∫ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
        """
        try:
            # –ü—Ä–æ—Å—Ç–∞—è —Ä–∞–∑–±–∏–≤–∫–∞ –ø–æ —Ç–æ—á–∫–∞–º, –≤–æ—Å–∫–ª–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–º –∏ –≤–æ–ø—Ä–æ—Å–∏—Ç–µ–ª—å–Ω—ã–º –∑–Ω–∞–∫–∞–º
            import re
            sentences = re.split(r'[.!?]+', text)
            
            # –û—á–∏—â–∞–µ–º –æ—Ç –ø—É—Å—Ç—ã—Ö —Å—Ç—Ä–æ–∫ –∏ –ª–∏—à–Ω–∏—Ö –ø—Ä–æ–±–µ–ª–æ–≤
            clean_sentences = [s.strip() for s in sentences if s.strip()]
            
            logger.debug(f"–¢–µ–∫—Å—Ç —Ä–∞–∑–±–∏—Ç –Ω–∞ {len(clean_sentences)} –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π")
            return clean_sentences
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Ä–∞–∑–±–∏–≤–∫–∏ —Ç–µ–∫—Å—Ç–∞: {e}")
            return [text]  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –≤–µ—Å—å —Ç–µ–∫—Å—Ç –∫–∞–∫ –æ–¥–Ω–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ
    
    async def cleanup(self):
        """–û—á–∏—Å—Ç–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤"""
        try:
            logger.info("–û—á–∏—Å—Ç–∫–∞ StreamingWorkflowIntegration...")
            self.is_initialized = False
            logger.info("‚úÖ StreamingWorkflowIntegration –æ—á–∏—â–µ–Ω")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ StreamingWorkflowIntegration: {e}")

    async def _get_memory_context_parallel(self, hardware_id: str) -> Optional[Dict[str, Any]]:
        """
        –ù–µ–±–ª–æ–∫–∏—Ä—É—é—â–µ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø–∞–º—è—Ç–∏
        
        Args:
            hardware_id: –ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è
        """
        try:
            if not self.memory_workflow:
                logger.debug("MemoryWorkflow –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –ø–æ–ª—É—á–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏")
                return None
            
            logger.debug(f"–ü–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø–∞–º—è—Ç–∏ –¥–ª—è {hardware_id}")
            memory_context = await self.memory_workflow.get_memory_context_parallel(hardware_id)
            
            if memory_context:
                logger.debug(f"‚úÖ –ü–æ–ª—É—á–µ–Ω –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø–∞–º—è—Ç–∏: {len(memory_context)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤")
            else:
                logger.debug("‚ö†Ô∏è –ö–æ–Ω—Ç–µ–∫—Å—Ç –ø–∞–º—è—Ç–∏ –ø—É—Å—Ç")
            
            return memory_context
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø–∞–º—è—Ç–∏: {e}")
            return None

    async def _iter_processed_sentences(
        self,
        text: str,
        screenshot: Optional[str],
        memory_context: Optional[Dict[str, Any]],
        subscription_context: str = ""  # MVP 7: Subscription context (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)
    ) -> AsyncGenerator[str, None]:
        """–°—Ç—Ä–∏–º–∏–Ω–≥–æ–≤–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è —Å —É—á—ë—Ç–æ–º –ø–∞–º—è—Ç–∏, subscription context –∏ —Å–∫—Ä–∏–Ω—à–æ—Ç–∞."""
        # MVP 7: –û–±–æ–≥–∞—â–∞–µ–º —Ç–µ–∫—Å—Ç subscription context –∏ memory context
        if subscription_context:
            enriched_text = self._enrich_with_subscription_and_memory(text, subscription_context, memory_context)
        else:
            enriched_text = self._enrich_with_memory(text, memory_context)

        screenshot_data: Optional[bytes] = None
        if screenshot:
            import base64
            try:
                screenshot_data = base64.b64decode(screenshot)
                logger.info(f"üì∏ –°–∫—Ä–∏–Ω—à–æ—Ç –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω: {len(screenshot_data)} bytes")
            except Exception as decode_error:
                logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞—Ç—å —Å–∫—Ä–∏–Ω—à–æ—Ç: {decode_error}")
                screenshot_data = None

        yielded_any = False
        if self.text_module and hasattr(self.text_module, 'process'):
            logger.info(f"üîÑ –°—Ç—Ä–∏–º–∏–Ω–≥ —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ Text Module: '{enriched_text[:80]}...'")
            try:
                async for chunk in self._stream_text_module(enriched_text, screenshot_data):
                    sentence = (self._extract_text_chunk(chunk) or '').strip()
                    if sentence:
                        yielded_any = True
                        logger.debug(f"üì® TextModule sentence: '{sentence[:120]}...'")
                        yield sentence
            except Exception as processing_error:
                logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ Text Module: {processing_error}. –ò—Å–ø–æ–ª—å–∑—É–µ–º fallback")
        elif self.text_module and hasattr(self.text_module, 'process_text_streaming'):
            # Legacy fallback –Ω–∞ –ø—Ä—è–º–æ–π –¥–æ—Å—Ç—É–ø –∫ TextProcessor
            logger.info(f"üîÑ Legacy —Å—Ç—Ä–∏–º–∏–Ω–≥ —Ç–µ–∫—Å—Ç–∞: '{enriched_text[:80]}...'")
            try:
                async for processed_sentence in self.text_module.process_text_streaming(enriched_text, screenshot_data):
                    sentence = (processed_sentence or '').strip()
                    if sentence:
                        yielded_any = True
                        logger.debug(f"üì® Legacy TextProcessor sentence: '{sentence[:120]}...'")
                        yield sentence
            except Exception as processing_error:
                logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ legacy TextProcessor: {processing_error}. –ò—Å–ø–æ–ª—å–∑—É–µ–º fallback")

        if not yielded_any:
            logger.debug("‚ö†Ô∏è TextProcessor –Ω–µ –≤–µ—Ä–Ω—É–ª –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π, –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback —Ä–∞–∑–±–∏–≤–∫—É")
            for fallback_sentence in self._split_into_sentences(enriched_text):
                if fallback_sentence:
                    yield fallback_sentence

    async def _sanitize_for_tts(self, text: str) -> str:
        """
        –û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è —Å–∏–Ω—Ç–µ–∑–∞ —Ä–µ—á–∏ —á–µ—Ä–µ–∑ –º–æ–¥—É–ª—å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        """
        if not text:
            return ""

        if self.text_filter_module and hasattr(self.text_filter_module, 'process'):
            try:
                result = await self.text_filter_module.process({
                    "operation": "clean_text",
                    "text": text,
                    "options": {
                        "remove_special_chars": True,
                        "remove_extra_whitespace": True,
                        "normalize_unicode": True,
                        "remove_control_chars": True
                    }
                })
                if isinstance(result, dict) and result.get("success") and result.get("cleaned_text") is not None:
                    return result.get("cleaned_text", "").strip()
            except Exception as err:
                logger.warning("‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ TextFilterModule: %s", err)

        return text.strip()

    async def _split_complete_sentences(self, text: str) -> tuple[list[str], str]:
        """
        –†–∞–∑–±–∏–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è —á–µ—Ä–µ–∑ –º–æ–¥—É–ª—å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        """
        if not text:
            return [], ""

        if self.text_filter_module and hasattr(self.text_filter_module, 'process'):
            try:
                result = await self.text_filter_module.process({
                    "operation": "split_sentences",
                    "text": text
                })
                if isinstance(result, dict) and result.get("success"):
                    return result.get("sentences", []), result.get("remainder", "")
            except Exception as err:
                logger.warning("‚ö†Ô∏è –û—à–∏–±–∫–∞ —Ä–∞–∑–±–∏–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ TextFilterModule: %s", err)

        stripped = text.strip()
        return ([stripped] if stripped else [], "")

    async def _count_meaningful_words(self, text: str) -> int:
        """
        –ü–æ–¥—Å—á—ë—Ç –∑–Ω–∞—á–∏–º—ã—Ö —Å–ª–æ–≤ —á–µ—Ä–µ–∑ –º–æ–¥—É–ª—å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        """
        if not text:
            return 0

        if self.text_filter_module and hasattr(self.text_filter_module, 'process'):
            try:
                result = await self.text_filter_module.process({
                    "operation": "count_meaningful_words",
                    "text": text
                })
                if isinstance(result, dict) and result.get("success"):
                    return int(result.get("count", 0))
            except Exception as err:
                logger.warning("‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–¥—Å—á—ë—Ç–∞ —Å–ª–æ–≤ —á–µ—Ä–µ–∑ TextFilterModule: %s", err)

        return len([w for w in text.split() if w.strip()])

    async def _stream_text_module(self, text: str, screenshot_data: Optional[bytes]):
        """–°—Ç—Ä–∏–º–∏–Ω–≥ –æ—Ç–≤–µ—Ç–æ–≤ –∏–∑ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –º–æ–¥—É–ª—è."""
        payload = {"text": text}
        if screenshot_data:
            payload["image_data"] = screenshot_data

        async for chunk in self._stream_module_results(self.text_module, payload):
            yield chunk

    async def _stream_audio_module(self, text: str):
        """–°—Ç—Ä–∏–º–∏–Ω–≥ –∞—É–¥–∏–æ —á–∞–Ω–∫–æ–≤ –∏–∑ –∞—É–¥–∏–æ –º–æ–¥—É–ª—è."""
        async for chunk in self._stream_module_results(self.audio_module, {"text": text}):
            yield chunk

    async def _stream_module_results(self, module, payload: Dict[str, Any]):
        """–£–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≤—ã–∑–æ–≤ module.process —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π async generator."""
        if not module or not hasattr(module, 'process'):
            return
        try:
            result = await module.process(payload)
            if result is None:
                return
            if hasattr(result, "__aiter__"):
                async for item in result:
                    yield item
            else:
                yield result
        except Exception as err:
            logger.warning("‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ –º–æ–¥—É–ª—è %s: %s", getattr(module, 'name', 'unknown'), err)

    def _extract_text_chunk(self, chunk: Any) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç–≤–µ—Ç –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –º–æ–¥—É–ª—è."""
        if chunk is None:
            return ""
        if isinstance(chunk, str):
            return chunk
        if isinstance(chunk, dict):
            for key in ("text", "text_response", "value", "chunk"):
                value = chunk.get(key)
                if isinstance(value, str):
                    return value
        return ""

    def _extract_audio_chunk(self, chunk: Any) -> bytes:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∞—É–¥–∏–æ –±–∞–π—Ç—ã –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –º–æ–¥—É–ª—è."""
        if chunk is None:
            return b""
        if isinstance(chunk, (bytes, bytearray)):
            return bytes(chunk)
        if isinstance(chunk, dict):
            for key in ("audio", "audio_chunk", "audio_data", "data", "value"):
                value = chunk.get(key)
                if isinstance(value, (bytes, bytearray)):
                    return bytes(value)
        return b""

    def _enrich_with_memory(self, text: str, memory_context: Optional[Dict[str, Any]]) -> str:
        """
        –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –ø–∞–º—è—Ç–∏

        Args:
            text: –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç
            memory_context: –ö–æ–Ω—Ç–µ–∫—Å—Ç –ø–∞–º—è—Ç–∏ (–¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å–ª–æ–≤–∞—Ä–µ–º)
        """
        if not memory_context:
            return text

        # ‚ö†Ô∏è CRITICAL: –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ memory_context - —ç—Ç–æ —Å–ª–æ–≤–∞—Ä—å
        if not isinstance(memory_context, dict):
            logger.warning(
                f"‚ö†Ô∏è Memory context is not a dict (type={type(memory_context).__name__}), skipping enrichment"
            )
            return text

        try:
            memory_info = memory_context.get('recent_context', '') if memory_context else ''
            if memory_info:
                enriched_text = f"–ö–æ–Ω—Ç–µ–∫—Å—Ç: {memory_info}\n\n{text}"
                logger.debug("–¢–µ–∫—Å—Ç –æ–±–æ–≥–∞—â–µ–Ω –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –ø–∞–º—è—Ç–∏")
                return enriched_text
            return text
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–±–æ–≥–∞—â–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –ø–∞–º—è—Ç—å—é: {e}")
            return text

    async def _stream_audio_for_sentence(self, sentence: str, sentence_index: int) -> AsyncGenerator[bytes, None]:
        """–°—Ç—Ä–∏–º–∏—Ç –∞—É–¥–∏–æ —á–∞–Ω–∫–∏ –¥–ª—è –æ–¥–Ω–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è."""
        if not sentence.strip():
            return
        if not self.audio_module:
            logger.warning("‚ö†Ô∏è AudioProcessor –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –∞—É–¥–∏–æ")
            return
        if hasattr(self.audio_module, 'process'):
            try:
                logger.info(f"üîä –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∞—É–¥–∏–æ –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è #{sentence_index}: '{sentence[:80]}...'")
                chunk_count = 0
                async for chunk in self._stream_audio_module(sentence):
                    audio_chunk = self._extract_audio_chunk(chunk)
                    if audio_chunk:
                        chunk_count += 1
                        logger.info(f"üîä Audio chunk #{chunk_count} –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è #{sentence_index}: {len(audio_chunk)} bytes")
                        yield audio_chunk
                logger.info(f"‚úÖ –ê—É–¥–∏–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è #{sentence_index}: {chunk_count} —á–∞–Ω–∫–æ–≤")
            except Exception as audio_error:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∞—É–¥–∏–æ –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è #{sentence_index}: {audio_error}")
        elif hasattr(self.audio_module, 'generate_speech_streaming'):
            # Legacy fallback
            try:
                logger.info(f"üîä Legacy –∞—É–¥–∏–æ –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è #{sentence_index}: '{sentence[:80]}...'")
                chunk_count = 0
                async for audio_chunk in self.audio_module.generate_speech_streaming(sentence):
                    if audio_chunk:
                        chunk_count += 1
                        logger.info(f"üîä Audio chunk #{chunk_count} –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è #{sentence_index}: {len(audio_chunk)} bytes")
                        yield audio_chunk
                logger.info(f"‚úÖ Legacy –∞—É–¥–∏–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è #{sentence_index}: {chunk_count} —á–∞–Ω–∫–æ–≤")
            except Exception as audio_error:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ legacy –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∞—É–¥–∏–æ –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è #{sentence_index}: {audio_error}")
    
    async def _parse_assistant_response(self, response: Union[str, Dict[str, Any]], session_id: str):
        """
        –ü–∞—Ä—Å–∏–Ω–≥ –æ—Ç–≤–µ—Ç–∞ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è text –∏ command_payload (–§–∞–∑–∞ 2)
        
        Args:
            response: –û—Ç–≤–µ—Ç –æ—Ç —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –º–æ–¥—É–ª—è (—Å—Ç—Ä–æ–∫–∞ –∏–ª–∏ —Å–ª–æ–≤–∞—Ä—å)
            session_id: ID —Å–µ—Å—Å–∏–∏ –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
            
        Returns:
            ParsedResponse —Å text_response –∏ –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–º command_payload
        """
        try:
            config = get_config()
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–∏—á–∞-—Ñ–ª–∞–≥ –∏ kill-switch
            if (not config.features.forward_assistant_actions or 
                config.kill_switches.disable_forward_assistant_actions):
                # –§–∏—á–∞ –≤—ã–∫–ª—é—á–µ–Ω–∞ - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç
                if isinstance(response, dict):
                    return self._assistant_parser.parse(response.get('text', str(response)))
                return self._assistant_parser.parse(response)
            
            # –ü–∞—Ä—Å–∏–º –æ—Ç–≤–µ—Ç, –ø–µ—Ä–µ–¥–∞–≤–∞—è session_id –¥–ª—è –ø–æ–¥—Å—Ç–∞–Ω–æ–≤–∫–∏ –≤ action-–æ—Ç–≤–µ—Ç—ã
            return self._assistant_parser.parse(response, session_id=session_id)
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ—Ç–≤–µ—Ç–∞ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞: {e}, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç")
            # Fallback –Ω–∞ –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç
            if isinstance(response, dict):
                text = response.get('text', str(response))
            else:
                text = str(response)
            return self._assistant_parser.parse(text)
    
    def _log_command_detected(self, parsed, session_id: str):
        """
        –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –∫–æ–º–∞–Ω–¥—ã (–§–∞–∑–∞ 2)
        
        Args:
            parsed: ParsedResponse —Å command_payload
            session_id: ID —Å–µ—Å—Å–∏–∏
        """
        if not parsed.command_payload:
            return
        
        payload = parsed.command_payload.get('payload', {})
        command = payload.get('command', 'unknown')
        args = payload.get('args', {})
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º feature_id –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∫–æ–º–∞–Ω–¥—ã
        if command == 'open_app':
            feature_id = 'F-2025-013-open-app'
        elif command == 'close_app':
            feature_id = 'F-2025-014-close-app'
        elif command in ('create_subscription', 'cancel_subscription'):
            feature_id = 'F-2025-017-stripe-payment'
        else:
            feature_id = 'F-2025-016-mcp-app-opening-integration'
        
        log_structured(
            logger,
            logging.INFO,
            f"[{feature_id}] Command detected: {command}",
            scope="command",
            method="parse_assistant_response",
            decision="start",
            ctx={
                "session_id": session_id,
                "command": command,
                "args": args,
                "feature_id": feature_id
            }
        )
    
    def _log_command_complete(self, session_id: str):
        """
        –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ–≥–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∫–æ–º–∞–Ω–¥—ã (–§–∞–∑–∞ 2)
        
        Args:
            session_id: ID —Å–µ—Å—Å–∏–∏
        """
        if not self._pending_command_payload:
            return
        
        payload = self._pending_command_payload.get('payload', {})
        command = payload.get('command', 'unknown')
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º feature_id –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∫–æ–º–∞–Ω–¥—ã
        if command == 'open_app':
            feature_id = 'F-2025-013-open-app'
        elif command == 'close_app':
            feature_id = 'F-2025-014-close-app'
        elif command in ('create_subscription', 'cancel_subscription'):
            feature_id = 'F-2025-017-stripe-payment'
        else:
            feature_id = 'F-2025-016-mcp-app-opening-integration'
        
        log_structured(
            logger,
            logging.INFO,
            f"[{feature_id}] Command forwarded: {command}",
            scope="command",
            method="process_request_streaming",
            decision="complete",
            ctx={
                "session_id": session_id,
                "command": command,
                "feature_id": feature_id
            }
        )
    
    def _extract_json_from_markdown(self, text: str) -> str:
        """
        –£–¥–∞–ª—è–µ—Ç Markdown-–æ–±—ë—Ä—Ç–∫–∏ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —á–∏—Å—Ç—ã–π JSON —Ç–µ–∫—Å—Ç.
        –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ä–∞–∑–ª–∏—á–Ω—ã–µ –≤–∞—Ä–∏–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–æ–≤ LLM:
        - ```json {...}```
        - ``` {...}```
        - json {...}
        - –¢–µ–∫—Å—Ç –¥–æ/–ø–æ—Å–ª–µ JSON
        - –ß–∞—Å—Ç–∏—á–Ω—ã–π JSON (–¥–ª—è –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è)
        - JSON —Å –ª–∏—à–Ω–∏–º–∏ –ø—Ä–æ–±–µ–ª–∞–º–∏/–ø–µ—Ä–µ–Ω–æ—Å–∞–º–∏
        - JSON —Å trailing commas (—É–¥–∞–ª—è—é—Ç—Å—è)
        - JSON —Å –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è–º–∏ (—É–¥–∞–ª—è—é—Ç—Å—è)
        
        Args:
            text: –¢–µ–∫—Å—Ç, –∫–æ—Ç–æ—Ä—ã–π –º–æ–∂–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å JSON –≤ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–∞—Ö
            
        Returns:
            –ß–∏—Å—Ç—ã–π JSON —Ç–µ–∫—Å—Ç –±–µ–∑ markdown-—Ä–∞–∑–º–µ—Ç–∫–∏ –∏ –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤
        """
        if not text:
            return ""

        import re
        
        text = str(text).strip()

        # –í–∞—Ä–∏–∞–Ω—Ç 1: Markdown code fence ```json ... ``` –∏–ª–∏ ``` ... ```
        if text.startswith("```"):
            # –£–¥–∞–ª—è–µ–º –æ—Ç–∫—Ä—ã–≤–∞—é—â–∏–π fence
            text = text[3:]
            text = text.lstrip()
            
            # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π —è–∑—ã–∫ (json/JSON/JSONC –∏ —Ç.–¥.)
            lowered = text.lower()
            if lowered.startswith("json"):
                text = text[4:]
            text = text.lstrip()
            
            # –£–¥–∞–ª—è–µ–º –≤–µ–¥—É—â–∏–µ –ø–µ—Ä–µ–≤–æ–¥—ã —Å—Ç—Ä–æ–∫–∏
            while text.startswith(("\n", "\r")):
                text = text[1:]
            
            # –£–¥–∞–ª—è–µ–º –∑–∞–∫—Ä—ã–≤–∞—é—â–∏–π fence (–º–æ–∂–µ—Ç –±—ã—Ç—å –≤ –∫–æ–Ω—Ü–µ –∏–ª–∏ –≤ —Å–µ—Ä–µ–¥–∏–Ω–µ –¥–ª—è —á–∞—Å—Ç–∏—á–Ω–æ–≥–æ JSON)
            text = text.rstrip()
            if text.endswith("```"):
                text = text[:-3]
            text = text.strip()

        # –í–∞—Ä–∏–∞–Ω—Ç 2: –¢–µ–∫—Å—Ç –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å "json" (–±–µ–∑ markdown)
        # –£–¥–∞–ª—è–µ–º "json" –µ—Å–ª–∏ –æ–Ω —Å—Ç–æ–∏—Ç –ø–µ—Ä–µ–¥ JSON –æ–±—ä–µ–∫—Ç–æ–º
        text_lower = text.lower()
        if text_lower.startswith("json") and len(text) > 4:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –ø–æ—Å–ª–µ "json" –∏–¥—ë—Ç –ø—Ä–æ–±–µ–ª/–ø–µ—Ä–µ–Ω–æ—Å –∏ –∑–∞—Ç–µ–º {
            after_json = text[4:].lstrip()
            if after_json.startswith("{") or after_json.startswith("\n{") or after_json.startswith("\r{"):
                text = after_json

        # –í–∞—Ä–∏–∞–Ω—Ç 3: –¢–µ–∫—Å—Ç –¥–æ/–ø–æ—Å–ª–µ JSON - –∏–∑–≤–ª–µ–∫–∞–µ–º —Ç–æ–ª—å–∫–æ JSON –æ–±—ä–µ–∫—Ç
        # –ò—â–µ–º –ø–µ—Ä–≤—É—é –æ—Ç–∫—Ä—ã–≤–∞—é—â—É—é —Å–∫–æ–±–∫—É –∏ –ø–æ—Å–ª–µ–¥–Ω—é—é –∑–∞–∫—Ä—ã–≤–∞—é—â—É—é
        first_brace = text.find("{")
        last_brace = text.rfind("}")
        
        if first_brace != -1 and last_brace != -1 and first_brace < last_brace:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º JSON –æ–±—ä–µ–∫—Ç
            json_candidate = text[first_brace:last_brace + 1]
            
            # –û—á–∏—â–∞–µ–º –æ—Ç –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤ –≤–æ–∫—Ä—É–≥
            json_candidate = json_candidate.strip()
            
            # –£–¥–∞–ª—è–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã:
            # 1. –£–¥–∞–ª—è–µ–º –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ (// –∏ /* */) - —Ö–æ—Ç—è JSON –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç, LLM –º–æ–∂–µ—Ç –∏—Ö –¥–æ–±–∞–≤–∏—Ç—å
            json_candidate = re.sub(r'//.*?$', '', json_candidate, flags=re.MULTILINE)  # –û–¥–Ω–æ—Å—Ç—Ä–æ—á–Ω—ã–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏
            json_candidate = re.sub(r'/\*.*?\*/', '', json_candidate, flags=re.DOTALL)  # –ú–Ω–æ–≥–æ—Å—Ç—Ä–æ—á–Ω—ã–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏
            
            # 2. –£–¥–∞–ª—è–µ–º trailing commas –ø–µ—Ä–µ–¥ –∑–∞–∫—Ä—ã–≤–∞—é—â–∏–º–∏ —Å–∫–æ–±–∫–∞–º–∏/—Ñ–∏–≥—É—Ä–Ω—ã–º–∏ —Å–∫–æ–±–∫–∞–º–∏
            json_candidate = re.sub(r',\s*}', '}', json_candidate)  # Trailing comma –ø–µ—Ä–µ–¥ }
            json_candidate = re.sub(r',\s*]', ']', json_candidate)  # Trailing comma –ø–µ—Ä–µ–¥ ]
            
            # 3. –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø—Ä–æ–±–µ–ª—ã –∏ –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫
            json_candidate = re.sub(r'\n\s*\n', '\n', json_candidate)  # –£–¥–∞–ª—è–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
            json_candidate = re.sub(r'[ \t]+', ' ', json_candidate)  # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø—Ä–æ–±–µ–ª—ã
            
            # 4. –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –≤–æ–∫—Ä—É–≥ –¥–≤–æ–µ—Ç–æ—á–∏–π –∏ –∑–∞–ø—è—Ç—ã—Ö
            json_candidate = re.sub(r'\s*:\s*', ': ', json_candidate)  # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø—Ä–æ–±–µ–ª—ã –≤–æ–∫—Ä—É–≥ :
            json_candidate = re.sub(r'\s*,\s*', ', ', json_candidate)  # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø—Ä–æ–±–µ–ª—ã –≤–æ–∫—Ä—É–≥ ,
            
            return json_candidate

        # –ï—Å–ª–∏ JSON –æ–±—ä–µ–∫—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—á–∏—â–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
        # (–º–æ–∂–µ—Ç –±—ã—Ç—å —á–∞—Å—Ç–∏—á–Ω—ã–π JSON –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è)
        return text.strip()

    def _split_into_sentences(self, text: str) -> list[str]:
        """
        –†–∞–∑–±–∏–≤–∫–∞ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
        
        Args:
            text: –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç
            
        Returns:
            –°–ø–∏—Å–æ–∫ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
        """
        try:
            # –ü—Ä–æ—Å—Ç–∞—è —Ä–∞–∑–±–∏–≤–∫–∞ –ø–æ —Ç–æ—á–∫–∞–º, –≤–æ—Å–∫–ª–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–º –∏ –≤–æ–ø—Ä–æ—Å–∏—Ç–µ–ª—å–Ω—ã–º –∑–Ω–∞–∫–∞–º
            import re
            sentences = re.split(r'[.!?]+', text)
            
            # –û—á–∏—â–∞–µ–º –æ—Ç –ø—É—Å—Ç—ã—Ö —Å—Ç—Ä–æ–∫ –∏ –ª–∏—à–Ω–∏—Ö –ø—Ä–æ–±–µ–ª–æ–≤
            clean_sentences = [s.strip() for s in sentences if s.strip()]
            
            logger.debug(f"–¢–µ–∫—Å—Ç —Ä–∞–∑–±–∏—Ç –Ω–∞ {len(clean_sentences)} –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π")
            return clean_sentences
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Ä–∞–∑–±–∏–≤–∫–∏ —Ç–µ–∫—Å—Ç–∞: {e}")
            return [text]  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –≤–µ—Å—å —Ç–µ–∫—Å—Ç –∫–∞–∫ –æ–¥–Ω–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ
    
    async def cleanup(self):
        """–û—á–∏—Å—Ç–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤"""
        try:
            logger.info("–û—á–∏—Å—Ç–∫–∞ StreamingWorkflowIntegration...")
            self.is_initialized = False
            logger.info("‚úÖ StreamingWorkflowIntegration –æ—á–∏—â–µ–Ω")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ StreamingWorkflowIntegration: {e}")

    async def _get_memory_context_parallel(self, hardware_id: str) -> Optional[Dict[str, Any]]:
        """
        –ù–µ–±–ª–æ–∫–∏—Ä—É—é—â–µ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø–∞–º—è—Ç–∏
        
        Args:
            hardware_id: –ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è
        """
        try:
            if not self.memory_workflow:
                logger.debug("MemoryWorkflow –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –ø–æ–ª—É—á–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏")
                return None
            
            logger.debug(f"–ü–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø–∞–º—è—Ç–∏ –¥–ª—è {hardware_id}")
            memory_context = await self.memory_workflow.get_memory_context_parallel(hardware_id)
            
            if memory_context:
                logger.debug(f"‚úÖ –ü–æ–ª—É—á–µ–Ω –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø–∞–º—è—Ç–∏: {len(memory_context)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤")
            else:
                logger.debug("‚ö†Ô∏è –ö–æ–Ω—Ç–µ–∫—Å—Ç –ø–∞–º—è—Ç–∏ –ø—É—Å—Ç")
            
            return memory_context
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø–∞–º—è—Ç–∏: {e}")
            return None

    async def _iter_processed_sentences(
        self,
        text: str,
        screenshot: Optional[str],
        memory_context: Optional[Dict[str, Any]],
        subscription_context: str = ""  # MVP 7: Subscription context (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)
    ) -> AsyncGenerator[str, None]:
        """–°—Ç—Ä–∏–º–∏–Ω–≥–æ–≤–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è —Å —É—á—ë—Ç–æ–º –ø–∞–º—è—Ç–∏, subscription context –∏ —Å–∫—Ä–∏–Ω—à–æ—Ç–∞."""
        # MVP 7: –û–±–æ–≥–∞—â–∞–µ–º —Ç–µ–∫—Å—Ç subscription context –∏ memory context
        if subscription_context:
            enriched_text = self._enrich_with_subscription_and_memory(text, subscription_context, memory_context)
        else:
            enriched_text = self._enrich_with_memory(text, memory_context)

        screenshot_data: Optional[bytes] = None
        if screenshot:
            import base64
            try:
                screenshot_data = base64.b64decode(screenshot)
                logger.info(f"üì∏ –°–∫—Ä–∏–Ω—à–æ—Ç –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω: {len(screenshot_data)} bytes")
            except Exception as decode_error:
                logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞—Ç—å —Å–∫—Ä–∏–Ω—à–æ—Ç: {decode_error}")
                screenshot_data = None

        yielded_any = False
        if self.text_module and hasattr(self.text_module, 'process'):
            logger.info(f"üîÑ –°—Ç—Ä–∏–º–∏–Ω–≥ —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ Text Module: '{enriched_text[:80]}...'")
            try:
                async for chunk in self._stream_text_module(enriched_text, screenshot_data):
                    sentence = (self._extract_text_chunk(chunk) or '').strip()
                    if sentence:
                        yielded_any = True
                        logger.debug(f"üì® TextModule sentence: '{sentence[:120]}...'")
                        yield sentence
            except Exception as processing_error:
                logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ Text Module: {processing_error}. –ò—Å–ø–æ–ª—å–∑—É–µ–º fallback")
        elif self.text_module and hasattr(self.text_module, 'process_text_streaming'):
            # Legacy fallback –Ω–∞ –ø—Ä—è–º–æ–π –¥–æ—Å—Ç—É–ø –∫ TextProcessor
            logger.info(f"üîÑ Legacy —Å—Ç—Ä–∏–º–∏–Ω–≥ —Ç–µ–∫—Å—Ç–∞: '{enriched_text[:80]}...'")
            try:
                async for processed_sentence in self.text_module.process_text_streaming(enriched_text, screenshot_data):
                    sentence = (processed_sentence or '').strip()
                    if sentence:
                        yielded_any = True
                        logger.debug(f"üì® Legacy TextProcessor sentence: '{sentence[:120]}...'")
                        yield sentence
            except Exception as processing_error:
                logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ legacy TextProcessor: {processing_error}. –ò—Å–ø–æ–ª—å–∑—É–µ–º fallback")

        if not yielded_any:
            logger.debug("‚ö†Ô∏è TextProcessor –Ω–µ –≤–µ—Ä–Ω—É–ª –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π, –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback —Ä–∞–∑–±–∏–≤–∫—É")
            for fallback_sentence in self._split_into_sentences(enriched_text):
                if fallback_sentence:
                    yield fallback_sentence

    async def _sanitize_for_tts(self, text: str) -> str:
        """
        –û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è —Å–∏–Ω—Ç–µ–∑–∞ —Ä–µ—á–∏ —á–µ—Ä–µ–∑ –º–æ–¥—É–ª—å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        """
        if not text:
            return ""

        if self.text_filter_module and hasattr(self.text_filter_module, 'process'):
            try:
                result = await self.text_filter_module.process({
                    "operation": "clean_text",
                    "text": text,
                    "options": {
                        "remove_special_chars": True,
                        "remove_extra_whitespace": True,
                        "normalize_unicode": True,
                        "remove_control_chars": True
                    }
                })
                if isinstance(result, dict) and result.get("success") and result.get("cleaned_text") is not None:
                    return result.get("cleaned_text", "").strip()
            except Exception as err:
                logger.warning("‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ TextFilterModule: %s", err)

        return text.strip()

    async def _split_complete_sentences(self, text: str) -> tuple[list[str], str]:
        """
        –†–∞–∑–±–∏–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è —á–µ—Ä–µ–∑ –º–æ–¥—É–ª—å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        """
        if not text:
            return [], ""

        if self.text_filter_module and hasattr(self.text_filter_module, 'process'):
            try:
                result = await self.text_filter_module.process({
                    "operation": "split_sentences",
                    "text": text
                })
                if isinstance(result, dict) and result.get("success"):
                    return result.get("sentences", []), result.get("remainder", "")
            except Exception as err:
                logger.warning("‚ö†Ô∏è –û—à–∏–±–∫–∞ —Ä–∞–∑–±–∏–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ TextFilterModule: %s", err)

        stripped = text.strip()
        return ([stripped] if stripped else [], "")

    async def _count_meaningful_words(self, text: str) -> int:
        """
        –ü–æ–¥—Å—á—ë—Ç –∑–Ω–∞—á–∏–º—ã—Ö —Å–ª–æ–≤ —á–µ—Ä–µ–∑ –º–æ–¥—É–ª—å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        """
        if not text:
            return 0

        if self.text_filter_module and hasattr(self.text_filter_module, 'process'):
            try:
                result = await self.text_filter_module.process({
                    "operation": "count_meaningful_words",
                    "text": text
                })
                if isinstance(result, dict) and result.get("success"):
                    return int(result.get("count", 0))
            except Exception as err:
                logger.warning("‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–¥—Å—á—ë—Ç–∞ —Å–ª–æ–≤ —á–µ—Ä–µ–∑ TextFilterModule: %s", err)

        return len([w for w in text.split() if w.strip()])

    async def _stream_text_module(self, text: str, screenshot_data: Optional[bytes]):
        """–°—Ç—Ä–∏–º–∏–Ω–≥ –æ—Ç–≤–µ—Ç–æ–≤ –∏–∑ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –º–æ–¥—É–ª—è."""
        payload = {"text": text}
        if screenshot_data:
            payload["image_data"] = screenshot_data

        async for chunk in self._stream_module_results(self.text_module, payload):
            yield chunk

    async def _stream_audio_module(self, text: str):
        """–°—Ç—Ä–∏–º–∏–Ω–≥ –∞—É–¥–∏–æ —á–∞–Ω–∫–æ–≤ –∏–∑ –∞—É–¥–∏–æ –º–æ–¥—É–ª—è."""
        async for chunk in self._stream_module_results(self.audio_module, {"text": text}):
            yield chunk

    async def _stream_module_results(self, module, payload: Dict[str, Any]):
        """–£–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≤—ã–∑–æ–≤ module.process —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π async generator."""
        if not module or not hasattr(module, 'process'):
            return
        try:
            result = await module.process(payload)
            if result is None:
                return
            if hasattr(result, "__aiter__"):
                async for item in result:
                    yield item
            else:
                yield result
        except Exception as err:
            logger.warning("‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ –º–æ–¥—É–ª—è %s: %s", getattr(module, 'name', 'unknown'), err)

    def _extract_text_chunk(self, chunk: Any) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç–≤–µ—Ç –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –º–æ–¥—É–ª—è."""
        if chunk is None:
            return ""
        if isinstance(chunk, str):
            return chunk
        if isinstance(chunk, dict):
            for key in ("text", "text_response", "value", "chunk"):
                value = chunk.get(key)
                if isinstance(value, str):
                    return value
        return ""

    def _extract_audio_chunk(self, chunk: Any) -> bytes:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∞—É–¥–∏–æ –±–∞–π—Ç—ã –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –º–æ–¥—É–ª—è."""
        if chunk is None:
            return b""
        if isinstance(chunk, (bytes, bytearray)):
            return bytes(chunk)
        if isinstance(chunk, dict):
            for key in ("audio", "audio_chunk", "audio_data", "data", "value"):
                value = chunk.get(key)
                if isinstance(value, (bytes, bytearray)):
                    return bytes(value)
        return b""

    def _enrich_with_memory(self, text: str, memory_context: Optional[Dict[str, Any]]) -> str:
        """
        –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –ø–∞–º—è—Ç–∏

        Args:
            text: –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç
            memory_context: –ö–æ–Ω—Ç–µ–∫—Å—Ç –ø–∞–º—è—Ç–∏ (–¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å–ª–æ–≤–∞—Ä–µ–º)
        """
        if not memory_context:
            return text

        # ‚ö†Ô∏è CRITICAL: –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ memory_context - —ç—Ç–æ —Å–ª–æ–≤–∞—Ä—å
        if not isinstance(memory_context, dict):
            logger.warning(
                f"‚ö†Ô∏è Memory context is not a dict (type={type(memory_context).__name__}), skipping enrichment"
            )
            return text

        try:
            memory_info = memory_context.get('recent_context', '') if memory_context else ''
            if memory_info:
                enriched_text = f"–ö–æ–Ω—Ç–µ–∫—Å—Ç: {memory_info}\n\n{text}"
                logger.debug("–¢–µ–∫—Å—Ç –æ–±–æ–≥–∞—â–µ–Ω –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –ø–∞–º—è—Ç–∏")
                return enriched_text
            return text
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–±–æ–≥–∞—â–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –ø–∞–º—è—Ç—å—é: {e}")
            return text

    async def _stream_audio_for_sentence(self, sentence: str, sentence_index: int) -> AsyncGenerator[bytes, None]:
        """–°—Ç—Ä–∏–º–∏—Ç –∞—É–¥–∏–æ —á–∞–Ω–∫–∏ –¥–ª—è –æ–¥–Ω–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è."""
        if not sentence.strip():
            return
        if not self.audio_module:
            logger.warning("‚ö†Ô∏è AudioProcessor –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –∞—É–¥–∏–æ")
            return
        if hasattr(self.audio_module, 'process'):
            try:
                logger.info(f"üîä –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∞—É–¥–∏–æ –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è #{sentence_index}: '{sentence[:80]}...'")
                chunk_count = 0
                async for chunk in self._stream_audio_module(sentence):
                    audio_chunk = self._extract_audio_chunk(chunk)
                    if audio_chunk:
                        chunk_count += 1
                        logger.info(f"üîä Audio chunk #{chunk_count} –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è #{sentence_index}: {len(audio_chunk)} bytes")
                        yield audio_chunk
                logger.info(f"‚úÖ –ê—É–¥–∏–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è #{sentence_index}: {chunk_count} —á–∞–Ω–∫–æ–≤")
            except Exception as audio_error:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∞—É–¥–∏–æ –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è #{sentence_index}: {audio_error}")
        elif hasattr(self.audio_module, 'generate_speech_streaming'):
            # Legacy fallback
            try:
                logger.info(f"üîä Legacy –∞—É–¥–∏–æ –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è #{sentence_index}: '{sentence[:80]}...'")
                chunk_count = 0
                async for audio_chunk in self.audio_module.generate_speech_streaming(sentence):
                    if audio_chunk:
                        chunk_count += 1
                        logger.info(f"üîä Audio chunk #{chunk_count} –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è #{sentence_index}: {len(audio_chunk)} bytes")
                        yield audio_chunk
                logger.info(f"‚úÖ Legacy –∞—É–¥–∏–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è #{sentence_index}: {chunk_count} —á–∞–Ω–∫–æ–≤")
            except Exception as audio_error:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ legacy –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∞—É–¥–∏–æ –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è #{sentence_index}: {audio_error}")
    
    async def _parse_assistant_response(self, response: Union[str, Dict[str, Any]], session_id: str):
        """
        –ü–∞—Ä—Å–∏–Ω–≥ –æ—Ç–≤–µ—Ç–∞ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è text –∏ command_payload (–§–∞–∑–∞ 2)
        
        Args:
            response: –û—Ç–≤–µ—Ç –æ—Ç —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –º–æ–¥—É–ª—è (—Å—Ç—Ä–æ–∫–∞ –∏–ª–∏ —Å–ª–æ–≤–∞—Ä—å)
            session_id: ID —Å–µ—Å—Å–∏–∏ –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
            
        Returns:
            ParsedResponse —Å text_response –∏ –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–º command_payload
        """
        try:
            config = get_config()
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–∏—á–∞-—Ñ–ª–∞–≥ –∏ kill-switch
            if (not config.features.forward_assistant_actions or 
                config.kill_switches.disable_forward_assistant_actions):
                # –§–∏—á–∞ –≤—ã–∫–ª—é—á–µ–Ω–∞ - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç
                if isinstance(response, dict):
                    return self._assistant_parser.parse(response.get('text', str(response)))
                return self._assistant_parser.parse(response)
            
            # –ü–∞—Ä—Å–∏–º –æ—Ç–≤–µ—Ç, –ø–µ—Ä–µ–¥–∞–≤–∞—è session_id –¥–ª—è –ø–æ–¥—Å—Ç–∞–Ω–æ–≤–∫–∏ –≤ action-–æ—Ç–≤–µ—Ç—ã
            return self._assistant_parser.parse(response, session_id=session_id)
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ—Ç–≤–µ—Ç–∞ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞: {e}, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç")
            # Fallback –Ω–∞ –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç
            if isinstance(response, dict):
                text = response.get('text', str(response))
            else:
                text = str(response)
            return self._assistant_parser.parse(text)
    
    def _log_command_detected(self, parsed, session_id: str):
        """
        –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –∫–æ–º–∞–Ω–¥—ã (–§–∞–∑–∞ 2)
        
        Args:
            parsed: ParsedResponse —Å command_payload
            session_id: ID —Å–µ—Å—Å–∏–∏
        """
        if not parsed.command_payload:
            return
        
        payload = parsed.command_payload.get('payload', {})
        command = payload.get('command', 'unknown')
        args = payload.get('args', {})
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º feature_id –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∫–æ–º–∞–Ω–¥—ã
        if command == 'open_app':
            feature_id = 'F-2025-013-open-app'
        elif command == 'close_app':
            feature_id = 'F-2025-014-close-app'
        elif command in ('create_subscription', 'cancel_subscription'):
            feature_id = 'F-2025-017-stripe-payment'
        else:
            feature_id = 'F-2025-016-mcp-app-opening-integration'
        
        log_structured(
            logger,
            logging.INFO,
            f"[{feature_id}] Command detected: {command}",
            scope="command",
            method="parse_assistant_response",
            decision="start",
            ctx={
                "session_id": session_id,
                "command": command,
                "args": args,
                "feature_id": feature_id
            }
        )
    
    def _log_command_complete(self, session_id: str):
        """
        –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ–≥–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∫–æ–º–∞–Ω–¥—ã (–§–∞–∑–∞ 2)
        
        Args:
            session_id: ID —Å–µ—Å—Å–∏–∏
        """
        if not self._pending_command_payload:
            return
        
        payload = self._pending_command_payload.get('payload', {})
        command = payload.get('command', 'unknown')
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º feature_id –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∫–æ–º–∞–Ω–¥—ã
        if command == 'open_app':
            feature_id = 'F-2025-013-open-app'
        elif command == 'close_app':
            feature_id = 'F-2025-014-close-app'
        elif command in ('create_subscription', 'cancel_subscription'):
            feature_id = 'F-2025-017-stripe-payment'
        else:
            feature_id = 'F-2025-016-mcp-app-opening-integration'
        
        log_structured(
            logger,
            logging.INFO,
            f"[{feature_id}] Command forwarded: {command}",
            scope="command",
            method="process_request_streaming",
            decision="complete",
            ctx={
                "session_id": session_id,
                "command": command,
                "feature_id": feature_id
            }
        )
    
    def _extract_json_from_markdown(self, text: str) -> str:
        """
        –£–¥–∞–ª—è–µ—Ç Markdown-–æ–±—ë—Ä—Ç–∫–∏ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —á–∏—Å—Ç—ã–π JSON —Ç–µ–∫—Å—Ç.
        –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ä–∞–∑–ª–∏—á–Ω—ã–µ –≤–∞—Ä–∏–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–æ–≤ LLM:
        - ```json {...}```
        - ``` {...}```
        - json {...}
        - –¢–µ–∫—Å—Ç –¥–æ/–ø–æ—Å–ª–µ JSON
        - –ß–∞—Å—Ç–∏—á–Ω—ã–π JSON (–¥–ª—è –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è)
        - JSON —Å –ª–∏—à–Ω–∏–º–∏ –ø—Ä–æ–±–µ–ª–∞–º–∏/–ø–µ—Ä–µ–Ω–æ—Å–∞–º–∏
        - JSON —Å trailing commas (—É–¥–∞–ª—è—é—Ç—Å—è)
        - JSON —Å –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è–º–∏ (—É–¥–∞–ª—è—é—Ç—Å—è)
        
        Args:
            text: –¢–µ–∫—Å—Ç, –∫–æ—Ç–æ—Ä—ã–π –º–æ–∂–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å JSON –≤ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–∞—Ö
            
        Returns:
            –ß–∏—Å—Ç—ã–π JSON —Ç–µ–∫—Å—Ç –±–µ–∑ markdown-—Ä–∞–∑–º–µ—Ç–∫–∏ –∏ –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤
        """
        if not text:
            return ""

        import re
        
        text = str(text).strip()

        # –í–∞—Ä–∏–∞–Ω—Ç 1: Markdown code fence ```json ... ``` –∏–ª–∏ ``` ... ```
        if text.startswith("```"):
            # –£–¥–∞–ª—è–µ–º –æ—Ç–∫—Ä—ã–≤–∞—é—â–∏–π fence
            text = text[3:]
            text = text.lstrip()
            
            # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π —è–∑—ã–∫ (json/JSON/JSONC –∏ —Ç.–¥.)
            lowered = text.lower()
            if lowered.startswith("json"):
                text = text[4:]
            text = text.lstrip()
            
            # –£–¥–∞–ª—è–µ–º –≤–µ–¥—É—â–∏–µ –ø–µ—Ä–µ–≤–æ–¥—ã —Å—Ç—Ä–æ–∫–∏
            while text.startswith(("\n", "\r")):
                text = text[1:]
            
            # –£–¥–∞–ª—è–µ–º –∑–∞–∫—Ä—ã–≤–∞—é—â–∏–π fence (–º–æ–∂–µ—Ç –±—ã—Ç—å –≤ –∫–æ–Ω—Ü–µ –∏–ª–∏ –≤ —Å–µ—Ä–µ–¥–∏–Ω–µ –¥–ª—è —á–∞—Å—Ç–∏—á–Ω–æ–≥–æ JSON)
            text = text.rstrip()
            if text.endswith("```"):
                text = text[:-3]
            text = text.strip()

        # –í–∞—Ä–∏–∞–Ω—Ç 2: –¢–µ–∫—Å—Ç –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å "json" (–±–µ–∑ markdown)
        # –£–¥–∞–ª—è–µ–º "json" –µ—Å–ª–∏ –æ–Ω —Å—Ç–æ–∏—Ç –ø–µ—Ä–µ–¥ JSON –æ–±—ä–µ–∫—Ç–æ–º
        text_lower = text.lower()
        if text_lower.startswith("json") and len(text) > 4:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –ø–æ—Å–ª–µ "json" –∏–¥—ë—Ç –ø—Ä–æ–±–µ–ª/–ø–µ—Ä–µ–Ω–æ—Å –∏ –∑–∞—Ç–µ–º {
            after_json = text[4:].lstrip()
            if after_json.startswith("{") or after_json.startswith("\n{") or after_json.startswith("\r{"):
                text = after_json

        # –í–∞—Ä–∏–∞–Ω—Ç 3: –¢–µ–∫—Å—Ç –¥–æ/–ø–æ—Å–ª–µ JSON - –∏–∑–≤–ª–µ–∫–∞–µ–º —Ç–æ–ª—å–∫–æ JSON –æ–±—ä–µ–∫—Ç
        # –ò—â–µ–º –ø–µ—Ä–≤—É—é –æ—Ç–∫—Ä—ã–≤–∞—é—â—É—é —Å–∫–æ–±–∫—É –∏ –ø–æ—Å–ª–µ–¥–Ω—é—é –∑–∞–∫—Ä—ã–≤–∞—é—â—É—é
        first_brace = text.find("{")
        last_brace = text.rfind("}")
        
        if first_brace != -1 and last_brace != -1 and first_brace < last_brace:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º JSON –æ–±—ä–µ–∫—Ç
            json_candidate = text[first_brace:last_brace + 1]
            
            # –û—á–∏—â–∞–µ–º –æ—Ç –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤ –≤–æ–∫—Ä—É–≥
            json_candidate = json_candidate.strip()
            
            # –£–¥–∞–ª—è–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã:
            # 1. –£–¥–∞–ª—è–µ–º –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ (// –∏ /* */) - —Ö–æ—Ç—è JSON –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç, LLM –º–æ–∂–µ—Ç –∏—Ö –¥–æ–±–∞–≤–∏—Ç—å
            json_candidate = re.sub(r'//.*?$', '', json_candidate, flags=re.MULTILINE)  # –û–¥–Ω–æ—Å—Ç—Ä–æ—á–Ω—ã–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏
            json_candidate = re.sub(r'/\*.*?\*/', '', json_candidate, flags=re.DOTALL)  # –ú–Ω–æ–≥–æ—Å—Ç—Ä–æ—á–Ω—ã–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏
            
            # 2. –£–¥–∞–ª—è–µ–º trailing commas –ø–µ—Ä–µ–¥ –∑–∞–∫—Ä—ã–≤–∞—é—â–∏–º–∏ —Å–∫–æ–±–∫–∞–º–∏/—Ñ–∏–≥—É—Ä–Ω—ã–º–∏ —Å–∫–æ–±–∫–∞–º–∏
            json_candidate = re.sub(r',\s*}', '}', json_candidate)  # Trailing comma –ø–µ—Ä–µ–¥ }
            json_candidate = re.sub(r',\s*]', ']', json_candidate)  # Trailing comma –ø–µ—Ä–µ–¥ ]
            
            # 3. –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø—Ä–æ–±–µ–ª—ã –∏ –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫
            json_candidate = re.sub(r'\n\s*\n', '\n', json_candidate)  # –£–¥–∞–ª—è–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
            json_candidate = re.sub(r'[ \t]+', ' ', json_candidate)  # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø—Ä–æ–±–µ–ª—ã
            
            # 4. –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –≤–æ–∫—Ä—É–≥ –¥–≤–æ–µ—Ç–æ—á–∏–π –∏ –∑–∞–ø—è—Ç—ã—Ö
            json_candidate = re.sub(r'\s*:\s*', ': ', json_candidate)  # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø—Ä–æ–±–µ–ª—ã –≤–æ–∫—Ä—É–≥ :
            json_candidate = re.sub(r'\s*,\s*', ', ', json_candidate)  # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø—Ä–æ–±–µ–ª—ã –≤–æ–∫—Ä—É–≥ ,
            
            return json_candidate

        # –ï—Å–ª–∏ JSON –æ–±—ä–µ–∫—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—á–∏—â–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
        # (–º–æ–∂–µ—Ç –±—ã—Ç—å —á–∞—Å—Ç–∏—á–Ω—ã–π JSON –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è)
        return text.strip()

    def _split_into_sentences(self, text: str) -> list[str]:
        """
        –†–∞–∑–±–∏–≤–∫–∞ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
        
        Args:
            text: –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç
            
        Returns:
            –°–ø–∏—Å–æ–∫ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
        """
        try:
            # –ü—Ä–æ—Å—Ç–∞—è —Ä–∞–∑–±–∏–≤–∫–∞ –ø–æ —Ç–æ—á–∫–∞–º, –≤–æ—Å–∫–ª–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–º –∏ –≤–æ–ø—Ä–æ—Å–∏—Ç–µ–ª—å–Ω—ã–º –∑–Ω–∞–∫–∞–º
            import re
            sentences = re.split(r'[.!?]+', text)
            
            # –û—á–∏—â–∞–µ–º –æ—Ç –ø—É—Å—Ç—ã—Ö —Å—Ç—Ä–æ–∫ –∏ –ª–∏—à–Ω–∏—Ö –ø—Ä–æ–±–µ–ª–æ–≤
            clean_sentences = [s.strip() for s in sentences if s.strip()]
            
            logger.debug(f"–¢–µ–∫—Å—Ç —Ä–∞–∑–±–∏—Ç –Ω–∞ {len(clean_sentences)} –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π")
            return clean_sentences
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Ä–∞–∑–±–∏–≤–∫–∏ —Ç–µ–∫—Å—Ç–∞: {e}")
            return [text]  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –≤–µ—Å—å —Ç–µ–∫—Å—Ç –∫–∞–∫ –æ–¥–Ω–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ
    
    async def cleanup(self):
        """–û—á–∏—Å—Ç–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤"""
        try:
            logger.info("–û—á–∏—Å—Ç–∫–∞ StreamingWorkflowIntegration...")
            self.is_initialized = False
            logger.info("‚úÖ StreamingWorkflowIntegration –æ—á–∏—â–µ–Ω")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ StreamingWorkflowIntegration: {e}")

    async def _get_memory_context_parallel(self, hardware_id: str) -> Optional[Dict[str, Any]]:
        """
        –ù–µ–±–ª–æ–∫–∏—Ä—É—é—â–µ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø–∞–º—è—Ç–∏
        
        Args:
            hardware_id: –ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è
        """
        try:
            if not self.memory_workflow:
                logger.debug("MemoryWorkflow –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –ø–æ–ª—É—á–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏")
                return None
            
            logger.debug(f"–ü–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø–∞–º—è—Ç–∏ –¥–ª—è {hardware_id}")
            memory_context = await self.memory_workflow.get_memory_context_parallel(hardware_id)
            
            if memory_context:
                logger.debug(f"‚úÖ –ü–æ–ª—É—á–µ–Ω –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø–∞–º—è—Ç–∏: {len(memory_context)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤")
            else:
                logger.debug("‚ö†Ô∏è –ö–æ–Ω—Ç–µ–∫—Å—Ç –ø–∞–º—è—Ç–∏ –ø—É—Å—Ç")
            
            return memory_context
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø–∞–º—è—Ç–∏: {e}")
            return None

    async def _iter_processed_sentences(
        self,
        text: str,
        screenshot: Optional[str],
        memory_context: Optional[Dict[str, Any]],
        subscription_context: str = ""  # MVP 7: Subscription context (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)
    ) -> AsyncGenerator[str, None]:
        """–°—Ç—Ä–∏–º–∏–Ω–≥–æ–≤–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è —Å —É—á—ë—Ç–æ–º –ø–∞–º—è—Ç–∏, subscription context –∏ —Å–∫—Ä–∏–Ω—à–æ—Ç–∞."""
        # MVP 7: –û–±–æ–≥–∞—â–∞–µ–º —Ç–µ–∫—Å—Ç subscription context –∏ memory context
        if subscription_context:
            enriched_text = self._enrich_with_subscription_and_memory(text, subscription_context, memory_context)
        else:
            enriched_text = self._enrich_with_memory(text, memory_context)

        screenshot_data: Optional[bytes] = None
        if screenshot:
            import base64
            try:
                screenshot_data = base64.b64decode(screenshot)
                logger.info(f"üì∏ –°–∫—Ä–∏–Ω—à–æ—Ç –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω: {len(screenshot_data)} bytes")
            except Exception as decode_error:
                logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞—Ç—å —Å–∫—Ä–∏–Ω—à–æ—Ç: {decode_error}")
                screenshot_data = None

        yielded_any = False
        if self.text_module and hasattr(self.text_module, 'process'):
            logger.info(f"üîÑ –°—Ç—Ä–∏–º–∏–Ω–≥ —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ Text Module: '{enriched_text[:80]}...'")
            try:
                async for chunk in self._stream_text_module(enriched_text, screenshot_data):
                    sentence = (self._extract_text_chunk(chunk) or '').strip()
                    if sentence:
                        yielded_any = True
                        logger.debug(f"üì® TextModule sentence: '{sentence[:120]}...'")
                        yield sentence
            except Exception as processing_error:
                logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ Text Module: {processing_error}. –ò—Å–ø–æ–ª—å–∑—É–µ–º fallback")
        elif self.text_module and hasattr(self.text_module, 'process_text_streaming'):
            # Legacy fallback –Ω–∞ –ø—Ä—è–º–æ–π –¥–æ—Å—Ç—É–ø –∫ TextProcessor
            logger.info(f"üîÑ Legacy —Å—Ç—Ä–∏–º–∏–Ω–≥ —Ç–µ–∫—Å—Ç–∞: '{enriched_text[:80]}...'")
            try:
                async for processed_sentence in self.text_module.process_text_streaming(enriched_text, screenshot_data):
                    sentence = (processed_sentence or '').strip()
                    if sentence:
                        yielded_any = True
                        logger.debug(f"üì® Legacy TextProcessor sentence: '{sentence[:120]}...'")
                        yield sentence
            except Exception as processing_error:
                logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ legacy TextProcessor: {processing_error}. –ò—Å–ø–æ–ª—å–∑—É–µ–º fallback")

        if not yielded_any:
            logger.debug("‚ö†Ô∏è TextProcessor –Ω–µ –≤–µ—Ä–Ω—É–ª –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π, –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback —Ä–∞–∑–±–∏–≤–∫—É")
            for fallback_sentence in self._split_into_sentences(enriched_text):
                if fallback_sentence:
                    yield fallback_sentence

    async def _sanitize_for_tts(self, text: str) -> str:
        """
        –û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è —Å–∏–Ω—Ç–µ–∑–∞ —Ä–µ—á–∏ —á–µ—Ä–µ–∑ –º–æ–¥—É–ª—å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        """
        if not text:
            return ""

        if self.text_filter_module and hasattr(self.text_filter_module, 'process'):
            try:
                result = await self.text_filter_module.process({
                    "operation": "clean_text",
                    "text": text,
                    "options": {
                        "remove_special_chars": True,
                        "remove_extra_whitespace": True,
                        "normalize_unicode": True,
                        "remove_control_chars": True
                    }
                })
                if isinstance(result, dict) and result.get("success") and result.get("cleaned_text") is not None:
                    return result.get("cleaned_text", "").strip()
            except Exception as err:
                logger.warning("‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ TextFilterModule: %s", err)

        return text.strip()

    async def _split_complete_sentences(self, text: str) -> tuple[list[str], str]:
        """
        –†–∞–∑–±–∏–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è —á–µ—Ä–µ–∑ –º–æ–¥—É–ª—å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        """
        if not text:
            return [], ""

        if self.text_filter_module and hasattr(self.text_filter_module, 'process'):
            try:
                result = await self.text_filter_module.process({
                    "operation": "split_sentences",
                    "text": text
                })
                if isinstance(result, dict) and result.get("success"):
                    return result.get("sentences", []), result.get("remainder", "")
            except Exception as err:
                logger.warning("‚ö†Ô∏è –û—à–∏–±–∫–∞ —Ä–∞–∑–±–∏–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ TextFilterModule: %s", err)

        stripped = text.strip()
        return ([stripped] if stripped else [], "")

    async def _count_meaningful_words(self, text: str) -> int:
        """
        –ü–æ–¥—Å—á—ë—Ç –∑–Ω–∞—á–∏–º—ã—Ö —Å–ª–æ–≤ —á–µ—Ä–µ–∑ –º–æ–¥—É–ª—å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        """
        if not text:
            return 0

        if self.text_filter_module and hasattr(self.text_filter_module, 'process'):
            try:
                result = await self.text_filter_module.process({
                    "operation": "count_meaningful_words",
                    "text": text
                })
                if isinstance(result, dict) and result.get("success"):
                    return int(result.get("count", 0))
            except Exception as err:
                logger.warning("‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–¥—Å—á—ë—Ç–∞ —Å–ª–æ–≤ —á–µ—Ä–µ–∑ TextFilterModule: %s", err)

        return len([w for w in text.split() if w.strip()])

    async def _stream_text_module(self, text: str, screenshot_data: Optional[bytes]):
        """–°—Ç—Ä–∏–º–∏–Ω–≥ –æ—Ç–≤–µ—Ç–æ–≤ –∏–∑ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –º–æ–¥—É–ª—è."""
        payload = {"text": text}
        if screenshot_data:
            payload["image_data"] = screenshot_data

        async for chunk in self._stream_module_results(self.text_module, payload):
            yield chunk

    async def _stream_audio_module(self, text: str):
        """–°—Ç—Ä–∏–º–∏–Ω–≥ –∞—É–¥–∏–æ —á–∞–Ω–∫–æ–≤ –∏–∑ –∞—É–¥–∏–æ –º–æ–¥—É–ª—è."""
        async for chunk in self._stream_module_results(self.audio_module, {"text": text}):
            yield chunk

    async def _stream_module_results(self, module, payload: Dict[str, Any]):
        """–£–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≤—ã–∑–æ–≤ module.process —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π async generator."""
        if not module or not hasattr(module, 'process'):
            return
        try:
            result = await module.process(payload)
            if result is None:
                return
            if hasattr(result, "__aiter__"):
                async for item in result:
                    yield item
            else:
                yield result
        except Exception as err:
            logger.warning("‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ –º–æ–¥—É–ª—è %s: %s", getattr(module, 'name', 'unknown'), err)

    def _extract_text_chunk(self, chunk: Any) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç–≤–µ—Ç –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –º–æ–¥—É–ª—è."""
        if chunk is None:
            return ""
        if isinstance(chunk, str):
            return chunk
        if isinstance(chunk, dict):
            for key in ("text", "text_response", "value", "chunk"):
                value = chunk.get(key)
                if isinstance(value, str):
                    return value
        return ""

    def _extract_audio_chunk(self, chunk: Any) -> bytes:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∞—É–¥–∏–æ –±–∞–π—Ç—ã –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –º–æ–¥—É–ª—è."""
        if chunk is None:
            return b""
        if isinstance(chunk, (bytes, bytearray)):
            return bytes(chunk)
        if isinstance(chunk, dict):
            for key in ("audio", "audio_chunk", "audio_data", "data", "value"):
                value = chunk.get(key)
                if isinstance(value, (bytes, bytearray)):
                    return bytes(value)
        return b""

    def _enrich_with_memory(self, text: str, memory_context: Optional[Dict[str, Any]]) -> str:
        """
        –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –ø–∞–º—è—Ç–∏

        Args:
            text: –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç
            memory_context: –ö–æ–Ω—Ç–µ–∫—Å—Ç –ø–∞–º—è—Ç–∏ (–¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å–ª–æ–≤–∞—Ä–µ–º)
        """
        if not memory_context:
            return text

        # ‚ö†Ô∏è CRITICAL: –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ memory_context - —ç—Ç–æ —Å–ª–æ–≤–∞—Ä—å
        if not isinstance(memory_context, dict):
            logger.warning(
                f"‚ö†Ô∏è Memory context is not a dict (type={type(memory_context).__name__}), skipping enrichment"
            )
            return text

        try:
            memory_info = memory_context.get('recent_context', '') if memory_context else ''
            if memory_info:
                enriched_text = f"–ö–æ–Ω—Ç–µ–∫—Å—Ç: {memory_info}\n\n{text}"
                logger.debug("–¢–µ–∫—Å—Ç –æ–±–æ–≥–∞—â–µ–Ω –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –ø–∞–º—è—Ç–∏")
                return enriched_text
            return text
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–±–æ–≥–∞—â–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –ø–∞–º—è—Ç—å—é: {e}")
            return text

    async def _stream_audio_for_sentence(self, sentence: str, sentence_index: int) -> AsyncGenerator[bytes, None]:
        """–°—Ç—Ä–∏–º–∏—Ç –∞—É–¥–∏–æ —á–∞–Ω–∫–∏ –¥–ª—è –æ–¥–Ω–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è."""
        if not sentence.strip():
            return
        if not self.audio_module:
            logger.warning("‚ö†Ô∏è AudioProcessor –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –∞—É–¥–∏–æ")
            return
        if hasattr(self.audio_module, 'process'):
            try:
                logger.info(f"üîä –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∞—É–¥–∏–æ –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è #{sentence_index}: '{sentence[:80]}...'")
                chunk_count = 0
                async for chunk in self._stream_audio_module(sentence):
                    audio_chunk = self._extract_audio_chunk(chunk)
                    if audio_chunk:
                        chunk_count += 1
                        logger.info(f"üîä Audio chunk #{chunk_count} –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è #{sentence_index}: {len(audio_chunk)} bytes")
                        yield audio_chunk
                logger.info(f"‚úÖ –ê—É–¥–∏–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è #{sentence_index}: {chunk_count} —á–∞–Ω–∫–æ–≤")
            except Exception as audio_error:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∞—É–¥–∏–æ –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è #{sentence_index}: {audio_error}")
        elif hasattr(self.audio_module, 'generate_speech_streaming'):
            # Legacy fallback
            try:
                logger.info(f"üîä Legacy –∞—É–¥–∏–æ –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è #{sentence_index}: '{sentence[:80]}...'")
                chunk_count = 0
                async for audio_chunk in self.audio_module.generate_speech_streaming(sentence):
                    if audio_chunk:
                        chunk_count += 1
                        logger.info(f"üîä Audio chunk #{chunk_count} –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è #{sentence_index}: {len(audio_chunk)} bytes")
                        yield audio_chunk
                logger.info(f"‚úÖ Legacy –∞—É–¥–∏–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è #{sentence_index}: {chunk_count} —á–∞–Ω–∫–æ–≤")
            except Exception as audio_error:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ legacy –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∞—É–¥–∏–æ –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è #{sentence_index}: {audio_error}")
    
    async def _parse_assistant_response(self, response: Union[str, Dict[str, Any]], session_id: str):
        """
        –ü–∞—Ä—Å–∏–Ω–≥ –æ—Ç–≤–µ—Ç–∞ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è text –∏ command_payload (–§–∞–∑–∞ 2)
        
        Args:
            response: –û—Ç–≤–µ—Ç –æ—Ç —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –º–æ–¥—É–ª—è (—Å—Ç—Ä–æ–∫–∞ –∏–ª–∏ —Å–ª–æ–≤–∞—Ä—å)
            session_id: ID —Å–µ—Å—Å–∏–∏ –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
            
        Returns:
            ParsedResponse —Å text_response –∏ –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–º command_payload
        """
        try:
            config = get_config()
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–∏—á–∞-—Ñ–ª–∞–≥ –∏ kill-switch
            if (not config.features.forward_assistant_actions or 
                config.kill_switches.disable_forward_assistant_actions):
                # –§–∏—á–∞ –≤—ã–∫–ª—é—á–µ–Ω–∞ - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç
                if isinstance(response, dict):
                    return self._assistant_parser.parse(response.get('text', str(response)))
                return self._assistant_parser.parse(response)
            
            # –ü–∞—Ä—Å–∏–º –æ—Ç–≤–µ—Ç, –ø–µ—Ä–µ–¥–∞–≤–∞—è session_id –¥–ª—è –ø–æ–¥—Å—Ç–∞–Ω–æ–≤–∫–∏ –≤ action-–æ—Ç–≤–µ—Ç—ã
            return self._assistant_parser.parse(response, session_id=session_id)
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ—Ç–≤–µ—Ç–∞ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞: {e}, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç")
            # Fallback –Ω–∞ –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç
            if isinstance(response, dict):
                text = response.get('text', str(response))
            else:
                text = str(response)
            return self._assistant_parser.parse(text)
    
    def _log_command_detected(self, parsed, session_id: str):
        """
        –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –∫–æ–º–∞–Ω–¥—ã (–§–∞–∑–∞ 2)
        
        Args:
            parsed: ParsedResponse —Å command_payload
            session_id: ID —Å–µ—Å—Å–∏–∏
        """
        if not parsed.command_payload:
            return
        
        payload = parsed.command_payload.get('payload', {})
        command = payload.get('command', 'unknown')
        args = payload.get('args', {})
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º feature_id –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∫–æ–º–∞–Ω–¥—ã
        if command == 'open_app':
            feature_id = 'F-2025-013-open-app'
        elif command == 'close_app':
            feature_id = 'F-2025-014-close-app'
        elif command in ('create_subscription', 'cancel_subscription'):
            feature_id = 'F-2025-017-stripe-payment'
        else:
            feature_id = 'F-2025-016-mcp-app-opening-integration'
        
        log_structured(
            logger,
            logging.INFO,
            f"[{feature_id}] Command detected: {command}",
            scope="command",
            method="parse_assistant_response",
            decision="start",
            ctx={
                "session_id": session_id,
                "command": command,
                "args": args,
                "feature_id": feature_id
            }
        )
    
    def _log_command_complete(self, session_id: str):
        """
        –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ–≥–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∫–æ–º–∞–Ω–¥—ã (–§–∞–∑–∞ 2)
        
        Args:
            session_id: ID —Å–µ—Å—Å–∏–∏
        """
        if not self._pending_command_payload:
            return
        
        payload = self._pending_command_payload.get('payload', {})
        command = payload.get('command', 'unknown')
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º feature_id –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∫–æ–º–∞–Ω–¥—ã
        if command == 'open_app':
            feature_id = 'F-2025-013-open-app'
        elif command == 'close_app':
            feature_id = 'F-2025-014-close-app'
        elif command in ('create_subscription', 'cancel_subscription'):
            feature_id = 'F-2025-017-stripe-payment'
        else:
            feature_id = 'F-2025-016-mcp-app-opening-integration'
        
        log_structured(
            logger,
            logging.INFO,
            f"[{feature_id}] Command forwarded: {command}",
            scope="command",
            method="process_request_streaming",
            decision="complete",
            ctx={
                "session_id": session_id,
                "command": command,
                "feature_id": feature_id
            }
        )
    
    def _extract_json_from_markdown(self, text: str) -> str:
        """
        –£–¥–∞–ª—è–µ—Ç Markdown-–æ–±—ë—Ä—Ç–∫–∏ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —á–∏—Å—Ç—ã–π JSON —Ç–µ–∫—Å—Ç.
        –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ä–∞–∑–ª–∏—á–Ω—ã–µ –≤–∞—Ä–∏–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–æ–≤ LLM:
        - ```json {...}```
        - ``` {...}```
        - json {...}
        - –¢–µ–∫—Å—Ç –¥–æ/–ø–æ—Å–ª–µ JSON
        - –ß–∞—Å—Ç–∏—á–Ω—ã–π JSON (–¥–ª—è –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è)
        - JSON —Å –ª–∏—à–Ω–∏–º–∏ –ø—Ä–æ–±–µ–ª–∞–º–∏/–ø–µ—Ä–µ–Ω–æ—Å–∞–º–∏
        - JSON —Å trailing commas (—É–¥–∞–ª—è—é—Ç—Å—è)
        - JSON —Å –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è–º–∏ (—É–¥–∞–ª—è—é—Ç—Å—è)
        
        Args:
            text: –¢–µ–∫—Å—Ç, –∫–æ—Ç–æ—Ä—ã–π –º–æ–∂–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å JSON –≤ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–∞—Ö
            
        Returns:
            –ß–∏—Å—Ç—ã–π JSON —Ç–µ–∫—Å—Ç –±–µ–∑ markdown-—Ä–∞–∑–º–µ—Ç–∫–∏ –∏ –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤
        """
        if not text:
            return ""

        import re
        
        text = str(text).strip()

        # –í–∞—Ä–∏–∞–Ω—Ç 1: Markdown code fence ```json ... ``` –∏–ª–∏ ``` ... ```
        if text.startswith("```"):
            # –£–¥–∞–ª—è–µ–º –æ—Ç–∫—Ä—ã–≤–∞—é—â–∏–π fence
            text = text[3:]
            text = text.lstrip()
            
            # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π —è–∑—ã–∫ (json/JSON/JSONC –∏ —Ç.–¥.)
            lowered = text.lower()
            if lowered.startswith("json"):
                text = text[4:]
            text = text.lstrip()
            
            # –£–¥–∞–ª—è–µ–º –≤–µ–¥—É—â–∏–µ –ø–µ—Ä–µ–≤–æ–¥—ã —Å—Ç—Ä–æ–∫–∏
            while text.startswith(("\n", "\r")):
                text = text[1:]
            
            # –£–¥–∞–ª—è–µ–º –∑–∞–∫—Ä—ã–≤–∞—é—â–∏–π fence (–º–æ–∂–µ—Ç –±—ã—Ç—å –≤ –∫–æ–Ω—Ü–µ –∏–ª–∏ –≤ —Å–µ—Ä–µ–¥–∏–Ω–µ –¥–ª—è —á–∞—Å—Ç–∏—á–Ω–æ–≥–æ JSON)
            text = text.rstrip()
            if text.endswith("```"):
                text = text[:-3]
            text = text.strip()

        # –í–∞—Ä–∏–∞–Ω—Ç 2: –¢–µ–∫—Å—Ç –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å "json" (–±–µ–∑ markdown)
        # –£–¥–∞–ª—è–µ–º "json" –µ—Å–ª–∏ –æ–Ω —Å—Ç–æ–∏—Ç –ø–µ—Ä–µ–¥ JSON –æ–±—ä–µ–∫—Ç–æ–º
        text_lower = text.lower()
        if text_lower.startswith("json") and len(text) > 4:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –ø–æ—Å–ª–µ "json" –∏–¥—ë—Ç –ø—Ä–æ–±–µ–ª/–ø–µ—Ä–µ–Ω–æ—Å –∏ –∑–∞—Ç–µ–º {
            after_json = text[4:].lstrip()
            if after_json.startswith("{") or after_json.startswith("\n{") or after_json.startswith("\r{"):
                text = after_json

        # –í–∞—Ä–∏–∞–Ω—Ç 3: –¢–µ–∫—Å—Ç –¥–æ/–ø–æ—Å–ª–µ JSON - –∏–∑–≤–ª–µ–∫–∞–µ–º —Ç–æ–ª—å–∫–æ JSON –æ–±—ä–µ–∫—Ç
        # –ò—â–µ–º –ø–µ—Ä–≤—É—é –æ—Ç–∫—Ä—ã–≤–∞—é—â—É—é —Å–∫–æ–±–∫—É –∏ –ø–æ—Å–ª–µ–¥–Ω—é—é –∑–∞–∫—Ä—ã–≤–∞—é—â—É—é
        first_brace = text.find("{")
        last_brace = text.rfind("}")
        
        if first_brace != -1 and last_brace != -1 and first_brace < last_brace:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º JSON –æ–±—ä–µ–∫—Ç
            json_candidate = text[first_brace:last_brace + 1]
            
            # –û—á–∏—â–∞–µ–º –æ—Ç –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤ –≤–æ–∫—Ä—É–≥
            json_candidate = json_candidate.strip()
            
            # –£–¥–∞–ª—è–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã:
            # 1. –£–¥–∞–ª—è–µ–º –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ (// –∏ /* */) - —Ö–æ—Ç—è JSON –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç, LLM –º–æ–∂–µ—Ç –∏—Ö –¥–æ–±–∞–≤–∏—Ç—å
            json_candidate = re.sub(r'//.*?$', '', json_candidate, flags=re.MULTILINE)  # –û–¥–Ω–æ—Å—Ç—Ä–æ—á–Ω—ã–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏
            json_candidate = re.sub(r'/\*.*?\*/', '', json_candidate, flags=re.DOTALL)  # –ú–Ω–æ–≥–æ—Å—Ç—Ä–æ—á–Ω—ã–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏
            
            # 2. –£–¥–∞–ª—è–µ–º trailing commas –ø–µ—Ä–µ–¥ –∑–∞–∫—Ä—ã–≤–∞—é—â–∏–º–∏ —Å–∫–æ–±–∫–∞–º–∏/—Ñ–∏–≥—É—Ä–Ω—ã–º–∏ —Å–∫–æ–±–∫–∞–º–∏
            json_candidate = re.sub(r',\s*}', '}', json_candidate)  # Trailing comma –ø–µ—Ä–µ–¥ }
            json_candidate = re.sub(r',\s*]', ']', json_candidate)  # Trailing comma –ø–µ—Ä–µ–¥ ]
            
            # 3. –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø—Ä–æ–±–µ–ª—ã –∏ –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫
            json_candidate = re.sub(r'\n\s*\n', '\n', json_candidate)  # –£–¥–∞–ª—è–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
            json_candidate = re.sub(r'[ \t]+', ' ', json_candidate)  # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø—Ä–æ–±–µ–ª—ã
            
            # 4. –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –≤–æ–∫—Ä—É–≥ –¥–≤–æ–µ—Ç–æ—á–∏–π –∏ –∑–∞–ø—è—Ç—ã—Ö
            json_candidate = re.sub(r'\s*:\s*', ': ', json_candidate)  # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø—Ä–æ–±–µ–ª—ã –≤–æ–∫—Ä—É–≥ :
            json_candidate = re.sub(r'\s*,\s*', ', ', json_candidate)  # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø—Ä–æ–±–µ–ª—ã –≤–æ–∫—Ä—É–≥ ,
            
            return json_candidate

        # –ï—Å–ª–∏ JSON –æ–±—ä–µ–∫—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—á–∏—â–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
        # (–º–æ–∂–µ—Ç –±—ã—Ç—å —á–∞—Å—Ç–∏—á–Ω—ã–π JSON –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è)
        return text.strip()

    def _split_into_sentences(self, text: str) -> list[str]:
        """
        –†–∞–∑–±–∏–≤–∫–∞ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
        
        Args:
            text: –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç
            
        Returns:
            –°–ø–∏—Å–æ–∫ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
        """
        try:
            # –ü—Ä–æ—Å—Ç–∞—è —Ä–∞–∑–±–∏–≤–∫–∞ –ø–æ —Ç–æ—á–∫–∞–º, –≤–æ—Å–∫–ª–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–º –∏ –≤–æ–ø—Ä–æ—Å–∏—Ç–µ–ª—å–Ω—ã–º –∑–Ω–∞–∫–∞–º
            import re
            sentences = re.split(r'[.!?]+', text)
            
            # –û—á–∏—â–∞–µ–º –æ—Ç –ø—É—Å—Ç—ã—Ö —Å—Ç—Ä–æ–∫ –∏ –ª–∏—à–Ω–∏—Ö –ø—Ä–æ–±–µ–ª–æ–≤
            clean_sentences = [s.strip() for s in sentences if s.strip()]
            
            logger.debug(f"–¢–µ–∫—Å—Ç —Ä–∞–∑–±–∏—Ç –Ω–∞ {len(clean_sentences)} –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π")
            return clean_sentences
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Ä–∞–∑–±–∏–≤–∫–∏ —Ç–µ–∫—Å—Ç–∞: {e}")
            return [text]  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –≤–µ—Å—å —Ç–µ–∫—Å—Ç –∫–∞–∫ –æ–¥–Ω–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ
    
    # MVP 8: –ö–æ–º–∞–Ω–¥—ã –ø–æ–¥–ø–∏—Å–∫–∏
    async def _execute_subscription_command(
        self,
        command: str,
        hardware_id: str,
        session_id: str,
        args: Dict[str, Any]
    ) -> Optional[Dict[str, Any]]:
        """
        –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∫–æ–º–∞–Ω–¥—ã –ø–æ–¥–ø–∏—Å–∫–∏ (create_subscription, cancel_subscription –∏–ª–∏ manage_subscription)
        
        Args:
            command: –ù–∞–∑–≤–∞–Ω–∏–µ –∫–æ–º–∞–Ω–¥—ã ('create_subscription', 'cancel_subscription' –∏–ª–∏ 'manage_subscription')
            hardware_id: ID —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞
            session_id: ID —Å–µ—Å—Å–∏–∏
            args: –ê—Ä–≥—É–º–µ–Ω—Ç—ã –∫–æ–º–∞–Ω–¥—ã:
                - create_subscription: price_id, success_url, cancel_url (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ)
                - manage_subscription: return_url (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π)
        
        Returns:
            Dict —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ
        """
        if not self.subscription_module:
            logger.warning('[MVP8] SubscriptionModule not available, cannot execute subscription command')
            return {
                'text_response': "I'm sorry, but subscription features are not available at the moment.",
                'error': 'SubscriptionModule not available'
            }
        
        try:
            if command == 'create_subscription':
                logger.info(f'[MVP8] Creating checkout for {hardware_id[:8]}...')
                
                # –ü–æ–ª—É—á–∞–µ–º –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ args
                price_id = args.get('price_id')
                success_url = args.get('success_url')
                cancel_url = args.get('cancel_url')
                
                result = self.subscription_module.create_checkout(
                    hardware_id=hardware_id,
                    success_url=success_url,
                    cancel_url=cancel_url,
                    price_id=price_id
                )
                
                if result.get('error'):
                    logger.error(f'[MVP8] Error creating checkout: {result["error"]}')
                    return {
                        'text_response': f"I'm sorry, but I couldn't create the checkout session. {result['error']}",
                        'error': result['error']
                    }
                
                checkout_url = result.get('checkout_url')
                if checkout_url:
                    logger.info(f'[MVP8] Checkout created successfully: {result.get("session_id")}')
                    return {
                        'text_response': "I've created a checkout session for you. Opening the payment page...",
                        'checkout_url': checkout_url,
                        'session_id': result.get('session_id'),
                        'customer_id': result.get('customer_id')
                    }
                else:
                    return {
                        'text_response': "I'm sorry, but I couldn't create the checkout session. Please try again later.",
                        'error': 'No checkout URL returned'
                    }
            
            elif command == 'cancel_subscription':
                logger.info(f'[MVP8] Cancelling subscription for {hardware_id[:8]}...')
                
                result = self.subscription_module.cancel_subscription(hardware_id=hardware_id)
                
                if result.get('success'):
                    logger.info(f'[MVP8] Subscription cancelled successfully')
                    return {
                        'text_response': result.get('message', 'Your subscription has been cancelled successfully.'),
                        'success': True
                    }
                else:
                    logger.error(f'[MVP8] Error cancelling subscription: {result.get("message")}')
                    return {
                        'text_response': f"I'm sorry, but I couldn't cancel your subscription. {result.get('message', 'Unknown error')}",
                        'error': result.get('message')
                    }
            
            elif command == 'manage_subscription':
                logger.info(f'[MVP10] Creating portal session for {hardware_id[:8]}...')
                
                # –ü–æ–ª—É—á–∞–µ–º –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π return_url –∏–∑ args
                return_url = args.get('return_url')
                
                result = self.subscription_module.get_portal_url(
                    hardware_id=hardware_id,
                    return_url=return_url
                )
                
                if result.get('error'):
                    logger.error(f'[MVP10] Error creating portal URL: {result["error"]}')
                    return {
                        'text_response': f"I'm sorry, but I couldn't open the payment management page. {result['error']}",
                        'error': result['error']
                    }
                
                portal_url = result.get('portal_url')
                if portal_url:
                    logger.info(f'[MVP10] Portal URL created successfully: {result.get("session_id")}')
                    return {
                        'text_response': "I'm opening the payment management page where you can update your payment method, view billing history, and manage your subscription.",
                        'portal_url': portal_url,
                        'session_id': result.get('session_id')
                    }
                else:
                    return {
                        'text_response': "I'm sorry, but I couldn't open the payment management page. Please try again later.",
                        'error': 'No portal URL returned'
                    }
            
            else:
                logger.warning(f'[MVP8] Unknown subscription command: {command}')
                return {
                    'text_response': f"I don't recognize the subscription command: {command}",
                    'error': 'Unknown command'
                }
                
        except Exception as e:
            logger.error(f'[MVP8] Error executing subscription command: {e}')
            import traceback
            traceback.print_exc()
            return {
                'text_response': "I'm sorry, but an error occurred while processing your subscription request. Please try again later.",
                'error': str(e)
            }
    
    async def cleanup(self):
        """–û—á–∏—Å—Ç–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤"""
        try:
            logger.info("–û—á–∏—Å—Ç–∫–∞ StreamingWorkflowIntegration...")
            self.is_initialized = False
            logger.info("‚úÖ StreamingWorkflowIntegration –æ—á–∏—â–µ–Ω")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ StreamingWorkflowIntegration: {e}")
